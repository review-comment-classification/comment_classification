id,comment_id,revision_id,parent_revision,file_name,line_number,review_comment,comment_group
0,9fdfeff1_719b5072,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1686,"...and this make for an exception of mixed languages when translated.

Marking these with _() would improve the situation. That's ""message composition"" which is generally also a no-no. But the alternative is making separate explicit full messages for every path, and I don't think we need to go that far.",FUNCTION
1,9fdfeff1_0a1eeaba,ccc6ae9e649840e6b3e654a71f3b77103e6e5de2,b05d0b30b38a71a6b4ab607e2c6a2e8d5b97d629,nova/pci/request.py,50,"this import isn't needed. Below, simply do:

 inst_compute_node = objects.ComputeNode.get_by_host_and_nodename(...)",FUNCTION
2,3f79a3b5_ce50a40b,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,741,these changes not needed,EVOLVE
3,5fc1f717_40e4dc3c,3a2ffb73bdfd231a3fdc50964fec72073ced7a06,b5df2d428e9b4da1b0736ead2b98c320005e8287,nova/tests/unit/privsep/test_path.py,60,"with three *different* things called mock_open, this test case is tough to follow. It simplifies to:

    @mock.patch('os.path.exists', return_value=True)
    def test_write(self, mock_exists):
        mock_open = mock.mock_open()
        with mock.patch.object(six.moves.builtins, 'open',
                               new=mock_open):
            nova.privsep.path.writefile('/fake/path/file', 'w', 'foo')

            mock_exists.assert_called_with('/fake/path')
            self.assertTrue(mock.call('/fake/path/file', 'w') in
                            mock_open.mock_calls)
        mock_open.return_value.write.assert_called_with('foo')

...which, if not crystal clear, is at least somewhat more comprehensible.",FUNCTION
4,9fdfeff1_233726b3,ecd0d0c3572f77b844e5dd9657204d23ada12318,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/conf/api.py,323,"This is presumptive and we have to make sure we update it, right? I would tend to put this in the patch that adds the microversion because that's the first place it can be hit...",EVOLVE
5,9fdfeff1_4532aaf4,31fe7c76009e1c6d7859036e44b057d081b059b5,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/api/openstack/compute/instance_actions.py,185,ok this seams resonable,DISCUSS
6,5fc1f717_fd2718c6,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,6725,...though in this case it seems like we ought to be able to access self.conductor.manager.compute_task_mgr (you would have to expose the result of start_service('conductor') in ProviderUsageBaseTestCase).,FUNCTION
7,9fdfeff1_d777d907,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3501,good to add a case for sg not existed,FUNCTION
8,9fdfeff1_127753a2,65910122ef5d66d6804c3138f16f7e989be162ee,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,251,maybe this is why its on infinite loop ? we just ignore the updation of those mappings though we count them as migrated and they keep appearing in the next run ?,FUNCTION
9,9fdfeff1_13a430a2,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/network/neutronv2/api.py,1732,You can break the loop once you've found the matching VIF from the cache.,FUNCTION
10,9fdfeff1_f3dc3f75,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/tests/fixtures.py,1381,"nit: I don't think this needs to be magic, particularly as you're providing a spec.",FUNCTION
11,9fdfeff1_7b488f86,366be87bca5622fce10cedbb518bdbfcd602a7ea,220251f3eb85779165ecb86f9ae30058ba4c091e,nova/tests/unit/privsep/test_linux_net.py,17,nit: This blank line is not necessary.,EVOLVE
12,5fc1f717_7133cb63,6466a0f8adc5ea3ace8adc9de4fced8ff7ab7e81,a760f99d22a52d59119575660b84b7d506b67c5d,nova/tests/unit/privsep/test_fs.py,145,nit: I think you can decorate the class with this and avoid having to duplicate it everywhere,EVOLVE
13,9fdfeff1_916fd45e,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1741,ick,FUNCTION
14,bfdaf3ff_433fdd24,661dd591c94a9203c1a63e17789b83539a364527,84d94171d93a89af9fc71f6a326a988842c64d5e,nova/conductor/tasks/live_migrate.py,353,Better,DISCUSS
15,9fdfeff1_7e15819b,cd20ca77655f2d79776f4db165d03be941ac024f,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/compute/views/servers.py,293,"Now this seems wierd, if a server could only belong to one server_group(which seems to be the case), we should name this ``server_group``, and it doesn't need to be a list, and you should probably change also your spec https://review.openstack.org/#/c/612255/13/specs/stein/approved/show-server-group.rst@66

if it can belong to serveral groups, then it should be named as ``server_groups`` and have to be a list, but you don't need this key as ``uuid`` and a dict of uuids as value, just the group list is OK",FUNCTION
16,9fdfeff1_de1c3279,47163c365bd986cddd8a9f87abcc1db590a01573,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/tests/unit/virt/xenapi/test_xenapi.py,3588,"Any reason you couldn't create an instance of 'objects.XenapiLiveMigrateData' here too, as is done in the below test. Possible cleanup",FALSE
17,5fc1f717_91cddc5e,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6723,#ERROR!,DISCUSS
18,3f79a3b5_8679ac82,4eb512aa15f9f80322b2889dfdafaab1b08da7c0,aceef76e03374501811e58d6c2f108c4a5ffddf1,nova/tests/functional/regressions/test_bug_1550919.py,75,same,DISCUSS
19,5fc1f717_ce48df5d,e438b926202b1b13f9a04dbf16551cdb0e8ae566,95501d6f7876a9c218351d4e418e3f9779cca46d,nova/tests/unit/privsep/test_libvirt.py,39,"Python 3 test fails. So it should be ""b'I am a fish'"".",FUNCTION
20,9fdfeff1_f710225c,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/functional/test_servers.py,6371,++,DISCUSS
21,9fdfeff1_2fabcad7,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/unit/virt/libvirt/test_driver.py,15198,"parent_ifname may have made more sense, given the existing fields here",EVOLVE
22,3f79a3b5_c90a3acf,67fed7cc2d42e611e278b4a09fb0887ae8314aa4,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/functional/db/test_compute_node.py,143,"nit: since there is only one test calling this, I'd just merge it into the test itself.",EVOLVE
23,9fdfeff1_ab31ed5b,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2146,yaaaaay another upcall to Placement...,FALSE
24,9fdfeff1_69a072f5,bf22574eaffeb0337c2bf5b184ceed2982208e6a,8f38da3bf7ecae8a78888a2e64b90e5011c59d20,nova/tests/unit/virt/libvirt/volume/test_scaleio.py,26,"Not sure if there's any value in this anymore, since we do this below. Drop it",EVOLVE
25,9fdfeff1_2fa0c942,ffd81eb107dd04d05f828e9e049320412c576e1b,a8c065dea946599a1b07d003cd21409c4cd58df0,nova/tests/unit/matchers.py,384,Since you removed __enter__ and __exit__ is this still used as a context manager though?,DISCUSS
26,9fdfeff1_e1d1ff58,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,99,"So, if we get here and they didn't use 2.68, but we get an instance without display_name in it, we will continue to L110 and then explode right?

Presumably the cell_down_support should all match up with what we passed down to the lower layers such that we never get here where cell_down_support=False and ""'display_name' not instance=True"". However, seems like since we have the potential to be out of sync, we should do something here to prevent us from getting to L110, or even worse, getting to L110 and returning the instance with display_name=None or something, right?

So maybe change this to:

 if ""display_name"" not in instance:
     if cell_down_support:
         return { .. }
     else:
         LOG.warning('Tell the nova devs they messed up')
         return  # I dunno what this would do in the caller, but.. something

 return { ...regular thing... }

Or something like that?",FUNCTION
27,9fdfeff1_c3f688d9,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/unit/objects/test_request_spec.py,663,are,EVOLVE
28,9fdfeff1_8d6930bf,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1679,nix,EVOLVE
29,3f79a3b5_a262a9a6,d779b33d72d6ef41651ce7b93fe982f121bae2d7,183f6238c1d98b04fdcee0fb70212f01f4012ae4,nova/tests/unit/compute/test_rpcapi.py,612,This is sort of redundant with test_auto_pin right? The only difference is that test doesn't assert nova.objects.Service.get_minimum_version is *not* called.,EVOLVE
30,9fdfeff1_a1915354,1bb006516ecf68c4d43884780dfef748da8cfb46,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/virt/libvirt/driver.py,6310,does this need to be translated?,DISCUSS
31,5fc1f717_44be90b4,71df650d0a390d2b6b19928db4379e723e9f5cde,63e5cba88af5cd121b498cc46358eef19f83b69f,nova/virt/libvirt/driver.py,5952,"What about LOG.info() with architecture name? In case when it would be something to implement.

Could be handy for people adding support for new (sub)architectures.",FALSE
32,9fdfeff1_ea6f428f,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6195,nit: this is obvious and doesn't require a comment,EVOLVE
33,5fc1f717_b3442049,7931f85fe66d4e024d7dd5396dcf38378af85470,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,76,"Maybe I didn't get the point, but from the first glance it's not obvious that is_systemd() will be called before checking ""found_sysd"", and also sysd_checked is not used. Maybe it would be better to check for sysd_checked inside is_systemd() and return cached result if it is True?",EVOLVE
34,9fdfeff1_1833c964,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/virt/libvirt/driver.py,369,"It might be worth noting here with a comment that the ""unique"" choice does not have a special function since it is just the instance.uuid value.",EVOLVE
35,5fc1f717_d167ad4c,88c20a168ee89293751bd22ad621d1d8eb305693,75d4ba6752b0bebe6643d0efcdfcebdca2828a7c,nova/tests/functional/test_json_filter.py,82,Could create a server without the os:scheduler_hints query (or with a bogus one) to prove that it lands on host1; though I assume that's redundant with some other test elsewhere.,DISCUSS
36,9fdfeff1_9564c023,a5d6833d77c961ea75488f0992b91d3166424381,1d44fbddefb11421523c8ae5815642da0e22f8ea,nova/scheduler/utils.py,85,"An easier-to-read way of doing the above would be:

 int_keys = map(int, self._rg_by_id)
 ident = max(0, *int_keys) + 1

or just:

 ident = max(0, *map(int, self._rg_by_id)) + 1",FUNCTION
37,9fdfeff1_58801a47,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,676,"nit: use a set here since we only need it for ""in"" operation?

nit #2: I hope we're fine with the potential duplication of CONF.host in case we do not use a set here.",FUNCTION
38,9fdfeff1_58a7ba0c,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/client_wrapper.py,38,nit: needs updating?,EVOLVE
39,9fdfeff1_d2d5ecb8,91c6e0cc0194f16e579dfa38d29b19da4671c413,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,nova/conductor/manager.py,1252,RP,EVOLVE
40,3fce034c_ab1462a1,063824125bd56684395761569a0a24c54767ccb6,469d58ed79aca342a2916d0f4f8ffd06df467fe4,nova/api/openstack/compute/hypervisors.py,271,Yeehaw this was never documented in the API reference.,EVOLVE
41,9fdfeff1_335d3e79,20a46ece5701c9798a5e0df12c944237cb1ece3e,743d9e4dc7117412047d76c0fca6ed281265d5c7,nova/compute/resource_tracker.py,252,"+1

i would have assumed from the signiture of this function that since we are passing presuable the new flaovr as the instance_type paramater that invoking self._move_claim would have use that instead of the  instance.new_flavor so it non obvious that instance.new_flavor would need to be set.

so just a general question. i have wonderd why we have instance.flavor .old_flavor and .new_flavor in the past and lookin at the patch that intoduced them it was non obviobious to me. 
https://github.com/openstack/nova/commit/8b6a22e0e132d8dac6c280c1cd8aed2bbe980760

am i correct in my understanding that instance.flavor is the current flavor the instace is useing. instance.new_flavor is the target  falvor for a resize and instance.old_flavor is used to store the current flavor so that we can restore it if we revert the resize?",DISCUSS
42,ffb9cba7_7eede4ed,186b37f8237010b5abd4ab4ad208a9ea400f8819,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/api/openstack/compute/availability_zone.py,76,"Probably the only good way to test this with a unit test is to make sure that we're properly handling duplicates (which maybe there is already a test for that? We could find out by simply removing the ""if service['host'] not in zone_hosts[service['availability_zone']]:"" check in the previous code).",EVOLVE
43,3f79a3b5_6ee8a97d,ef0a50df52abef022d67fa20a1bbba9bb23ad6c2,ad31f5d66d6df25555c2f1c5653ac754790f06df,nova/conf/libvirt.py,695,ditto,EVOLVE
44,9fdfeff1_216483b8,701d653b5ac9a85fe691c77d6d0611f690d00d3a,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,167,nit: hypervisor,EVOLVE
45,9fdfeff1_0aa4184a,33644fbc8ebbca43d4d706d38501314a07ae5e66,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,2103,"Meh, there's not really a thing called requester_id. Really it's just the odd empty-string/number-ish thing that we use as a key for the request group :) But I suppose ""requester_id"" is as good a term for that as any ;)",EVOLVE
46,9fdfeff1_f90ba279,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6311,is this not an f... exception?,DISCUSS
47,5fc1f717_823c55c8,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,521,"Per the discussion in the spec, I think just document that if nodes > 1 we have a case of a target baremetal host being specified without a specific node and we can't decide which node to use, so we have to remove the limit from the GET /a_c query.",EVOLVE
48,3f79a3b5_750f0d38,69f2e957df7374a7d8bfbd30ebecfed940e17a2f,346db33d7d3185efc2c86dfd7d20984000404a94,nova/network/neutronv2/api.py,3033,RP,EVOLVE
49,3f79a3b5_314fcc31,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,1077,"After Mel's earlier comment I did my own quick audit, too. I think the only way this instance.host check could result in unwanted loss of data is if instance.host has been set to dest, but the data is not present there, yet. The 3 opportunities for doing that are evacuation, live migration, and resize.

Evacuate uses the rebuild workflow, which updates instance.host after a successful call to _do_rebuild_instance.

Resize updates instance.host after a successful call to migrate_disk_and_power_off.

Live migration updates instance.host in post_live_migration_at_destination, which is called after the data has moved.",FUNCTION
50,9fdfeff1_eb0bff79,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/tests/functional/test_servers.py,5474,"This seems like it could be racy later if something else is using the fixture, but hopefully none of that is global...",FUNCTION
51,9fdfeff1_2cb661de,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,706,"Ã¢Å“â€

could also do:

 if not group.required_traits.issubset(provider_traits[rp_uuid]):
     return False",FUNCTION
52,9fdfeff1_2820e8ab,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,174,"We should probably also update this warning to give the operator some things to check or try, right? Maybe add something like: ""Check your [pci]passthrough_whitelist configuration to make sure this allocated device is whitelisted, and/or you may need to migrate the server to another host if the device is no longer available on this host.""",EVOLVE
53,5fc1f717_5db09543,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,117,"This case is tested with test_create_invalid_flavorid, fine.",EVOLVE
54,9fdfeff1_6b6b8f84,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/api/openstack/common.py,574,"This could be optimized to only return the ""resource_request"" field using the fields kwarg to list_ports.",EVOLVE
55,9fdfeff1_c58a71bd,da972e3432ef0f7a242510a52484bc5660d9806c,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/driver.py,163,Need to add use_cache param to docstring.,EVOLVE
56,9fdfeff1_92447aba,a152f0922e97a5f6e6dde36fc0b5d18bdfb04e1f,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,241,"Just thinking out loud, but if the cell is down here this would blow up in some weird way right, like some kind of DBError? And we'd just choke and not be able to process any other instances in up cells. I realize this is an issue in other data migrations that are iterating all the cells (the one for queued_for_delete and the virtual_interfaces one). Seems we should be more resilient, but we could also deal with that in a follow up.",FUNCTION
57,9fdfeff1_49de653f,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,536,"Would be nice to take this opportunity to document the parameters here, specifically image because from just looking at this I can't tell if it's a dict or an ImageMeta object.",EVOLVE
58,3f79a3b5_c27dc1c3,80881918f676d218d076ca30a66214c312dd089f,a1dba961f0018a4995d208a290f4a859ce295840,nova/compute/manager.py,968,"This is debatable and I wouldn't include it here - if we don't save it, the info_cache (our state) is not the same as neutron's state, which could lead to weird side effects. Generally I think it's best if we try to always mirror the source of truth as much as possible (hence https://review.openstack.org/#/c/591607/). So how about we just add the 'unbound' here and drop the additional editorial?",EVOLVE
59,3f79a3b5_db2b47e6,4a5da5a3b471bb5592d0a97e93bb69152e6447c0,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/virt/libvirt/driver.py,8436,"This isn't working on a snapshot right? This is just a non-config drive disk during a resize (cold migration), as such if snapshot_compression=True we'll apply the -c option on qemu-img convert - is that OK? Is it harmless?",DISCUSS
60,3f79a3b5_025efd12,d779b33d72d6ef41651ce7b93fe982f121bae2d7,183f6238c1d98b04fdcee0fb70212f01f4012ae4,nova/tests/unit/compute/test_rpcapi.py,615,"Not sure why we don't just do this in setUp so each individual test doesn't need to remember to do it, but that could be done as a cleanup follow up (same for NO_COMPUTES_WARNING really).",EVOLVE
61,9fdfeff1_f08c9e80,6225fa3a4cf89b7156ca7e2a4f2198ee57a9b1f6,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/compute/manager.py,5455,"Hmm, shoulde we just get rid of this logic?",EVOLVE
62,5fc1f717_fc70fede,18ff2ab25b282e757e807174afcd9c122cc06aeb,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/conf/libvirt.py,661,"I'm not super happy with how it looks with the PS12 (and this one but Zuul isn't done yet) :
http://logs.openstack.org/81/641981/12/check/openstack-tox-docs/858e4f4/html/configuration/config.html#libvirt.disk_cachemodes

Maybe we could just add yet another level of bullets but it's maybe just a follow-up nit.",EVOLVE
63,9fdfeff1_d26f6291,8de9b00589f32359ee56b85fefce002234ac833a,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,42,"I think this might be unresolved from https://review.openstack.org/#/c/633350/7/nova/objects/instance_mapping.py@42.

Technically we can try to get the user_id from the RequestSpec *and* the BuildRequest:

- RequestSpec.user_id
- BuildRequest.instance.user_id

Failing those, if cell_mapping is set, we can try to get the Instance record via the cell. But if the cell is down, then we're pretty much screwed, right? What would we do, raise InstanceMappingNotFound or something? Otherwise it could result in a 500 response when trying to do GET /servers/{server_id}, but maybe that's OK because it is a 500 kind of situation, but you probably can't get out of it until the cell is back up since the online data migration is going to rely on talking to the cell as well to get the Instance.user_id.",DISCUSS
64,9fdfeff1_042428c5,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3574,use a named kwarg so people don't have to look at the method signature to figure out what this is,EVOLVE
65,1f769fc5_eb2aac8e,63d77bf63fd474d10fd7cac5f725784737bafa1a,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,218,"Looks like the comment from mriedem is still unaddressed?

https://review.openstack.org/#/c/618478/17/nova/conf/workarounds.py@218",DISCUSS
66,3f79a3b5_f6af6e99,68e8ae35929f33e6d50cf3e52f15a54691b487c7,01cea1a045db22f274fb8a6886733bee3f213fb6,nova/tests/unit/virt/vmwareapi/test_vif.py,431,"This is typically done as

 mock_network_name.assert_not_called()",FUNCTION
67,1f769fc5_18ff2aab,63d77bf63fd474d10fd7cac5f725784737bafa1a,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,244,instances_path,EVOLVE
68,9fdfeff1_a3ba6407,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,140,Also assert that it is False.,FUNCTION
69,5fc1f717_ec37b1af,28f2baca0294846a52763a5735c57b047ef6e483,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/unit/virt/libvirt/test_driver.py,701,\o/,EVOLVE
70,9fdfeff1_b8d5dde7,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,743,"Maybe we should add something like, ""It is recommended to use the default (``unique``) since that will not change when an instance is migrated. However, if you have a need for host-specific serials in addition to per-instance serial numbers, then consider restricting flavors via host aggregates.""",EVOLVE
71,9fdfeff1_801e4d5d,55f455262144ab319a9ff480850aeece88b1dedb,20a46ece5701c9798a5e0df12c944237cb1ece3e,nova/scheduler/client/report.py,1744,idempotency for the win,EVOLVE
72,9fdfeff1_b2f6d1d6,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/servers.py,274,"nit: the alignment here bugs me, I'd drop the whole line down together but that's just me",EVOLVE
73,3fce034c_84a2b34a,c0db968abc47672abac9c2a99554cece5c642d2f,acd64d1d805ad36004bc4c23d74ed7490bd43857,nova/scheduler/utils.py,505,"I realize this was already here, but I'm unable to interpret what an 'ored' is. What is it?",EVOLVE
74,3f79a3b5_30d29f60,f4253e095574b99f5313de2923f2e42e0cb75fed,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/tests/unit/compute/test_rpcapi.py,600,Or just: mock_log.debug.assert_called_once() ... :),FUNCTION
75,ffb9cba7_d479282f,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/objects/migrate_data.py,138,"In hindsight, this probably should have been an staticmethod on VIFMigrateData, or we should have added a VIFMigrateDataList object, *or* we could have had it as an attribute of Instance, seeing as it's always called with 'Instance.get_network_info'. This can be a follow up though",EVOLVE
76,9fdfeff1_52a8c576,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,2098,having,EVOLVE
77,9fdfeff1_32e82eb2,a152f0922e97a5f6e6dde36fc0b5d18bdfb04e1f,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,232,"Hitting this in flight should be relatively rare I would think so it might be worth logging this instance mapping as not having a cell yet during the migration. I'm thinking about stuff like where mnaser has seen some weird things where an instance mapping doesn't have a cell but the build request is gone. So if I were running this over and over and over and continued to see 'found' results but nothing 'done' I'd want some logging, because if that's a persistent issue we'd have to consider trying to lookup the RequestSpec to fill in the user_id here.",EVOLVE
78,9fdfeff1_6d014b38,f4451b6f2de16308ee9783ea44914f0ccf15ac01,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,5631,Why not fetch the BDM outside the lock?,EVOLVE
79,9fdfeff1_88623409,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,172,"Should probably change this to ""Unable"" since we're not trying to remove it now, at least not by forcing the status change.",EVOLVE
80,dfd5e7cf_ef6ca237,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/conductor/tasks/test_live_migrate.py,653,non-network,EVOLVE
81,9fdfeff1_6594f736,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/objects/instance_pci_requests.py,115,I guess we don't care about this because if we get here we have a really old instance and it wouldn't have the requester_id anyway.,FALSE
82,3f79a3b5_ad2ecaf5,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,378,"This didn't really need to be added in this change, I was just commenting on it as weird that we didn't have it in PS12. I'm not sure how other reviewers will feel about munging this into this patch. Some could think it's reason for an upgrade impact release note, but I think that is probably excessive. Given the logic in how this option is used, it's not doing ""live_migration_completion_timeout > 0"" it's doing ""live_migration_completion_timeout != 0"" so if anyone has this set to a value <0 they are already broken; given that I'm OK with including it here and not adding a specific upgrade note for it.

(later)

OK I see you mentioned it in the release note here. That's good enough for me.",FALSE
83,9fdfeff1_4fb9c0c9,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,449,"Set what false? OK I see, you should be using self._post_server and passing use_common_server_api_samples=False because you have your own server create request sample for this microversion with a server group in it.",EVOLVE
84,9fdfeff1_9abf1fa9,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/conductor/tasks/live_migrate.py,212,non-VIF,EVOLVE
85,9fdfeff1_13a60755,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/api_sample_tests/test_evacuate.py,212,is there not a way to pass the force flag and assert that the API failed json validation?,DISCUSS
86,9fdfeff1_cfd130fd,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,463,Do we need all this? Can't you just call self._post_server() from L466?,FUNCTION
87,3f79a3b5_8c5fa64a,31e7f0bb82b93b50b5c50076fcd8c2d133f6eb00,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,454,live_migration_timeout_action should also be listed here.,EVOLVE
88,9fdfeff1_5cffc166,27617ee1931b3240dbd0ad4c7d8ffd64cc202bc9,bcc4d233efceb98d3799f3ee339a5fe9a55aa266,nova/utils.py,1378,"TODO: remove once [1] is released.

[1] https://review.openstack.org/634258",EVOLVE
89,9fdfeff1_ed28fc33,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/scheduler/client/report.py,1752,"I see this block is mostly copied from put_allocations but this code is not doing any string comparison whereas put_allocations is, so we can remove this comment right?",EVOLVE
90,3f79a3b5_c0d99d53,e06ce8d3ce0a2152b0314808b29166620c971b1b,a2e1d1bd572fa71cc8ed53f618e322ac5ae524db,nova/exception.py,2357,"could it be better if we show what the limit is in the error message? Otherwise as an user, I may have to test out what the limit is.",EVOLVE
91,9fdfeff1_77214dfc,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3796,"You did nothing at here, so you can remove this.",EVOLVE
92,9fdfeff1_bf404309,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_linux_net.py,597,ditto,DISCUSS
93,9fdfeff1_2e1aeb16,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,82,"Going to want a feature release note for this stuff, unless there are more changes to come.",EVOLVE
94,9fdfeff1_249fec50,451d41a9deaf4bdba20509afc15a73df02e400f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,711,"just thinking through this... does this block need to have a guard for the 1.46 version support as well? If peer_list is not None, but Ironic doesn't support 1.46, that means that instead of hashing a subset of nodes across a subset of nova-compute peer services, *all* nodes will be hashed across a subset of nova-compute peer services.

This means that if a deployer configures two separate peering groups of nova-compute services and Ironic doesn't support 1.46 API, that multiple nova-compute services will end up managing the same Ironic node, right?",DISCUSS
95,5fc1f717_f33708e3,56541244fd4931c88cc17771c18e2e72ae9356eb,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/virt/libvirt/utils.py,320,"This is done as part of images.convert_image(), so we're not losing anything here.",FALSE
96,9fdfeff1_ac27b112,60a772b4a11512f3d7d591367fc7a1735e4b2515,d51c8b4c35f58af87d2c4ce7b6bfb6c7d6454b63,nova/exception.py,1803,just put Node ID: %(node_id)s,EVOLVE
97,3f79a3b5_873486d8,6fea14020bf7246bfcb2c7b2dcb71b680e9a0aa0,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/virt/libvirt/volume/net.py,74,nit: this log message could have been updated to mention rbd_user as well.,EVOLVE
98,3f79a3b5_eedbaa48,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,ec044885ff2c44202cc62cf85149b7993d4d0221,nova/scheduler/client/report.py,677,"hold up, I'm not sure I'm following this ...

if the UUID exists but the associations for that UUID are *NOT* stale, then we look for all providers that are *children* of that UUID and check to see if any of *them* are stale.

Is that correct?",DISCUSS
99,3f79a3b5_45f3066f,801ef1adca667ecdf243464b083282418d5987e4,2b97e508381e7f1efe48799ee3d9b068b4fd5902,nova/scheduler/client/report.py,705,"okay so here is the second optimization: since now our uuids_to_refresh would mostly not consist of anything during normal periodic cycles as the tree would be existing in cache unless its startup of sighup and the cache would never be stale since association refresh would be disabled (in our case), we would essentially also cut down:

1) GET/resource_providers/$rp_uuid/inventories
2) GET/resource_providers/$rp_uuid/aggregates
3) GET/resource_providers/$rp_uuid/traits
4) GET/resource_providers?member_of=in:$aggs&required=os_traits.MISC_SHARES_VIA_AGGREGATE""",FUNCTION
100,3f79a3b5_6b78fef4,ba0c1fbc6cd84e33ab35e6d467fd2a361e6cc7fa,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_driver.py,11433,probably should change the test name as this now has nothing to do with the switch function? Or probably you should add another test,EVOLVE
101,bfdaf3ff_bdba6107,6e49978b91e53d40dca766134340233163da374a,40a9d195de13e47eab37a07ccb9eb9518970875e,nova/api/openstack/placement/handlers/reshaper.py,70,"Unless this change is strictly necessary I wouldn't change anything in here at all, if you can help it, it's making more work/overhead for the extraction. If we think the response is insufficient, save it up for later and change it in placement itself.",FALSE
102,5fc1f717_44c5ab3c,4ffaf6e53bdd9af28dce8e9440a73c8f7604fda1,4cd89c138afaf97cb42743a38c407399bc3fd9c4,nova/virt/xenapi/vmops.py,1734,"it shadows the translation function that is also called '_' see below at L1739 for example. 


>>> def _():
...   print('original')
... 
>>> try:
...   for _ in range(10):
...     print('.')
...   raise ValueError('!')
... except:
...   print(_)
... 
.
.
.
.
.
.
.
.
.
.
9
>>>",FUNCTION
103,5fc1f717_e8983c6b,30295f1a141bb10f69f39c7ba453c7162db926b2,a7fae371a7fc48a778b2d632b1b90bf5659eda7d,nova/pci/request.py,54,nit: would be more typical to group this with 'CONF' below,EVOLVE
104,5fc1f717_06602ca5,b927748c257e705903c2aa0ffa47b19914e31ede,59d94633518e6f6272e9f0654bb908e332f97a96,nova/tests/unit/virt/libvirt/fakelibvirt.py,323,eventually it would probably be better to just have static fixtures of host resources instead of all the modulo stuff we're doing below... :),DISCUSS
105,3f79a3b5_7ab36dec,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,566,Do we really need these in the return object? Same below.,DISCUSS
106,5fc1f717_5141b4a5,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6744,"Move this entire method into the _claim_pci_for_instance_vifs() method below and put the semaphore around that method instead. After all, you want to claim all the PCI devices for an instance atomically, no?",EVOLVE
107,5fc1f717_13bcf903,baba88b1d73dfee45f1ca1ca8e261664237c2da6,18dc4d3dc526a3313fb6e1eee1c8913b22dffb93,nova/compute/manager.py,2130,it is shadowing this loop variable.,FALSE
108,9fdfeff1_37d665f3,d0d51a653a25a651e204b940957d0eb3c85798e5,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,645,"I'm not sure what this means. So ""internal"" DNS integration means the network does not have a DNS domain and ""external"" means it does?",DISCUSS
109,5fc1f717_a87474d1,891568eade76a3f559b7191e17d90d6b53b7b4e7,3cfcd117ce7ddb5a8d94396191cde559db73fb86,nova/virt/xenapi/agent.py,422,could these args ever be loged output to stderr by openssl,DISCUSS
110,9fdfeff1_8d55b052,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3635,nit: use mock_put.assert_has_calls instead,FUNCTION
111,9fdfeff1_ee37cd4a,debff531a8f0906cbdd38fbbb75e4c351d43412a,55f455262144ab319a9ff480850aeece88b1dedb,nova/tests/fixtures.py,1414,"you proably should also stub out the bindings extention. we are currently
adding support for binding-extended to the sriov nic agent
but odl and ovs to my knowladge dont support binding-extended jsut binding
so  you proably shoulc copy the alisa https://github.com/openstack/neutron-lib/blob/master/neutron_lib/api/definitions/portbindings.py#L122 name: https://github.com/openstack/neutron-lib/blob/master/neutron_lib/api/definitions/portbindings.py#L137 and description https://github.com/openstack/neutron-lib/blob/master/neutron_lib/api/definitions/portbindings.py#L144 form that too.",FALSE
112,9fdfeff1_9fe0dffa,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2178,ya i think using tags is fine once its automated. ideally we would traslate these into traits in the future once PFs RPs are modeled in placment with VF inventories and bandwith inventres in the same RP.,FALSE
113,3f79a3b5_125be488,07ed1c3292b46ecddd32ba22386795df732f77a0,48ad73e1faf966badab1f0344baad9f4f4055abf,nova/privsep/path.py,77,"This seems to come from https://review.openstack.org/#/c/489190/21/nova/virt/libvirt/utils.py

It is nice to get feedback from mikal.",DISCUSS
114,ffb9cba7_a90bd97a,622671fe5bf9518c3b88d947763d86a9c560153e,585e62e24481ce3e8c1d02a4d0b6f99b4f9df8c0,nova/tests/functional/db/test_compute_api.py,14,Looks like this doesn't exist in this release.. not sure how we'd address this.,FUNCTION
115,3fce034c_47035b74,29d82108928dd03a2907cd84a633a5ee65eeec46,013aa1915c79cfcb90c4333ce1e16b3c40f16be8,nova/tests/functional/api_sample_tests/test_cells.py,26,check_response_status,FUNCTION
116,5fc1f717_9c20a84b,43ce926dccae9e60611b1224ab06dcad8f650fce,b7bd97bc8896346e92d271a443d5ada9ab0074be,nova/compute/manager.py,1398,"maybe change to ""ins_on_host"" and delete line 1390?",FUNCTION
117,3f79a3b5_8771e648,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,218,"I'm not sure that 'rbd' belongs in here - makes it sound like the instance files are on rbd shared storage, which they're not. I realize this is all related to the rbd imagebackend but that's about the disks, not the instance files. Anyway, it's fine to leave this in.",EVOLVE
118,3f79a3b5_70904598,085fe6de688923540e13440f9189310e4cc15194,288c537fcd3dd605dc3ad393ba1234199a782e05,nova/virt/libvirt/driver.py,1074,"Just a note on the instance.host/CONF.host comparison, we need to be careful here if there's a way (I don't yet know if there is) that the migration has failed before completion but instance.host has already been updated to the destination, to avoid deleting the instance directory in that case.",FALSE
119,5fc1f717_6f47d2a4,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,662,nit: this is redundant,EVOLVE
120,9fdfeff1_ebeada71,31f048c689c6c750b0199a412922c87149e17bbf,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,nova/tests/fixtures.py,2031,OK so this now permanently targets the context to the cell unlike before where it was only for the duration of the call to fn.,DISCUSS
121,dfd5e7cf_41411539,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,187,"nit: you could shortcut all of this with:

  vif_pci_dev_address = vif.get('profile', {}).get('pci_slot')
  if not vif_pci_dev_address:
      return

  inst_compute_node = compute_node_objs.ComputeNode.\
      get_by_host_and_nodename(context, instance.host, instance.node)
  ...",FALSE
122,5fc1f717_0e1355b7,2a3179affb07e26202c7c7896b40368843bdc47a,64b4f41b24bf876294d1e587909ab911ce8e0b48,nova/tests/unit/pci/test_manager.py,550,"just a nit for future patches... comments like this (or below like ""Free instance claims"") aren't particularly useful since they are redundant with the name of the function called directly beneath them.

I know it's often good practice to code up a test by first outlining the different test steps into code comments and then ""filling in"" the test by calling the code for each of those steps, but generally good to remove single-line comments that simply repeat the function you're calling below them.",EVOLVE
123,3f79a3b5_0b70bfa6,5cdb825394f3015ef4b1224eb7d9f55633d217e9,801ef1adca667ecdf243464b083282418d5987e4,nova/scheduler/client/report.py,785,nit: no longer needed.,EVOLVE
124,9fdfeff1_12b72a89,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/scheduler/client/report.py,927,"ack, ok, yeah, here...",FALSE
125,bfdaf3ff_44b279e8,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/compute/manager.py,2335,"I guess we need this because of _default_block_device_names raising TooManyDiskDevices. If TooManyDiskDevices extended InvalidBDM then we could just get this handling for free, but it's a nit. Might be better (saner) to have the more explicit exception type getting handled.",FUNCTION
126,3f79a3b5_01e4f0a5,33aa1ec50a6733c30faeabd2f1b345b447498a7e,5153f122446905688526436634332bf81660a4f4,nova/pci/request.py,237,"im not sure this is sufficent.

i think we will need to take into account what host the vif is bound to handel the migration case. other wise this will only work if we dont use the multiple port binding feature.

since we want to use that feature this will be ambigious if 
the pci address of the vif did not change as part of the migfation.

ideally we should probably avoid using the pci_slot entirely if we can and look it up based on other critiera such as the instace vif and host.

that said im not sure we can do that today.",DISCUSS
127,3f79a3b5_23193bd1,44a553e0e98ea90a9ff9347d0ad891ffdb81c78c,dca1432f3db595fff91fe74e073b1b234e444e0f,nova/conf/compute.py,506,hmm... to long?,EVOLVE
128,9fdfeff1_a7e1999d,2c206de988e45d0375ff7a7bdeef877cc16b8096,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/api/openstack/compute/servers.py,840,Good lord would it be possible to throw the new set of exceptions in a common list or something so we don't have to try and manage them all as a giant block like this in three different places?,EVOLVE
129,9fdfeff1_6d5c0c19,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1680,"either ""containing"" or ""which contains""",EVOLVE
130,9fdfeff1_df271912,a433aa1f76e32c4522e48df158e7185bacb8e385,3150726396e60a9a9eea5492adc5ee98af92cda5,nova/tests/functional/libvirt/test_reshape.py,67,"This fails for me locally:

nova.tests.functional.libvirt.test_reshape.VGPUReshapeTests.test_create_server_with_vgpu
----------------------------------------------------------------------------------------

Captured traceback:
~~~~~~~~~~~~~~~~~~~
    b'Traceback (most recent call last):'
    b'  File ""/home/osboxes/git/nova/nova/tests/functional/libvirt/test_reshape.py"", line 67, in test_create_server_with_vgpu'
    b""    self.compute = self.start_service('compute')""
    b'  File ""/home/osboxes/git/nova/nova/test.py"", line 398, in start_service'
    b'    nova_fixtures.ServiceFixture(name, host, cell=cell, **kwargs))'
    b'  File ""/home/osboxes/git/nova/.tox/functional-py35/lib/python3.5/site-packages/testtools/testcase.py"", line 756, in useFixture'
    b'    reraise(*exc_info)'
    b'  File ""/home/osboxes/git/nova/.tox/functional-py35/lib/python3.5/site-packages/testtools/_compat3x.py"", line 16, in reraise'
    b'    raise exc_obj.with_traceback(exc_tb)'
    b'  File ""/home/osboxes/git/nova/.tox/functional-py35/lib/python3.5/site-packages/testtools/testcase.py"", line 731, in useFixture'
    b'    fixture.setUp()'
    b'  File ""/home/osboxes/git/nova/nova/tests/fixtures.py"", line 90, in setUp'
    b'    self.service.start()'
    b'  File ""/home/osboxes/git/nova/nova/service.py"", line 162, in start'
    b'    self.manager.init_host()'
    b'  File ""/home/osboxes/git/nova/nova/compute/manager.py"", line 1204, in init_host'
    b'    self.driver.init_host(host=self.host)'
    b'  File ""/home/osboxes/git/nova/nova/virt/libvirt/driver.py"", line 502, in init_host'
    b'    libvirt_utils.version_to_string(MIN_LIBVIRT_VERSION))'
    b'nova.exception.InternalError: Nova requires libvirt version 1.3.1 or greater.'
    b''


But the get_connection mock seems to be doing the same thing as the other libvirt functional tests so I don't really get it.",FUNCTION
131,3f79a3b5_33ce1f8f,9b3aa4d2d04c9d17effb51ee4a9ed33889bbdb1f,33aa1ec50a6733c30faeabd2f1b345b447498a7e,nova/conductor/tasks/live_migrate.py,464,"this is rather messy you this is using info from 
self.migrate_data.vifs in a function that is assign to
self.migrate_data.vifs without passing it in",FUNCTION
132,9fdfeff1_9f70df74,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,2868,ditto,DISCUSS
133,3f79a3b5_87db2d79,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,208,configure,EVOLVE
134,3f79a3b5_b2a705bc,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/compute/provider_tree.py,57,"correct me if im wrong but doesnt placement internally keep the route of the tree that a provider is in the provider record in the db

is there any reason we dont store that in the object so we can skip the tree walk later",DISCUSS
135,9fdfeff1_529be571,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,157,"I would like to avoid the dict-like get() usage here, the attribute should be set so use instance.project_id.",FUNCTION
136,5fc1f717_86cdfc87,2bc2cb9e7bc4716bef57a0616db036a1b43783ae,a37b16610de0c09ea99b4e8a731b82e5bc1bd229,nova/tests/unit/compute/test_rpcapi.py,69,Does this work? Wouldn't it be better to mock.patch.object the globals in the tests that tickle them?,DISCUSS
137,9fdfeff1_f2ea4273,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/api/openstack/compute/volumes.py,313,"And this doesn't require a new microversion because 403 is implied because of policy checks:

https://docs.openstack.org/nova/latest/contributor/microversions.html#f2",FALSE
138,9fdfeff1_8b38a93b,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2160,.... and just for a lookup while we have the ProviderTree in the libvirt driver...,FUNCTION
139,9fdfeff1_9683f856,cca4c66375974622e42ca096a8c20e09d437a11f,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,nova/pci/manager.py,294,this can fit one line,EVOLVE
140,9fdfeff1_6d6f2c28,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3636,[put_call] * 4,EVOLVE
141,5fc1f717_26c9d5aa,bd6c5b0416ce2d95849b65217748933a176a31a7,b63c42a0d4836fd0364cb306145d3474619f1e19,nova/conductor/manager.py,690,"this is question, but not scope of this patch. So...if the host_available false, then do we still need refill this mapping?",DISCUSS
142,9fdfeff1_1f8bcac2,5158b509703a111c3f1cd5dde05dfa5e50a81f20,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,748,whitespace damage,EVOLVE
143,5fc1f717_a9bd7269,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,230,"As noted in PS17, this is old now, i.e. the query for instance mappings does not filter by cell.",EVOLVE
144,9fdfeff1_53ba42e1,bc57a916c4045a387c69f327eb3a9e74be5b1a33,bea316d479750452a42295d9980d9dac5a89934e,nova/compute/manager.py,2128,"Per my comment in the change before this in the series that adds this block, putting this into a private helper method would help.",EVOLVE
145,9fdfeff1_d752be67,fb10f7ed0cd1566da3e068490300b1ebd053af8f,d89579a66ac38fd1e30cea55306e6e7b69bab5b9,nova/virt/hardware.py,1305,do these exceptions get unit-tested anywhere?,DISCUSS
146,9fdfeff1_c9e0b9fb,3a9d8316dcf5677b25938dfbfa0b898f072c0aa0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/objects/request_spec.py,790,This should probably be in the docstring.,EVOLVE
147,3fce034c_55627e18,82c79ceac30d7b97d68c2d71bdd0aae8c7038811,f389773f5255051f2f1cff4d0b0a08eafc0ac147,nova/tests/unit/privsep/test_libvirt.py,151,you could mock patch those symbols (as you did fcntl.fcntl) and assert called with the mocks.,FUNCTION
148,3fce034c_15c58b5b,c0db968abc47672abac9c2a99554cece5c642d2f,acd64d1d805ad36004bc4c23d74ed7490bd43857,nova/tests/unit/scheduler/test_utils.py,499,"nit: the mock covers this up, but either the host value in the ComputeNode objects above should be 'test' or this should be 'fake-host'.",FUNCTION
149,9fdfeff1_92d14dfe,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,173,If you move the conditional block at L184 above this new block of code we can DRY up this code and then you can just rely on the show_extra_specs variable already being set.,EVOLVE
150,5fc1f717_cb48d1cd,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4555,Assert that _get_image method is *not* called.,FUNCTION
151,5fc1f717_371e6f70,61f3cb49087a715bd6617c7762005cd7d142cf36,30550d3d947e13f4d23b207ff96373971710dd55,nova/conf/utils.py,38,"Hmm, should we make this a kwarg on the get_ksa_adapter_opts method we're in so the caller can determine this? And then we only need to pass True from the ironic driver code and can eventually remove it (on master) once python-ironicclient is updated to no longer require this?

I see this makes the 'interface' option show up in docs generation though which is nice:

http://logs.openstack.org/79/640879/8/check/openstack-tox-docs/219446b/html/configuration/config.html#ironic.interface",FUNCTION
152,9fdfeff1_b32e0e8a,743d9e4dc7117412047d76c0fca6ed281265d5c7,f548c91da693aa3ce1b4277c250601f799db9512,nova/compute/claims.py,144,"so dumb question but long term should we move this code to useing schedulerLimit objects instead of dicts.
i assume if i did some clean up of this code at a later date to just
use object that would be fine?",DISCUSS
153,5fc1f717_ce7a7bef,bd6c5b0416ce2d95849b65217748933a176a31a7,b63c42a0d4836fd0364cb306145d3474619f1e19,nova/conductor/manager.py,695,"If it is resource provider generation conflict, we still can try the next host, right? https://github.com/openstack/nova/blob/master/nova/scheduler/client/report.py#L1645

For the consumer generation conflict, that should be stopped.",DISCUSS
154,9fdfeff1_462ce649,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,97,#ERROR!,DISCUSS
155,5fc1f717_1cff4168,e2352a1c70b5bc491dbcfe87977b0f2c0b907a97,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,nova/compute/api.py,575,Oh Chris...you could have just copied the other param docstrings...,EVOLVE
156,9fdfeff1_88d046f9,1c6fdc9aecba310630b6e74e861d31a4c3be1bed,a37a035c9d359b29fed6ea08bc99b93e51164e61,nova/api/openstack/compute/volumes.py,212,weird that this even existed in the first place,FALSE
157,3f79a3b5_4b198288,74f3b8c5be01c06a027d628b40346e646256c212,ba0c1fbc6cd84e33ab35e6d467fd2a361e6cc7fa,nova/conf/libvirt.py,422,no timeout and/or choose to use abort?,DISCUSS
158,3f79a3b5_1c5a4b84,7a08c7714d90cd4766ffb27fab1a8ac3f431399c,7fa740491e53195021036af69a0ddfde183daef5,nova/objects/build_request.py,460,"Indeed, we need to return the next item after the marker as the first item, so adding one to the marker_index does that.

Here's how we get instances when providing a marker, calling utils.paginate_query in oslo.db:

https://github.com/openstack/nova/blob/93597864a36e69bdf5d8c83e49783ca081017e32/nova/db/sqlalchemy/api.py#L2236-L2240

and paginate_query returns the next item found after the marker (linked to docstring, you can also look at code):

https://github.com/openstack/oslo.db/blob/f1be3e74a6c8b28c7ef77ce6ee8808364b02b2a7/oslo_db/sqlalchemy/utils.py#L170-L171",DISCUSS
159,9fdfeff1_bcb2d604,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1680,"this is always going to be just ""{'allocations': {}}"" right? :)",DISCUSS
160,5fc1f717_7773e481,a5d174c29f160ff01063be2583a2afe22088be2d,a76eefed62db96fe51ef40e3209c187af3eb9834,nova/tests/functional/libvirt/test_reshape.py,189,RP,EVOLVE
161,dfd5e7cf_0f76f807,f72f5c52d152852dcecabbf592194addad185c74,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,204,Ã¢Å“â€,DISCUSS
162,5fc1f717_1355a71d,91e700426b2ce5160d0877576c7265b983a2b29b,4f9bc724010f0c935bf83a6d19bdd805e86b7086,nova/conductor/manager.py,1268,Would be nice to take this opportunity to document the parameters and their types to this method.,EVOLVE
163,3f79a3b5_6b623e16,ba0c1fbc6cd84e33ab35e6d467fd2a361e6cc7fa,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7392,should probably handle exception.NoActiveMigrationForInstance raised in: http://git.openstack.org/cgit/openstack/nova/tree/nova/virt/libvirt/driver.py#n7573,FUNCTION
164,1f769fc5_da873c61,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,194,"it is a singular object, not plural. Just call it info_cache, not instance_info_caches...",EVOLVE
165,9fdfeff1_2602fdbb,38f2ce549ce4b21d5085824df701f9d2392b5604,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/cmd/status.py,201,"I figured you'd want to still query it manually and just use the templating functions to fill it out, but whatever you want is cool with me.

Was nova-status supposed to run against N-1 code and DB? If so, would this be a problem?",DISCUSS
166,9fdfeff1_ec7f67dc,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,211,"This seems out of place in this change with the online data migration. Would have probably been better to split this out to either the change that needs to use it or right before the change that needs to use it, but separate from the data migration change since nothing in here is using it.",EVOLVE
167,5fc1f717_3e92fe4c,a5c26d865fd082c4aaff3635612fe841f9a7482f,2623acaba4573738faa61658af2d6006da6918a0,nova/virt/libvirt/volume/quobyte.py,55,I think this is typically done with a lock-and-recheck. Not that that's any prettier.,FUNCTION
168,9fdfeff1_acdb037b,baebdfb995e077b92af7ca20a208ece264d376f4,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,nova/objects/instance_pci_requests.py,54,"move this to the top, see how these are going in order from newest to oldest",EVOLVE
169,9fdfeff1_041a3f16,99a3823f98c593fd7f0a9e3fe3aab4126f9bb383,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/tests/unit/virt/libvirt/test_driver.py,18804,Should probably test non-support too.,FUNCTION
170,5fc1f717_fceb1ead,3e6bf09a70377f825b90637c6e2c6865933d9971,d50d8b6357fce78db7f6a4f85ff6a14a529ac48e,nova/conf/compute.py,658,Ã¢Å“â€,DISCUSS
171,9fdfeff1_a5bbbfe2,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/network/neutronv2/api.py,2060,nit: you didn't mention this in the commit message - I also don't see a test for it,FUNCTION
172,9fdfeff1_22cf2e2a,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1270,"Christ almighty this is a big method and we should break it up or condense somehow. I remember it was a single for loop before the counting quotas check introduced in Pike, and I had ideas on how to re-converge to a single for loop for sanity:

https://review.openstack.org/#/c/501408/2/nova/conductor/manager.py@1020

But haven't done that work.

Anyway, unrelated grumbling.",EVOLVE
173,9fdfeff1_531faf6f,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/unit/api/openstack/compute/test_migrate_server.py,630,"yeah, like this",DISCUSS
174,bfdaf3ff_ebd48ebf,f78440d5287662ebb7efcda7024d5386032cf467,e5b55245976293e0cb53089cc1efad6cc1edfa17,nova/tests/unit/objects/test_security_group.py,120,"nit: every other version of this has old version test first, new version second",DISCUSS
175,dfd5e7cf_69bc4e05,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/objects/test_numa.py,139,:),DISCUSS
176,5fc1f717_e8435c6b,891568eade76a3f559b7191e17d90d6b53b7b4e7,3cfcd117ce7ddb5a8d94396191cde559db73fb86,nova/virt/xenapi/agent.py,420,general question why are we not using a python lib to do this like pyOpenSSL,DISCUSS
177,bfdaf3ff_63cb0172,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/objects/test_numa.py,156,note to self: This refers to 1TiB pages.,FALSE
178,9fdfeff1_aa306c08,33644fbc8ebbca43d4d706d38501314a07ae5e66,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/fixtures.py,1394,+1 good comment.,DISCUSS
179,9fdfeff1_045efa11,85985dbf91df81c7d66118ae29b2a2787f3ede86,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/api/openstack/compute/views/servers.py,354,we can put those few lines into the try block,EVOLVE
180,3f79a3b5_dac72166,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,213,"Hmm, I thought this would need to be treated like a dict, like db_compute is a result from db.compute_node_update on L336.",FUNCTION
181,9fdfeff1_6b462f53,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3493,same - we already have this in the functional test,EVOLVE
182,3f79a3b5_c7ad9ea3,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,221,"nit: ""(local) instance directory""? Maybe that's not making anything more clear about this.",EVOLVE
183,9fdfeff1_25734f82,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/network/neutronv2/api.py,1697,One more small thing - you don't have a unit test for this case.,FUNCTION
184,bfdaf3ff_79bc2205,8a649f44541a8a6a743c4c77fd38c32651f7bf34,0bfb81b4dff5eb572ce8cd9e00f2a77134ce2816,nova/privsep/linux_net.py,141,...but it's respected here. All good,DISCUSS
185,bfdaf3ff_38a1bbaa,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/scheduler/client/report.py,1584,"not necessarily an ""initial"" view, but ok.",EVOLVE
186,bfdaf3ff_9f3731e4,fb4dcaccb041a6ae38a4e46c7ed83fc855c707db,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/image/glance.py,471,in the metadata?,EVOLVE
187,9fdfeff1_ab3932d7,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,344,nit: you could also assert the warning message is logged on this call,FUNCTION
188,5fc1f717_4fc21636,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,fb1fee6772bb101eac83845bac9022df77113aaa,nova/objects/request_spec.py,100,This is where RequestGroup gets into the RequestSpec.,DISCUSS
189,9fdfeff1_633a3c99,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,158,the target host.,EVOLVE
190,9fdfeff1_945c4bee,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,340,"so this should be 
self._check_can_migrate_pci(self.source, destination)
self._update_migrate_vifs_from_bindings(self.migrate_data.vifs,
                                                    bindings)",FUNCTION
191,9fdfeff1_d88a7862,743d9e4dc7117412047d76c0fca6ed281265d5c7,f548c91da693aa3ce1b4277c250601f799db9512,nova/compute/claims.py,127,"afaict this is only called from Claim.__init__, and it's called with limits specified. Can we remove the kwarg-ness and the word ""Optional"" from the docstring while we're here?",EVOLVE
192,bfdaf3ff_19e95619,4ef7066b8a1cc6d4e97eb600d26f46c3ba9808fe,3a3a5d34aec3afb740c22a13fdd6479828ae7c7b,nova/network/linux_net.py,671,Whoops,FALSE
193,3f79a3b5_2632b4c0,5d514b33e28964b38aeb42a8dd5b93f3fc8ae239,288c537fcd3dd605dc3ad393ba1234199a782e05,nova/tests/functional/regressions/test_bug_1806064.py,37,"Hrm, this reminds me of how we've talked about collapsing the two conductor loops into a single loop and just let all the instance-related resources be created ""at the same time"" and upon a recheck failure, we clean up everything including BDMs and tags. And doing that is the right fix for this.

(later) Thinking about it more, that refactor would not be backport friendly, so I think we're best off with this sort of fix for backporting and have the refactor be master-only.",DISCUSS
194,5fc1f717_7d156848,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,4039,"You could also do this with

 side_effect=[orig_claim, exception.AllocationUpdateFailed(...)]",FUNCTION
195,9fdfeff1_081a2016,d8f6882f547bd1a92fb38de5aed287d56bf8b233,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3574,there should be 'True'?,FALSE
196,9fdfeff1_86863713,512397423092b2260b1a914bfcd4a54ba14f343c,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conductor/tasks/migrate.py,163,Obviously this is tested implicitly but couldn't hurt to have a unit test for it too :),FUNCTION
197,9fdfeff1_e726c116,2ad333c54a8cf28a45bb263b24baac0e2ec81db5,b2299908d3bad434dd25d6c6bb0a9e6b4ab9eba2,nova/compute/manager.py,4570,"This is a behavior change, whereas the rest is refactor. Seems like maybe it would be safer to split this into its own change in case it goes kaflooey - or wants to be backported to rocky where that other change hasn't generated a bug yet :)",DISCUSS
198,9fdfeff1_2fd98af3,7e5273677c58b94684aca92a61cac64b716c9c9f,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,780,can you fix the indentation? which was messed up by this commit https://github.com/openstack/nova/commit/3f5594cf40e1b5d83abc822f230f4dfcf23d6263,EVOLVE
199,3fce034c_d50c2e44,504099e4e2bdd3fcda661d53956c303af88e8dfb,82c79ceac30d7b97d68c2d71bdd0aae8c7038811,nova/tests/unit/privsep/test_qemu.py,45,"To improve coverage, should do this one with in_format=None and compress=False.",FUNCTION
200,3f79a3b5_6d30b253,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7389,"nit: either "". If the..."" or ""; if the..."".",EVOLVE
201,9fdfeff1_540af0d1,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,8184,"I think we get this event if the port was detached out of band in neutron by the admin (or whoever) changes the device_id on the port - in that case, we'd be leaking the allocation for that port in placement, right?

There is also the network-vif-deleted case below where the port is outright deleted. That's another case where we wouldn't be cleaning up the allocation on the port, right? It of seems like neutron should be taking care of this for us since it manages the ports.",DISCUSS
202,9fdfeff1_8a7ec867,6c239c2390799fef03ba4f7d00762a4a96f62819,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1738,"nit: either ""will (re)query"" or ""(re)queries""",EVOLVE
203,3f79a3b5_77fca6bb,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,182,from,EVOLVE
204,9fdfeff1_d5efa8ae,c97b4046edb3bcd7c4284cabd26c58be99f08532,a6963fa6858289d048e4d27ce8e61637cd023f4c,nova/tests/unit/conductor/test_conductor.py,124,This change alone is safe to do.,DISCUSS
205,bfdaf3ff_181397b7,6e49978b91e53d40dca766134340233163da374a,40a9d195de13e47eab37a07ccb9eb9518970875e,nova/tests/functional/test_report_client.py,1311,Ã¢Å“â€œ,DISCUSS
206,9fdfeff1_4bb52631,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,586,"Are mdev UUIDs guaranteed to be consistent across reboots?

An alternate solution -- as opposed to passing the allocation information in init_host() -- would be to have the virt driver look up the instance UUID -> resource provider UUID(s) in the libvirt.xml file for the instance.

https://libvirt.org/formatdomain.html#elementsHostDev

Are we creating a <hostdev> element in the <devices> section of the libvirt XML file for each mdev associated with a vGPU the instance is using? If not, can we do that?",DISCUSS
207,5fc1f717_79b8a529,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,282,nit: maybe log the len(ims_by_inst_uuid) here as an indicator of the size of the issue?,EVOLVE
208,5fc1f717_e6481f88,362bba9011f8445285c3f72a0b00630163bfbc2f,e65a5275eeecae6ab041db2f089ae5dc3eefd92c,nova/tests/unit/virt/libvirt/test_imagebackend.py,1884,++,DISCUSS
209,5fc1f717_dbc3f537,82d2f6d2e399161d414e28b841323b9e8ad50563,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/virt/libvirt/utils.py,546,If you made this {}...,EVOLVE
210,9fdfeff1_9699ee6d,1843894477177656ab1e91eb0ceb9009f46d57c6,f0a1d3c2eba591561d75fe353fb051134e7b10a1,nova/conf/api.py,343,"See the ""Handling Down Cells""...",EVOLVE
211,9fdfeff1_9f2a5a7c,5158327bc8a2fbc4c3cabcf3fd964e5f61285fa1,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,746,"So, this was wholly operator-controlled before. Moving the option to be under control of the guest might run afoul of some operator's desire right?

Like, maybe the operator uses the serial number for agent correlation, or debugging, or forensics after an issue. By putting it fully within the user's control, they have no way to prevent them from making it unique right?

IMHO, if we're going to allow the image property, we should only honor it if this config is set to auto (or another new option called ""user""). But I would prefer we just not add the new image property, default this to ""unique"" in new installations and leave it at that.

I can think of only one somewhat silly case where the user might want to ask for the host's serial to be used, but it's pretty edge-case-y. Presumably ignoring that, no user is going to complain about having a stable unique serial number, so ops would be the only ones that might have an opinion, and if so, they should still be able to control it here, IMHO.",DISCUSS
212,9fdfeff1_6dcb5571,859a0ac11842101c902a98165277175d984c3352,b4a52f8968e657aae83f512d8e165aba9fd7388f,nova/network/neutronv2/api.py,1692,Ã¢Å“â€,DISCUSS
213,3f79a3b5_651a666a,a60631fd3a5df3e81dd9141fc1dd60f7cdd6ba80,9cac4ba8c5795265632d85d576a4ff810bffd475,nova/tests/unit/pci/test_request.py,29,Remove this blank line. pep8 job fails.,EVOLVE
214,3f79a3b5_5fb99cc2,12f523dc024858155d432060d4f27dd4acada56a,7eb8c9f299d5fec10df591b486b572db21a007c2,nova/compute/utils.py,1224,"Is this use of *ratio still groovy with regard to recent changes, or are those changes still in flight?

[later]
Ah, never mind, is a straight copy.",DISCUSS
215,3f79a3b5_35ba8adf,b3975a07752de81c8fca8e9604434e6d2a398cd2,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/cmd/status.py,322,"This is all out of date since the scheduler will fail now if there are no resource providers. We haven't updated older checks since they are kind of point-in-time things and would require some thought/discussion on what to do about older checks that no longer apply to master, i.e. I'm not exactly sure about FFU cases where someone is going from Ocata to let's say Rocky, would they even run these? And if so, are they required to run them in order or can they spin up the target release (Rocky) in a container and run the checks from there? I would think you'd need to run the checks per release as you run through them, just like the online data migrations.",DISCUSS
216,9fdfeff1_cac290e9,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/compute/manager.py,5976,You might want to add a comment here about why raise_on_failure is not used here.,EVOLVE
217,5fc1f717_5c870914,edc130bc226e0e073b9fa102e8e77d6ba0834440,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4548,"So... I love this test case, but I think it should be present *in addition* to the one that was here before. Otherwise, we don't have any positive assertion that the trait makes the instance land in the right place.

You can tack it onto this same test method if you like, or do it separately.",FUNCTION
218,ffd0ebdf_fb534ae1,141817eb7e1d9214e041597eeb905388353fc66e,6d78ccdfaed64d92f2c1bfe0e108ab8dcab97575,nova/network/neutronv2/api.py,181,I get a hard time to find out where the context obj get the `global_request_id` field...,FALSE
219,ffd0ebdf_956c669d,e542e512a95382b7a8eba631eb0e67ca49176971,357b8b38e88300948bb2e07d1bbaabd1e9d7b60e,nova/compute/resource_tracker.py,855,Similar.,FUNCTION
220,9fdfeff1_57c00ee1,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/functional/test_servers.py,5733,nit: remove 'an',EVOLVE
221,9fdfeff1_ac287fe1,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,278,OK yeah based on my question above I was hoping I'd see this.,FALSE
222,9fdfeff1_eff434d1,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/servers.py,1110,Similar to update - why show the server groups in the response when they can't change on rebuild? show_keypair is different because we can change keypairs on rebuild since 2.54. Although I think I already answered my own question there and we messed these up already.,DISCUSS
223,9fdfeff1_f2148250,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/tests/functional/test_servers.py,1046,"This seems like kind of a weird place to put this test. I'm assuming you just copied an existing test from in here and tweaked it to show the failure, but we could hit this failure regardless of the 2.20+ microversions.

Having said that, I don't have a better suggestion unless you just put it in a new class.",EVOLVE
224,9fdfeff1_81dc4fe4,900fe1c2e8e90be914f283563c0664439db54b5a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5018,move _create_pty_device() to the 'else' case instead of _create_file_device(). The function just NOOPs in the serial_console.enabled case.,EVOLVE
225,3f79a3b5_da9ac15f,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,615,same,FUNCTION
226,3f79a3b5_16a00df2,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,645,use the initial config options here again for clarity,FUNCTION
227,bfdaf3ff_84f92fc9,127104732e6c25b97f9547f3368e8e66cd04e27a,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,178,"This would fail if running this online data migration from a cell where [api_database]/connection is not configured, but I'm assuming that operators are running the online data migrations with a fully populated nova.conf that has access to the at least the API DB, and if running from a cell they would also have [database]/connection set (we seem to be pretty fuzzy about this in our online data migrations).",FUNCTION
228,5fc1f717_7c8dbc79,e75b9d0bc938dd7c32dd9356ad62ead85c275866,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,6468,"Is anything else using this method now or can we remove it also? Looks like this is the only usage:

http://codesearch.openstack.org/?q=_wait_for_port_unbind&i=nope&files=&repos=

Note you could keep this method but change it's implementation to be waiting for that versioned notification.",FUNCTION
229,3f79a3b5_268e987b,4eb512aa15f9f80322b2889dfdafaab1b08da7c0,aceef76e03374501811e58d6c2f108c4a5ffddf1,nova/tests/functional/regressions/test_bug_1550919.py,85,same,DISCUSS
230,5fc1f717_469e3464,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/pci/request.py,219,as above,EVOLVE
231,9fdfeff1_cb663bee,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3498,"this is now the message, I think you mean group_uuid=FAKE_UUID?",DISCUSS
232,bfdaf3ff_686d3297,e9660512f92ecebc66778ac20cf0d07515d9fbbd,9f0dd822ee401f3bd2e52de6159631dd95859e05,doc/source/conf.py,176,Why is this here if tripleo isn't in the openstack_projects list? Or is that *why* the note is here? Otherwise if I'm looking at this in a year would I understand the context?,DISCUSS
233,3f79a3b5_67da23e8,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/migration.py,390,Could we short-circuit this method by simply returning False immediately if this value is 0?,FUNCTION
234,3f79a3b5_a210beab,7a08c7714d90cd4766ffb27fab1a8ac3f431399c,7fa740491e53195021036af69a0ddfde183daef5,nova/objects/build_request.py,448,A comment here would be good. I'll add that.,EVOLVE
235,9fdfeff1_ed223ca3,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,6048,were,EVOLVE
236,9fdfeff1_637ebce5,f78440d5287662ebb7efcda7024d5386032cf467,e5b55245976293e0cb53089cc1efad6cc1edfa17,nova/tests/unit/objects/test_network.py,219,Could have just added ['nova_object.data'] here to have a smaller diff.,EVOLVE
237,9fdfeff1_2e00abab,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/api/openstack/compute/volumes.py,50,"I guess this is for the old os-volumes API, which is deprecated and isn't going to change.",DISCUSS
238,5fc1f717_78b75a88,b927748c257e705903c2aa0ffa47b19914e31ede,59d94633518e6f6272e9f0654bb908e332f97a96,nova/tests/unit/virt/libvirt/fakelibvirt.py,227,thank you for making this into something somewhat understandable with some code comments.,DISCUSS
239,9fdfeff1_71d706f0,b18e905de6a0ab24f90e6dee207214d126347e10,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,87,"Splat here allows the string to be empty. Is that legit? (I would expect you don't want '' and None to both be acceptable and meaningful.)

You could use a min_length on the StrOpt; or you could replace * with e.g. {1,255} and remove max_length.",DISCUSS
240,3f79a3b5_6edf1039,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,3636,"this is either a cold migration (if flavor_id is not set) or a resize (if it is).  The flavor only changes on a resize, so you should be able to just move this check up to line 3589 so that it's part of the ""else"" at 3580.",EVOLVE
241,5fc1f717_33827051,56541244fd4931c88cc17771c18e2e72ae9356eb,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/virt/libvirt/utils.py,312,Same comment here about cache mode for non-directio.,EVOLVE
242,ffd0ebdf_0d406235,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/metrics.py,50,"This one would be tricky...I would think the aggregate key would be ""metrics_weight_multiplier"" but that won't match what the utility tries to lookup in the config (CONF.filter_scheduler.metrics_weight_multiplier doesn't exist). Maybe the utility needs to take the multiplier name and the default value (which comes from config).",EVOLVE
243,9fdfeff1_4ae4040f,65e7b38d31af94c1e9c12a9cda005e8e9cc5213d,0b372ae75e589550569713f9b1cc88b4a7902325,nova/objects/instance_mapping.py,236,"Looks like you're picking up a marker instance record from an earlier online data migration:

http://logs.openstack.org/51/633351/6/check/neutron-grenade/0d926dc/logs/grenade.sh.txt.gz#_2019-02-19_03_00_17_540

2019-02-19 03:00:17.540 | InstanceList(objects=[Instance(00000000-0000-0000-0000-000000000000)])
2019-02-19 03:00:17.540 | setting user_id=None for instance mapping=25 with cell=c497f098-f0cd-44f2-a5a3-7c5eb3562142 for instance=00000000-0000-0000-0000-000000000000
2019-02-19 03:00:17.542 | 1 rows matched query populate_user_id, 1 migrated

So I guess you need to skip any instances that don't have a user_id set (or any with the stub uuid).",DISCUSS
244,9fdfeff1_e426c4cb,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3573,why not pass image.id here?,DISCUSS
245,3f79a3b5_33236608,51d433812010c886b49762296d47cbba9a1be5fd,e27905f482ba26d2bbf3ae5d948dee37523042d5,nova/virt/libvirt/utils.py,326,could we just switch this to use nova.privsep.qemu.convert_image() so we'd reduce duplicated code and pick up the cache behaviour for free?,EVOLVE
246,bfdaf3ff_996c6637,ed5362d09f655e8f04d0f9ccae22f9c4480a852c,c9ac27f1bcf81d0cf8a06414edcafc3a9068ae1f,nova/tests/unit/compute/test_compute.py,7472,"hmm, interesting. nice :)",DISCUSS
247,3fce034c_4f9f3450,70f6018b1ba82359745d2a2bd1fdd7b828c5d3f7,02b26457f3c5773973f374f39e069d2a854e99f6,nova/db/api.py,248,is this the same thing as ``name of the node`` ?,DISCUSS
248,9fdfeff1_ef145d43,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,612,If you used instance.image_meta earlier you'd have already hit this.,FALSE
249,9fdfeff1_d113e9ff,695dfc59f2adea9995c138a9694e6f4368fbf185,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/objects/request_spec.py,800,"Product grows very fast and input values are user input AFAIU, so some limits should be applied.
Overwise, malicious user can attack nova-api easily.",FUNCTION
250,9fdfeff1_3c676a28,d087e7833297e9c6ded8c569574665798a957b80,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,166,nit: it might be nice to add a comment to say that kvm is not a hypervior and when using virt_type kvm the hypervior_type will be qemu,EVOLVE
251,dfd5e7cf_6651cf62,90c350fce0a30e59de753fddd6648513cc326ef7,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/unit/pci/test_manager.py,528,"I know we don't always have them elsewhere, but comments explaining your logic as you go through this would be mighty appreciated. Also, this could conceivably be split in two but I'm not that bothered about that",EVOLVE
252,3fce034c_f8ca764d,a4543eaf2e55bfb3abd981aa9d743f39cd2559ce,0d1310224818c204c52f67deee18efafd1269681,nova/tests/unit/scheduler/test_host_manager.py,1116,"This is wrong, cn3 nodename is 'fake-node', but the mock covers it up.

cn3 = objects.ComputeNode(host='fake_host1', node='fake-node')",FUNCTION
253,bfdaf3ff_d8f66f90,6e49978b91e53d40dca766134340233163da374a,40a9d195de13e47eab37a07ccb9eb9518970875e,nova/api/openstack/placement/handlers/reshaper.py,70,changing i18n's messages shouldn't be done lightly. Is there a reason to change this particular message? i.e. are you trying to differentiate better between a consumer and a provider generation conflict?,DISCUSS
254,5fc1f717_f940150a,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/tests/functional/db/test_instance_mapping.py,353,Can't you just loop over nonexistent here?,FUNCTION
255,5fc1f717_e23215f2,33782daddf90c61052ff668c138185753bc6c71f,e608568518ed91a0cbf08f779c5adb851762d80a,nova/privsep/qemu.py,53,"nit: 15x faster is one order of magnitude, not ""multiple orders""",EVOLVE
256,5fc1f717_bb7bbc78,a84a40676dcb12608363210072049bf01d720073,7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4,nova/tests/unit/virt/libvirt/volume/test_quobyte.py,69,...but I wonder if it would be better to mock.patch these in a setUp so each test gets its own copy.,FUNCTION
257,3f79a3b5_13040d6b,5fbc83bfb5146d5dbcef092a417879318e5d5f21,84825b16f20adfaf9264e5c87d7feaf6480f076e,nova/compute/resource_tracker.py,156,"This was added in I982b211e0315bdb9a816f346fafffd0f70e46d07 and it was used:

https://github.com/openstack/nova/blob/stable/rocky/nova/compute/manager.py#L3939

and that code was removed in Stein:

I0851e2d54a1fdc82fe3291fb7e286e790f121e92

Therefore, it's OK to remove this, but let's do it completely outside of this change to not muddy it up.",FALSE
258,9fdfeff1_53180283,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,43,the,EVOLVE
259,ffd0ebdf_63749d9a,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,203,same note as in the docs and reno,EVOLVE
260,5fc1f717_499f2e50,d24275951d3ad0e0ae00621971278aeedf2bfd09,2a12e420c2934e49da5cb3e586407d3f6e1d6300,nova/tests/unit/compute/test_compute_api.py,6027,same - move this by the new assert for context,EVOLVE
261,bfdaf3ff_bdea3aa9,397f7ea9f686eaf8d0ca8f267f26e29ded710bb3,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/virt/libvirt/driver.py,4891,nit: It is not necessary.,FUNCTION
262,bfdaf3ff_28796afb,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/scheduler/client/report.py,1096,are we doing this anywhere now? this was one of those compromises we made with the Ironic team to ensure that custom resource classes for Ironic nodes were automatically created and would not cause failures in the resource tracker in nova-compute services that service Ironic baremetal resource nodes.,DISCUSS
263,3fce034c_d034f1fd,fc9c0e8703004ae206071d820c07e3cd701baf0e,49a9ce67ae3798bbcf8e0701d33f791c57ca7e93,nova/tests/unit/compute/test_compute_mgr.py,4644,I think this part of this test needs to be kept to test the expired console token removal.,FUNCTION
264,bfdaf3ff_193febd6,1e7cc87b6608907b8e315342178d1cc2ab9001e9,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/unit/objects/test_compute_node.py,457,How come you need this here,DISCUSS
265,9fdfeff1_ee239abd,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1055,configuration value,EVOLVE
266,3f79a3b5_7e334160,82884c897cac0fc0cb21de8838e02ee806e223d6,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/db/api.py,1242,Do we really need the DB API changes? We already have BlockDeviceMappingList.root_bdm().,DISCUSS
267,5fc1f717_a08580af,481b4d7ad72f2538bc55e9468e37d3479fbc76e6,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/virt/ironic/client_wrapper.py,102,"sooo...

The important thing here is to pass interfaces through to ironic. On the nova side, `valid_interfaces` is still, um, valid. At this point (with your change on the conf side) you're accepting both; so you need to accommodate either one being specified. So I think here you need to say

 kwargs['interface'] = ironic_conf.valid_interfaces or ironic_conf.interface

or similar. The stuff on the ironicclient side is already set up to handle the value being in either format (string or list) under the same key ('interface').",FUNCTION
268,9fdfeff1_2815a4e5,d8f6882f547bd1a92fb38de5aed287d56bf8b233,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,626,"How about we put those check into method, then we needn't the hack at line 3570",EVOLVE
269,9fdfeff1_91d274fc,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1717,"It would be nice if we could say ""resource provider"" or ""resource class"" here. But meh.",EVOLVE
270,9fdfeff1_1747a1be,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3491,"I don't think we need those, since weonly test will simple case.",EVOLVE
271,9fdfeff1_e68f1a2c,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,740,"allocations left over

and mentioning the RC could be helpful too.",EVOLVE
272,9fdfeff1_f7e686b0,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,692,"Isn't this where you need to do the copy? Otherwise you're consuming the resources once for every group you check. I think that's working in most of your test cases because you don't have more than two candidates. Not yet sure how it's working on the one with three...

[Later] Or maybe I was just confused about the scope of what a 'mapping' is. It's the list of all the rg-to-rp mappings for the whole allocation; so we actually *do* want to decrement cumulatively as we go.

TL;DR: I think this is copacetic.",DISCUSS
273,9fdfeff1_3115c89c,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/conductor/manager.py,1399,same,FUNCTION
274,3f79a3b5_b3e22f01,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,832,"This is where you might want to note the special ""cell_down_support"" kwarg that some counting functions may receive and what it means.",EVOLVE
275,3f79a3b5_942c79b2,50a4f4e1d1a4711ddaf0bf30eff0244826f028bd,62245235bc15da6abcdfd3df1c24bd856d69fbb4,nova/cmd/status.py,259,maybe PlacementDirect can help here,FUNCTION
276,1f769fc5_4bb5e0ed,5f2ec710cf38be6c23e04ce40e8a298d50e3b79d,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/compute.py,575,nit: ``literal``,EVOLVE
277,9fdfeff1_dc09da2a,900fe1c2e8e90be914f283563c0664439db54b5a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5021,"If all calls to _create_pty_device() check for serial_console.enabled themselves it should be removed here.

This also creates functionally symmetric code where
_create_serial_consoles() and _create_pty_device() create the devices and _create_consoles_qemu_kvm() decides which type we need.",EVOLVE
278,9fdfeff1_2fbaa0bf,080587b75e14cadadfabc9ac007278b0b62f041a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,676,"And what happens if peer_list is left unset in the config, but partition_key is set? Will every compute think it owns all the nodes within a conductor group? Presumably we need to at least assert that _we_ are in the list, right? So maybe we should:

 1. Fail if the list is empty
 2. Log a BFW if we're the only thing in the list

I assume a single compute for a conductor group is legit, but potentially not what the operator was expecting, yeah?",DISCUSS
279,3fce034c_1ce63646,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/compute/cells_api.py,279,"Note to self: you were suspicious about

 except InstanceNotFound: pass

no longer being necessary here. You convinced yourself it doesn't matter.",FALSE
280,9fdfeff1_42b91277,a59198ae4940f27551166cbaeddc8ceedb20ff24,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/compute/api.py,2288,"so its at this part basically if they get restored we need to go set their user_id if its None in the mapping. makes sense.

Since we need not do this for other kinds of delete, maybe we can pass user_id=None in the _update_queued_for_deletion_and_user_id() function ? and only set it for this case or something ? Just felt that commonly doing this for all deletes doesn't make sense but avoiding double querying seperately does make sense",DISCUSS
281,3f79a3b5_6bdf0239,a53ccfb4fecd84941e7883ef7ce509cd016931fd,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,213,"I thought you were going to remove this?

Thinking about this more now, let's say we fetch the compute node from the db prior to calling this, call that version 1. Then while were processing the keys, something else updates it, call that version 2. Then we get to L211 and decide that we need to do the update of the ratio values, so we do, call that version 3. Now here on L213, we take our compute objects, which is version 1, and give it the updated_at from version 3. That doesn't make any sense to me.

So I would say you should either:

 1. Not change updated_at at all
 2. Do this fixup and save as the first thing in _from_db_compute, and then load all the fields from the one object you get back from the update.

I would recommend #1 because it's easier, but what you have here just seems confusing and inconsistent.",EVOLVE
282,9fdfeff1_fcd242d1,2f21b1ba50e92311bc38426363ff09c495c81a05,a76eefed62db96fe51ef40e3209c187af3eb9834,nova/tests/functional/libvirt/test_reshape.py,117,"Ew, would be nice if we did this in a helper method:

https://review.openstack.org/#/c/599208/18/nova/virt/libvirt/driver.py@6835",EVOLVE
283,3f79a3b5_ac75c2cb,31e7f0bb82b93b50b5c50076fcd8c2d133f6eb00,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,419,the compute service,EVOLVE
284,9fdfeff1_c6115254,b164aaac1f036455205d2457abc3ae75769bf42f,3730bd079104ad14f6992ad55cf8643911c916ab,nova/tests/unit/api/openstack/compute/test_evacuate.py,247,This is redundant with the functional test but that's just a nit since this is pretty simple.,EVOLVE
285,9fdfeff1_73b75388,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/api/openstack/compute/schemas/migrate_server.py,72,x,EVOLVE
286,3fce034c_f0a45fbb,4713b49c8646501957a49b8a7f2e13521a2e0544,a40c7f3e8d06f0bc8918a25b60f73ec2c18add05,nova/compute/api.py,574,"this part of comment is not accurate, image activity is checked in _validate_flavor_image.",EVOLVE
287,5fc1f717_c4ce97b3,e660c6646b8f8dd02c0b64b20b6c2db630969315,2623acaba4573738faa61658af2d6006da6918a0,nova/tests/unit/virt/libvirt/volume/test_quobyte.py,38,Pls drop these mocks,EVOLVE
288,9fdfeff1_507b8126,ecfdec5a6ed0de56c4a5b1649a17f5f229d9470b,4d32b45c152c4dedcb9d01380f557338c3acb81e,nova/network/os_vif_util.py,450,"ok so your just pulling this out.
that makes sense.
its not need but it makes senes",DISCUSS
289,5fc1f717_0b4b4284,30295f1a141bb10f69f39c7ba453c7162db926b2,a7fae371a7fc48a778b2d632b1b90bf5659eda7d,nova/pci/request.py,227,much cleaner thank you.,DISCUSS
290,9fdfeff1_d35dd248,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/unit/virt/libvirt/fakelibvirt.py,338,"unnecessary var

[Later] Templated on L292-3, shrug.",FUNCTION
291,9fdfeff1_569219a0,a44cae9c1c692811d6e6b29951421f0aeb6af5c5,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/compute/views/servers.py,291,should we also return [] if there is no server group? Since you said it is a required field in api-ref,EVOLVE
292,dfd5e7cf_e19e09b7,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,203,Just use 'inst_compute_node.id',FUNCTION
293,5fc1f717_dd75129a,febf6db11d2e6c5fc023c3b9ce713696411e78fc,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/tests/unit/virt/ironic/test_client_wrapper.py,178,"This is a little surprising. Why does this end up as a list? Is it because valid_interfaces is a ListOpt? It doesn't matter on the ironicclient side, which is happy with either, so it's fine.",DISCUSS
294,9fdfeff1_5a833caa,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/api_sample_tests/test_migrate_server.py,213,"I'm not even sure why we fake these out, the fake virt driver should just noop live migration. But again, that's cleanup that can be done separately later.",FUNCTION
295,9fdfeff1_bfb28305,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/fixtures.py,1328,can we add a test somewhere for vnic_type macvtap.,DISCUSS
296,dfd5e7cf_21c5f15b,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,8306,pci_reqs?,EVOLVE
297,9fdfeff1_8f748837,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,420,nit: don't really need to define this here,EVOLVE
298,3f79a3b5_a67aa876,4eb512aa15f9f80322b2889dfdafaab1b08da7c0,aceef76e03374501811e58d6c2f108c4a5ffddf1,nova/tests/functional/regressions/test_bug_1550919.py,65,"I don't think this is the right uuid to use, this should be a volume id if source_type is volume, and given our cinder fixture you'd want to use this id for a bootable volume:

https://github.com/openstack/nova/blob/8c318d0fb20fdfe0ae8e203245e4d4d6668c8a44/nova/tests/fixtures.py#L1642",FUNCTION
299,9fdfeff1_3d7ff666,f651ebc0ceeca70aba8c0f7e5054f598e491c848,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/tests/unit/virt/libvirt/test_vif.py,616,1,DISCUSS
300,3f79a3b5_cecb201a,1bea334251fd8f1babc04ddb7b732a267d9adfc1,7fa740491e53195021036af69a0ddfde183daef5,nova/virt/libvirt/vif.py,839,"as finally libvirt seems do be behaving nicely
id remove the comment all together as we are simply clearing the MAC we set during plug_hw_veb()

also the ""TODO(vladikr)"" above seems to be outdated:",EVOLVE
301,9fdfeff1_06288c30,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1659,successive?,EVOLVE
302,9fdfeff1_a290feee,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1252,RP,EVOLVE
303,3f79a3b5_59e2ca00,8a5c7b51cd558f5a7b3183d890a1ef5905bf643c,8545ba2af7476e0884b5e7fb90965bef92d605bc,nova/virt/libvirt/driver.py,5153,Also good - the <everything else> is (aarch64 and machine type virt) or <something else>,DISCUSS
304,5fc1f717_de681ff6,391ea45fa36aac2aaad6af21f5c2af2086f393c0,556cf103b22ab6bebecc9d824d6f918cda38fe3e,nova/objects/request_spec.py,540,we still need the above because of existing records for RequestSpecs. Cool with me.,DISCUSS
305,bfdaf3ff_64e20b32,127104732e6c25b97f9547f3368e8e66cd04e27a,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/cmd/manage.py,420,"nit: Add the ""Added in Stein"" comment.",EVOLVE
306,9fdfeff1_14422810,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,623,"Let's say we're detaching a port that had a resource allocation in the binding:profile, shouldn't we null that out in here?",FALSE
307,3f79a3b5_177a6bba,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/scheduler/client/report.py,875,"this works fine.
i personlly would reorder this to

   if rpar:
        refresh_time = self._association_refresh_time.get(uuid, 0)
        return (time.time() - refresh_time) > rpar

  # Refresh disabled (associations ""never"" stale)
  return False

but that is just personal preference and is barely 
worthy of a nit let alone a -1",FUNCTION
308,1f769fc5_fab8f82a,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,195,"you are not properly handling InstanceInfoCacheNotFound:

https://github.com/openstack/nova/blob/357b8b38e88300948bb2e07d1bbaabd1e9d7b60e/nova/objects/instance_info_cache.py#L70",FUNCTION
309,9fdfeff1_d3e4f210,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/conductor/manager.py,709,"Note to other reviewers, this is handled in https://review.openstack.org/#/c/619529/ next in the series.",FALSE
310,5fc1f717_0dce8859,e44ca7a3c655a8ceab827d0dbd58321872a8a519,8c663dbd25a0dab1c2d903efc7cf7fc3d9d07b00,nova/pci/manager.py,184,I get why this isn't out-dented another level but still :(,EVOLVE
311,9fdfeff1_7cfb0e78,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,140,This is nice,DISCUSS
312,9fdfeff1_14e232d6,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/network/neutronv2/api.py,1039,ditto,EVOLVE
313,9fdfeff1_dbb16446,4178fb0d2e4a1033156826fda16ed01f9af8acf4,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/api/openstack/compute/views/servers.py,346,instance.uuid,FUNCTION
314,9fdfeff1_e23302aa,f651ebc0ceeca70aba8c0f7e5054f598e491c848,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/vif.py,578,"I'm a bit eww on this - seems like we could do better by adding a property on the vif objects in os-vif like:

@property
supports_bw_config(self):
    return True

And then VIFVHostUser and VIFHostDevice would override that to return False and we could just check that value here rather than hard-code a blacklist.

I realize that would require an os-vif release and all, but couldn't we do that in a follow up?",FUNCTION
315,9fdfeff1_e63715fe,48d6753d37c0ef1ae5aa1ec9b5b369869ff8905b,ffd81eb107dd04d05f828e9e049320412c576e1b,nova/virt/libvirt/config.py,320,consider renaming this domain_type_emulator_map or domain_type_emulators to make it clearer what it contains/does.,EVOLVE
316,ffb9cba7_9563b8dc,12c3eb2d3a7e7f12a65d304ecfc14fed58d4ea58,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/tests/unit/api/openstack/compute/test_availability_zone.py,92,"Ugh, so apparently the global nature of this stomps on other tests running concurrently. The best thing to do would be to mock just self.controller.host_api.service_get_all *but* availability_zones.get_availability_zones calls that also and with a fresh HostAPI every time. We could / should probably also clean that up by passing in our instance of HostAPI to get_availability_zones.",FUNCTION
317,3f79a3b5_67a3d59d,dd3cb4b4744be87a4227f257cb4d97583768c1a1,7fa740491e53195021036af69a0ddfde183daef5,nova/virt/libvirt/vif.py,839,"digging further, i believe we should not do anything during 
plug_hw_veb() and unplug_hw_veb() in the case of macVtap.

libvirt will set the MAC and vlan for us.
see: https://bugzilla.redhat.com/show_bug.cgi?id=1113474

now, libvirt in case of macVtap sets the MAC on the VF netdev not the VF idx, this means an additional fix will be needed in neutron sriov agent (sriovnicswitch) as today the agent relies on the VF idx mac address to determine if a port was successfully binded.


a hook in neutron to test this: (since nova will not boot a VM as it waits for a port bind event from neutron)

+++ b/neutron/plugins/ml2/drivers/mech_sriov/mech_driver/mech_driver.py
@@ -91,7 +91,7 @@ class SriovNicSwitchMechanismDriver(mech_agent.SimpleAgentMechanismDriverBase):
                       vnic_type)
             return

-        if vnic_type == portbindings.VNIC_DIRECT_PHYSICAL:
+        if (vnic_type == portbindings.VNIC_DIRECT_PHYSICAL or vnic_type == portbindings.VNIC_MACVTAP):
             # Physical functions don't support things like QoS properties,
             # spoof checking, etc. so we might as well side-step the agent
             # for now. The agent also doesn't currently recognize non-VF",FUNCTION
318,5fc1f717_029d9856,749f83568a368343924b0558e51ce1984ad3903e,10fd3782e104cfba50d68e75bac2edc1ad3b262a,nova/tests/functional/libvirt/base.py,51,"this retruns True by default and otherwise returns False
but never non so this should proably return True.

https://github.com/openstack/nova/blob/10fd3782e104cfba50d68e75bac2edc1ad3b262a/nova/privsep/utils.py#L45-L92

This stub is returning None which will never happen and might 
lead to error in the future if supports_direct_io ever does start using None as a return value.",FUNCTION
319,9fdfeff1_7ab72088,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/test_servers.py,2868,ditto,EVOLVE
320,5fc1f717_f6900899,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,7193,Could you explain why you couldn't just use utils.synchronized?,DISCUSS
321,3fce034c_3059e459,ded3e4d9007b3806665bc1b7bec2705bcbe2977e,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/cmd/manage.py,1921,"So this will return None, and boo(None) is False so num_processed are not incremented and therefore num_processed will stay at 0 and that will result in exit code 4.",FALSE
322,9fdfeff1_ee5a6d4e,81e1fff0b45e09a872abc4eea21b5d605a1af597,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/tests/functional/test_servers.py,1216,why not just call this maximum allowed exceeded.,EVOLVE
323,dfd5e7cf_86d153d0,90c350fce0a30e59de753fddd6648513cc326ef7,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/pci/manager.py,301,nit: drop,EVOLVE
324,9fdfeff1_9714daea,72618a4f48ccad8f8c10f83dde2b63f44b903708,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,145,"Throw CONF.host in here for clarity, e.g. ""does not contain this compute service hostname (%s)"" ...",EVOLVE
325,9fdfeff1_96f0aa69,2133e4c0dbd5b3860d922c96f6998ee438f51f37,e3b517b6fd7c470d5cee420fce1456b98495d310,nova/virt/libvirt/driver.py,242,Change to 9.,FUNCTION
326,9fdfeff1_cdadf884,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/functional/test_servers.py,6319,"You never asserted that the port resources were allocated to the server after the server was created, so this could be a false positive correct?",FUNCTION
327,9fdfeff1_34bbb60f,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/conductor/manager.py,711,curious why this isn't done for us in RequestSpec.from_primitives,EVOLVE
328,9fdfeff1_e9515965,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/virt/hardware.py,1573,Both of these methods raise a new exception which is not documented in the nice list of exceptions that *this* method raises.,EVOLVE
329,3f79a3b5_2695d493,454cc5c41c84fbf4b2a192599368215e22afbd81,48ad73e1faf966badab1f0344baad9f4f4055abf,nova/api/metadata/handler.py,102,"is this necessary? But sure, it can save some time if debug not enabled.",DISCUSS
330,5fc1f717_27e3f335,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/tests/functional/db/test_instance_mapping.py,293,"Or just use the ""not in"" test on the object instead of ""is None"" but it doesn't really matter.",FUNCTION
331,5fc1f717_bc44841a,43ce926dccae9e60611b1224ab06dcad8f650fce,b7bd97bc8896346e92d271a443d5ada9ab0074be,nova/compute/manager.py,1392,"would be clearer as just ""migrations"" I think. It took me some thinking to realize that ""mgs"" meant ""migrations.",EVOLVE
332,3f79a3b5_9c4f3bbe,1bb477e778be8c793cd65b74b4a373be50f3420a,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/conf/libvirt.py,437,should we change this also? as we may not automatically active post-copy according to the choice of the new option?,DISCUSS
333,9fdfeff1_5aba12c1,135889d8b5991ec249a31767f5a11fd89908e38f,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/objects/request_spec.py,818,fulfill,EVOLVE
334,5fc1f717_ac15b29d,2b15904afdc4bc7b17c34bc774386dec4eb3aa32,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,43,nit: A line above this would be nice,EVOLVE
335,9fdfeff1_7f73bb81,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,1712,ditto,DISCUSS
336,9fdfeff1_7aa91b22,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/compute/api.py,817,"nit: I feel like we should have a comment here, but maybe it's already obvious. Maybe something like, ""Creating servers with ports that have resource requests, like QoS minimum bandwidth policies, is only supported in a requested minimum microversion.""",EVOLVE
337,dfd5e7cf_7b73c6e8,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/tests/functional/test_conf_max_attach_disk_devices.py,84,"According to the commit message, shouldn't this be 403?",FALSE
338,9fdfeff1_957ea4ad,35ce77835bb271bad3c18eaf22146edac3a42ea0,4c34ab574ef61819a891ac4445a3dbfaed30d498,nova/compute/manager.py,540,"we still have a reference from the RT, but okay.",FALSE
339,9fdfeff1_465482ff,0b92325fe14eda062c78de2c3423ca4834861152,b164aaac1f036455205d2457abc3ae75769bf42f,nova/api/openstack/compute/shelve.py,85,"OK I guess you're checking this because the compute API unshelve method allows unshelving for both shelved and shelved_offloaded:

    @check_instance_state(vm_state=[vm_states.SHELVED,
        vm_states.SHELVED_OFFLOADED])
    def unshelve(self, context, instance):

And in the case of shelved (not offloaded) the port resource requests still apply to the host on which the instance 'lives'. That's potentially racy if the nova-compute service automatically offloads the server while we're doing this check (the _poll_shelved_instances periodic task), but that task should also be setting the task_state so the API would reject the unshelve while the periodic task is running (I'm sure we could still miss that window but it's always existed so nothing new to worry about here).",DISCUSS
340,9fdfeff1_3267e5eb,77726e30792ea101c9ca3eb78beed8fd4d64f13e,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,182,"I think this part could be removed - I'm not sure what ResourceTracker means to an operator - if you mean, ""for this warning to go away"" that's probably a better thing to say.",EVOLVE
341,3f79a3b5_13ae4d30,27b7bad88b531e0869f8e9af9ab951b921c37634,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,nova/tests/functional/test_report_client.py,1250,you just did this on line 1246... :),EVOLVE
342,3f79a3b5_8742df92,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/migration.py,399,"This could be updated, right? Meaning there is now a configurable action and abort might not be what happens.",EVOLVE
343,bfdaf3ff_0489d1c8,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/conf/compute.py,815,Not sure if you'd want to mention that this doesn't apply when attaching volumes to a shelved offloaded instance and is only enforced in that case when the server is unshelved. That might be too much detail for this though.,EVOLVE
344,5fc1f717_e1496e32,67d5970445818f2f245cf1b6d9d46c36fb220f04,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/regressions/test_bug_1815153.py,141,nit: use self.assertFalse(reqspec.is_bfv),FUNCTION
345,5fc1f717_a76a967e,2a8d417913fe32777393e796684d4712e827e2ac,28944d05f3fc415bc294e11202db7810bc354b5a,nova/tests/fixtures.py,2234,"I don't really think we should merge anything like this. Any difference in how these files get laid out on disk could cause this to fail to detect properly. In a frozen environment (not sure if the win32 people run like that or not) then this is also likely to be different.

However, the fact that we need to do this is part of why I'm highly concerned with just doing this globally -- it's a pretty core piece of functionality that everything we import into our process will choke on. Maybe in obvious ways like this, but maybe not. What if I have a polling loop in some library that wraps a sleep and a poll and catches ValueError for the poll? That library will behave very strangely and non-obviously, only in these tests and for a very obscure reason.",DISCUSS
346,9fdfeff1_92038d42,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/virt/fake.py,863,"I don't know if you can use self.flags here or not, but if you can, then you don't need the CONF.set_default (although under the covers self.flags just calls CONF.set_default).",FUNCTION
347,9fdfeff1_c0cf5e55,0ea52f6a2cc1f8474b4d2a835a2559434172d663,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/vif.py,445,im pretty sure this will not work for vhost-user,FUNCTION
348,9fdfeff1_92a68453,91c6e0cc0194f16e579dfa38d29b19da4671c413,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,nova/conductor/manager.py,1262,"hmm, is this call to placement necessary? don't we already have all the allocation information in the Selection object?

[Later] Hmm, I see we're just storing the allocation_request as a serialized string in the Selection object:

https://github.com/openstack/nova/blob/af78b13c24d4abf393d17ac57e9135204ef12b73/nova/objects/selection.py#L40

We really should pass the actual allocations information that were consumed in claim_resources() instead of requiring the conductor to re-fetch that information... but, future work I guess. :)",DISCUSS
349,5fc1f717_ec5587fb,60b84974b05ebe4913009890bb47536f7640b7d5,6ebb2c4cae65cb437e17a8c02fe5174a9825d8e0,nova/scheduler/client/report.py,1880,As per the comment in the bug report this should be 'debug',EVOLVE
350,9fdfeff1_4012a55a,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/tests/unit/scheduler/client/test_report.py,2884,assert_getters_not_called,EVOLVE
351,9fdfeff1_cb3ddbbb,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,2529,"This is redundant with the functional test, I don't think we need both (just drop the unit test).",EVOLVE
352,5fc1f717_b345b245,91e700426b2ce5160d0877576c7265b983a2b29b,4f9bc724010f0c935bf83a6d19bdd805e86b7086,nova/conductor/manager.py,1290,"Yeah so this is issue #1 above - if that's the case, we'd blow up by the time we got here because allocation_request will be None.

>>> import json
>>> json.loads(None)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python2.7/json/__init__.py"", line 339, in loads
    return _default_decoder.decode(s)
  File ""/usr/lib/python2.7/json/decoder.py"", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
TypeError: expected string or buffer


So if you leave this in here, you need to check host_selection.allocation_request before trying to deserialize it.",FUNCTION
353,3f79a3b5_ce153240,364724ba6f7442cbaedcb270498cad549a571449,d1e38f06bb5282dd9bf81d979926a0ebbfd93caa,nova/tests/unit/image/test_glance.py,192,"Sorry, where is this used?

[Later] Actually, I don't see where anything except image_fixtures['active_image_v2'] is being used. What am I missing?",DISCUSS
354,5fc1f717_9d42060f,4cd89c138afaf97cb42743a38c407399bc3fd9c4,93d7b97b77aa50ca3876fde8dc09c1be38ff1a61,nova/cmd/manage.py,105,Looks like this has not been used since the flavor commands were removed.,DISCUSS
355,9fdfeff1_9255cd52,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1363,Is this TODO also meant to cover https://review.openstack.org/#/c/569459/67/nova/network/neutronv2/api.py@3234? Not all move operations use this bind_ports_to_host code yet (only live migration does).,DISCUSS
356,9fdfeff1_b629a9e6,34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/objects/request_spec.py,95,What would have helped (assuming I would have noticed it) is if this had a big NOTE on it stating that it currently only houses bw-related request groups. Can you do that in a fup please?,EVOLVE
357,9fdfeff1_7ef36ae8,cc16de04e8dc21a666ddc414cf80a94f30e4d424,ac1fafb84c94ed9f8e610c7c3e152e38aef844ed,nova/tests/unit/compute/test_compute_api.py,6428,"This is removed per comment at [1]

[1] https://review.openstack.org/#/c/630721/4/nova/tests/unit/compute/test_compute_api.py@6430",FALSE
358,3f79a3b5_1784d956,e8ce4d095eee87c10e538b18a8f4b00a36d1c958,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,1080,"Apologies if this is obvious or has otherwise been explained already, would there be any harm in removing this conditional and letting this workaround also take care of the revert resize bug?

I know we have discussed the possibility of a failed start and cleanup in that case, but thinking about the current code without this patch, it does delete the instance files during a failed start regardless (that is, the current behavior is to cleanup instance files if shared storage, thus no change for the worse).

Rationale being, if we have a gap in cleanup for when we don't have migrate_data.is_shared_block_storage set, that applies to evacuate and resize and this patch seems like it's closing that gap.",DISCUSS
359,9fdfeff1_19cd46b6,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6248,Not needed.,FUNCTION
360,9fdfeff1_ae2d92a9,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1063,Include the multiplier_name value in this message.,EVOLVE
361,3f79a3b5_c7c84577,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/api/metadata/password.py,74,There is no test coverage for this.,FUNCTION
362,5fc1f717_9493ca00,88c20a168ee89293751bd22ad621d1d8eb305693,75d4ba6752b0bebe6643d0efcdfcebdca2828a7c,nova/tests/functional/test_json_filter.py,50,"This is inspired by Eric comment, so...we should set 'host_subset_size' to 1, otherwise, we still have chance to get the host2 without JsonFilter due to the random choice.",FALSE
363,9fdfeff1_c00a9a24,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/servers.py,1102,"same, like how we handle show_keypair",DISCUSS
364,5fc1f717_671092a9,4ffaa7c6742951469431c86b63aac6d4393db702,4f9bc724010f0c935bf83a6d19bdd805e86b7086,api-guide/source/conf.py,289,"I'm surprised we need this now? We've already referenced neutron docs from the nova docs, e.g.:

http://git.openstack.org/cgit/openstack/nova/tree/doc/source/admin/pci-passthrough.rst#n21

(later)

Oh this is the API guide, I keep forgetting.",DISCUSS
365,9fdfeff1_ad01736c,de0d24bb4c135cc3cf7c9efbd312ac9e35e04223,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,5628,"nit: could you do this via a with statement insstead.

inventing the new fuction seam overkill",FALSE
366,ffb9cba7_3ec1ac55,186b37f8237010b5abd4ab4ad208a9ea400f8819,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/availability_zones.py,128,A simple unit test would assert that we don't call service_get_all if enabled_services is passed in.,FALSE
367,9fdfeff1_f47bfbf0,39f7e163c027a7f561a07651484b4bef07035174,fea7a04ca9ebd6bf7b608d2815a5e845465ae178,nova/pci/request.py,189,"Once you need to do this, I think it's a sign that you should just use an if statement. Alternatively, and I think I might have suggested this before:

    vif_pci_dev_address = vif.get('profile', {}).get('pci_slot', None)",FUNCTION
368,9fdfeff1_d2c64c4a,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/tests/unit/objects/test_request_spec.py,1011,Ã¢Å“â€,DISCUSS
369,9fdfeff1_4f7a20f1,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,2514,This isn't used.,FUNCTION
370,9fdfeff1_d8a0e194,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,740,an instance,EVOLVE
371,bfdaf3ff_d73059eb,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/functional/test_conf_max_attach_disk_devices.py,110,nit: I think you can just six.text_type(ex) this to avoid the internals.,FUNCTION
372,9fdfeff1_9b30bca0,12c38291b85a373905bd754bd210c7d1cac53662,d9bd5b1377acf4468c89422fa471de6c8325d775,nova/compute/api.py,2536,all_tenants,EVOLVE
373,9fdfeff1_fae3cbd6,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/conductor/tasks/live_migrate.py,213,are,EVOLVE
374,9fdfeff1_a58e5f24,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/objects/instance_pci_requests.py,136,"Eww I wonder when we can remove this, but I supposed we'd need a blocker migration first...",EVOLVE
375,3f79a3b5_4e5574ec,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,3322,change not needed if you have _checks_for_create_and_rebuild() call _validate_flavor_image(),FUNCTION
376,5fc1f717_8e2bb7e9,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4554,Use self._create_flavor().,FUNCTION
377,5fc1f717_503940ef,47287f6f945beba30c23e698b2bdae09a44736f9,4f9bc724010f0c935bf83a6d19bdd805e86b7086,api-guide/source/conf.py,290,not sure how it will create a dependency with those projects but okay.,DISCUSS
378,5fc1f717_c26c9dd1,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,492,I think something like this needs to be the else block to the condition on L522 now.,FUNCTION
379,9fdfeff1_be604e37,594cc40c2ae88da36e6cc69f79e7781a32b60d4a,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/tests/fixtures.py,849,are these backslashes necessary?,EVOLVE
380,3f79a3b5_f43d02ba,1f10b84a8690c7bf0146e180329d3dffcfcc4730,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/conf/compute.py,806,"Perhaps adding a small note to inform operators that the number of disks supported by instance depends of the bus used, and perhaps we could refer the hw_disk_bus option.",EVOLVE
381,9fdfeff1_2cbfaf61,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/tests/functional/db/test_instance_mapping.py,290,"Good comment, I was doing this tracking in my head...",DISCUSS
382,ffb9cba7_31a6bdc3,12c3eb2d3a7e7f12a65d304ecfc14fed58d4ea58,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/api/openstack/compute/availability_zone.py,66,"ok so we look up the enables service and pass it in
os that here https://review.opendev.org/#/c/636947/3/nova/availability_zones.py@129 we dont have to look it up again.",EVOLVE
383,ffb9cba7_bb1e0e0a,13278be9f265e237fc68ee60acfacaa1df68522e,b7a018f1265d9e0354e26822d32cbdc789819c35,nova/virt/ironic/client_wrapper.py,117,"https://docs.openstack.org/keystoneauth/latest/using-sessions.html#endpoint-metadata says there is also a min_microversion kwarg, why don't we use that? Or is ironicclient already dealing with that because of os_ironic_api_version above?",DISCUSS
384,5fc1f717_cd7589ce,38f2ce549ce4b21d5085824df701f9d2392b5604,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/cmd/status.py,207,"thanks for the detailed explanation, it helps understanding why you use objects.",DISCUSS
385,9fdfeff1_cfa3709d,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,445,"Can't this just be self.sg_uuid? No need to use a regex when we know what it's going to be. Also, if you really needed do, just use the %(uuid)s variable in the template for which we already have a common regex:

https://github.com/openstack/nova/blob/eb93d0cffd11fcfca97b3d4679a0043142a5d998/nova/tests/functional/api_samples_test_base.py#L409",DISCUSS
386,9fdfeff1_8a42da67,ccc6ae9e649840e6b3e654a71f3b77103e6e5de2,b05d0b30b38a71a6b4ab607e2c6a2e8d5b97d629,nova/pci/request.py,199,"unlikely, but ComputeNode.get_by_host_and_nodename() can fail...",FUNCTION
387,9fdfeff1_eda55c04,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1689,allocates,EVOLVE
388,3f79a3b5_ad348afa,cbd45d0c2ea8100a76030a003688a9ae6210b6c8,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,nova/virt/libvirt/migration.py,380,align this with the other args above,EVOLVE
389,5fc1f717_f7964b3e,40f6672f53794b563f4c7e27ede7b59a1d63c14a,73aaead294b9df412305abb1cb01aac95477bcc1,nova/compute/api.py,3498,"Aren't AZs mapped to placement aggregates at this point? So we could query placement - from wherever, whenever - to get the proper value?",DISCUSS
390,9fdfeff1_616c2f36,df494543dad41ae8c4526d16dcd024465c0303af,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,nova/pci/manager.py,310,ditto,EVOLVE
391,3f79a3b5_4b40f733,5cdb825394f3015ef4b1224eb7d9f55633d217e9,801ef1adca667ecdf243464b083282418d5987e4,nova/scheduler/client/report.py,801,so we merge inventory refresh also with association refresh.,DISCUSS
392,9fdfeff1_93d2f7d0,da34a5f05230c4bfcc828a223e1ff8434b05ce09,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/tests/unit/virt/libvirt/test_driver.py,7532,Add assertions for mock_attach_encryptor and mock_get_volume_driver.,FUNCTION
393,9fdfeff1_b411f306,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,774,partition,EVOLVE
394,9fdfeff1_2d7e04e4,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3616,same,EVOLVE
395,5fc1f717_5b5c1818,a84a40676dcb12608363210072049bf01d720073,7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4,nova/tests/unit/virt/libvirt/volume/test_quobyte.py,65,this should really be the first method defined (or second if you had a setUp),EVOLVE
396,9fdfeff1_32858e08,a152f0922e97a5f6e6dde36fc0b5d18bdfb04e1f,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,211,This is old now.,EVOLVE
397,5fc1f717_01ab5ad6,67d5970445818f2f245cf1b6d9d46c36fb220f04,29e5b0ad7bde210f95885656768f0480d06882c0,nova/objects/request_spec.py,613,"Blech, more stuff I'd like to make generic, but we don't need to in this change (which needs to be backported).",FUNCTION
398,9fdfeff1_9ecbaea3,cc16de04e8dc21a666ddc414cf80a94f30e4d424,ac1fafb84c94ed9f8e610c7c3e152e38aef844ed,nova/network/neutronv2/api.py,527,"This is correct but it reads rather weirdly and took me a few passes to grok. Not sure how I'd reword though, tbh.",EVOLVE
399,9fdfeff1_857ad222,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,546,"nit: you could add, ""; enforces the image status is 'active'""",EVOLVE
400,5fc1f717_9cd96c84,24fe74d126f23bea56c87524b1005a2aaacb870c,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4568,same,FUNCTION
401,3f79a3b5_b91e7e0c,8a5c7b51cd558f5a7b3183d890a1ef5905bf643c,8545ba2af7476e0884b5e7fb90965bef92d605bc,nova/virt/libvirt/driver.py,5150,So far so good - the original if has num_pcie_ports and <everything else>,DISCUSS
402,9fdfeff1_cad11efd,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/unit/virt/libvirt/fakelibvirt.py,343,Wouldn't it be better to use self.devices[device_name] here so KeyError is raised if a bogus device_name is passed in?,EVOLVE
403,9fdfeff1_d7f7c2d2,9ba910bb539b0172bab899852692a49d30645a14,a5d6833d77c961ea75488f0992b91d3166424381,nova/compute/api.py,814,"OK so as of this change, this variable is unused. It gets used later here:

https://review.openstack.org/#/c/567268/46/nova/compute/api.py",FUNCTION
404,5fc1f717_057cbd1e,c29f7026ca17f3419579bef2f8e0e534dad4af27,926e584136e7dce59f32065292aa4eb8120f628c,nova/compute/resource_tracker.py,990,"could remove this too, but meh",EVOLVE
405,9fdfeff1_eb75b501,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2165,"I'm a bit afraid of this convention be just an implementation detail instead of a global regex as a main attribute, but meh.",FUNCTION
406,9fdfeff1_2cd18158,e5e929f019c05fa57f6b216855b9246b7a5f8d48,9cc0a58cf1765bcd55b5d10f66b634df06914c14,nova/tests/fixtures.py,1254,"OK this matches:

https://review.openstack.org/#/c/583288/7/nova/tests/fixtures.py@1295",FALSE
407,9fdfeff1_d1b76920,695dfc59f2adea9995c138a9694e6f4368fbf185,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/objects/request_spec.py,704,"nit: set arith could be used: 
like set(provider_traits[rp_uuid]) & set( group.required_traits) != set( group.required_traits)

BTW it's good to have this list as sets initially.",FUNCTION
408,9fdfeff1_190f8688,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6665,"And this also isn't bouncing on that lock, huh?

Need to get to the bottom of this.

[Later] Figured it out. eventlet.monkey_patch replaces thread with eventlet.green.thread. The former blows up when you try to copy it; the latter does not. And the latter is doing the right thing by creating a new semaphore. http://paste.openstack.org/show/745119/",FUNCTION
409,9fdfeff1_79c33239,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6305,"This could be safer as:

 if rp_name.startswith(root.name + '_'):

Unless we can predict how many underscores are in the root.name or parent_device portions of the rp name (or otherwise ensure a deterministic format), in which case we could split() it and get it perfect.",FUNCTION
410,9fdfeff1_705e0a77,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/api/openstack/common.py,560,didn't @dansmith want to only have a single microversion and not have a microversion for the spawn/greenfield stuff and another microversion for the move operations?,DISCUSS
411,bfdaf3ff_248415b1,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/exception.py,2358,nit: period,EVOLVE
412,9fdfeff1_a56be8b4,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/tests/unit/compute/test_compute_api.py,6430,"I'm not sure we really need the unit test when we have the functional test, or vice-versa.",DISCUSS
413,3f79a3b5_70fe053a,b01f2746f4c1de3895a0a701d064df7fb902e464,c64b03d218c4d05b9db47eaf7660cdab9baa6468,nova/tests/unit/compute/test_compute_mgr.py,6440,This is still mocking something that's private.,FUNCTION
414,9fdfeff1_b3e7fb46,430baa37bf961e5a5bc1fa1956e13c52000150fa,4a92b338d94355ea06337433fd3d79c352fce152,nova/db/sqlalchemy/api_models.py,146,ok so by default its NULL for now. But like your note says you will fix this after the migration gets removed.,FALSE
415,3f79a3b5_e81f7fb6,1abdb4ca22436c5eabadeab46b1237154c9cca92,6380226863ecfcba2792c8ada3b2b92503b1d8ec,nova/tests/functional/regressions/test_bug_1764883.py,87,"Yup this was made a list later:

https://review.openstack.org/#/c/525242/17/nova/tests/functional/integrated_helpers.py",FALSE
416,9fdfeff1_af49fa66,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/unit/compute/test_compute_mgr.py,6689,calculated,EVOLVE
417,3fce034c_fc3b2a99,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/tests/unit/objects/test_instance.py,449,"Weird that this was here in the first place, as it's the default.",FALSE
418,9fdfeff1_2a00ea65,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/unit/virt/libvirt/fakelibvirt.py,1541,raise?,EVOLVE
419,9fdfeff1_20e1a12b,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/compute/manager.py,8348,"As a random aside, is there any reason to stick these functions at the bottom of the file as opposed to immediately after/before their caller?",EVOLVE
420,9fdfeff1_12596afd,deef31729bd54f3747b7adba4132f148559c2242,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/scheduler/client/report.py,310,get_provider_uuids_in_tree,EVOLVE
421,9fdfeff1_8e1c016b,abe5a4b64dcf678903d3db555caa2fb7f1fa01ee,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/compute/views/servers.py,293,server_groups,EVOLVE
422,3f79a3b5_d341eb09,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,1153,"docstring for this param

Also, this is blowing up several things because this is supposed to have a specific signature. I think what you'll probably need to do is pass this through as a kwarg instead of a required argument.",EVOLVE
423,3f79a3b5_aea481a5,ef0a50df52abef022d67fa20a1bbba9bb23ad6c2,ad31f5d66d6df25555c2f1c5653ac754790f06df,nova/cmd/manage.py,1411,"This might make the code reading more confusing, it the line is too long, you can probably add space in the next line",EVOLVE
424,9fdfeff1_26e9e7e4,570ad369928c296aac59a3e81ceb45a4ff2e19a7,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,nova/tests/functional/test_report_client.py,306,No need to keep this? Does something else test the fix for bug 1746615?,DISCUSS
425,5fc1f717_3d10404e,5418e8ea6688ca4c717d8b511720a20047656a1f,51aa230d2f0afe8a8fa9c5fb58f187ef1b243371,nova/tests/fixtures.py,2011,Ã¢Å“â€,DISCUSS
426,3f79a3b5_f43298eb,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/workarounds.py,203,"Add the normal ""Related options"" section. I can think of at least two:

* compute_driver (libvirt)
* [libvirt]/images_type (rbd)",EVOLVE
427,9fdfeff1_462ec292,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/tests/unit/objects/test_request_spec.py,1391,noyce,DISCUSS
428,3fce034c_a42b2fe9,acd64d1d805ad36004bc4c23d74ed7490bd43857,02b26457f3c5773973f374f39e069d2a854e99f6,nova/scheduler/host_manager.py,703,"I'm pretty sure you could rewrite this as something like:

nodes = next(nodes for nodes in nodes_by_cell.values() if nodes, objects.ComuteNodeList())

There's probably some missing parens in there, but the idea is that next  can provide a default instead of handling StopIteration",FUNCTION
429,9fdfeff1_2aa5ee47,ccc6ae9e649840e6b3e654a71f3b77103e6e5de2,b05d0b30b38a71a6b4ab607e2c6a2e8d5b97d629,nova/pci/request.py,216,"you could make the above more readable using a combination of short-circuiting and different variable names:

 try:
     cn_id = objects.ComputeNode.get_by_host_and_nodename(
         context, instance.host, instance.node).id
 except exception.NotFound:
     LOG.warning(""expected to find compute node with host %s""
                 "" and node %s when getting instance PCI request ""
                 "" from VIF"")
     return None
 vif_addr = vif_pci_dev_address

 # Find PCIDevice associated with vif_pci_dev_address on the compute
 # the instance is running on.
 found_dev = None
 for dev in instance.pci_devices:
     if dev.compute_node_id == cn_id and dev.address == vif_addr:
         found_dev = dev
         break
 if not found_dev:
     return None

 # Find PCIRequest associated with the given PCIDevice in instance
 for req in instance.pci_requests.requests:
     if req.request_id == found_dev.request_id:
         return req

 raise exception.PciRequestFromVIFNotFound(
     pci_slot=vif_pci_dev_address,
     node_id=compute_node.id)",EVOLVE
430,5fc1f717_33dfd03b,74ef3a67096ca8203cd344e4ee32c71ab340ab1b,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,550,"nit: would be good to have a docstring on this method to say it's only used for build_instance reschedules, not to be confused with resize reschedules.",EVOLVE
431,9fdfeff1_731bc67f,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,51,exist,EVOLVE
432,3f79a3b5_ffed9ab8,1a5ed00e358e268c74697c41e045355e8a983fa7,1abdb4ca22436c5eabadeab46b1237154c9cca92,nova/tests/functional/regressions/test_bug_1806064.py,61,"We should reset this:

self.addCleanup(nova.tests.unit.image.fake.FakeImageService_reset)",FUNCTION
433,9fdfeff1_f671df78,be7e417bc7df90b4f062a1fd81cd4d53dda37eeb,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,2515,"you can use a real InstanceGroup obj with the uuid assigned value. And in the line 2530, when you use the decorator, you probably can create that object directly in the prarameter.",FUNCTION
434,9fdfeff1_f5b74c20,8d9c231632605a54c6c8b262cf4e510c1a215aea,b0f795e512416e3934a7e2663f22998f62248cba,nova/conductor/manager.py,681,"I wasn't actually asking that we handle this in this follow up - I would actually prefer that we deal with this separately because claim_resources could also fail and we don't set the instance to ERROR state nor cleanup allocated networks. As I said in the original review I think we should separately split out the while loop code and then we can deal with error handling in isolation, but that's a bigger refactor.",EVOLVE
435,9fdfeff1_9201dab2,deef31729bd54f3747b7adba4132f148559c2242,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/scheduler/client/report.py,712,"for reviewers, *this* spot right here is the call to placement that we are reducing in this patch. This is the GET /resource_providers?in_tree=<UUID> referred to in the commit message.

With this patch, we no longer make this call when the ProviderTree has a fresh record of the provider (which is the case in all cases except when initially creating the compute node).",FALSE
436,9fdfeff1_e3cb5ea2,ecd0d0c3572f77b844e5dd9657204d23ada12318,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/compute/multi_cell_list.py,249,"I would have just put this as a thing before **kwargs in the definition so you don't have to pop it out and it's clear we don't pass it downstream, but this works of course.",FUNCTION
437,9fdfeff1_c3253fb0,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/compute/manager.py,6829,Why do we need to do this here and yet not when freeing above? Is there a potential race condition that this prevents. You've said we don't want to rely on the periodic job but not why,FUNCTION
438,1f769fc5_7a0f08e1,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,206,"NetworkInfo is a list of VIFs, not ports.

This really should be:

 nw_info = info_cache.network_info
 cached_vif_ids = [vif['id'] for vif in nw_info]
 db_vif_ids = [vif.uuid for vif in vif_list]

 if cached_vif_ids == db_vif_ids:
     continue
 ...",FUNCTION
439,5fc1f717_af84dab1,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,703,"What if we have multiple nodes, i.e. the admin specifies a baremetal compute host but not the node, and there are multiple compute nodes mapped to that host - do we raise or something to signal that we still have to do the unlimited GET /allocation_candidates call?",DISCUSS
440,9fdfeff1_b3305b09,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/unit/api/openstack/compute/test_evacuate.py,507,likewise,FUNCTION
441,3fce034c_4e906c4f,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7239,"This is a bit gross if there are other drivers that need to avoid this kind of behavior - a new method on the driver interface might be better, but I'm not sure what you'd call it.

Also, this will completely side-step the heal task for baremetal instances which I don't think is what you want, what you really want to avoid is the call to self.network_api.setup_instance_network_on_host on L7311 which is the regression with https://review.openstack.org/#/c/603844/ so why not just restrict the check to that conditional? And add a comment about why baremetal instances are special here.",FUNCTION
442,9fdfeff1_08b6c98b,f548c91da693aa3ce1b4277c250601f799db9512,78d6aca9a6cfb25ac180e28dc519fb76d22a2314,nova/compute/manager.py,4634,"yep this look like a pretty clean refactor.
behavior should be identical before and after this patch
but you have pulled out the common code.",DISCUSS
443,3f79a3b5_f14e34c1,bf45bd89a104ddf108fcf6676c59195878d432a8,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,416,will be used to determine,EVOLVE
444,bfdaf3ff_b9257fc4,1e7cc87b6608907b8e315342178d1cc2ab9001e9,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/unit/objects/test_compute_node.py,475,But not here?,DISCUSS
445,9fdfeff1_0b176353,b164aaac1f036455205d2457abc3ae75769bf42f,3730bd079104ad14f6992ad55cf8643911c916ab,nova/tests/functional/test_servers.py,5560,"Are you using the latest microversion? Because otherwise onSharedStorage is required.

Oh right ProviderUsageBaseTestCase uses the latest microversion by default.",DISCUSS
446,9fdfeff1_adebe675,d8f6882f547bd1a92fb38de5aed287d56bf8b233,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/api/openstack/compute/servers.py,1071,oh...my god..can we put them into a common list for create and rebuild and resize method?,EVOLVE
447,9fdfeff1_f17ae074,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/compute/api.py,950,"Per my comment on the patch before this, I expect this is the only place we actually create instance mappings, and thus the optional-ness of it in the object implementation is to reduce unit test fallout, not actual functional code.",FALSE
448,9fdfeff1_2033d415,0b56cdeb8a438246d45cbf5117f3cbbf4ba9355d,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,130,"This is a really odd thing to raise out of _from_db_object(). We've basically said ""here, I found this in the database, convert it to an object"" only to have this explode and say ""that thing doesn't exist"". Right?

So, I agree that this needs to explode, but this is probably not the best exception to use. Presumably whatever this is has to be handled in the thing that does the bulk query of mappings...is that get_counts()?",FUNCTION
449,9fdfeff1_b1e3c533,c2331d692445796d604d27d2388309f2eb545d31,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/api/openstack/api_version_request.py,175,don't see you have api-ref or tests on this case?,DISCUSS
450,9fdfeff1_21bd63b6,1bb006516ecf68c4d43884780dfef748da8cfb46,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/virt/libvirt/driver.py,6308,"We should log that we expected to find the pgpu in a child provider with name %(rp_name)s. If this exception winds up in the user's face, do it as a separate log message; otherwise include it in the exception text itself.",EVOLVE
451,ffd0ebdf_4813b867,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,205,same nit,EVOLVE
452,9fdfeff1_110f1f2f,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/weights.py,79,"Since this is an interface change, and we support loading out-of-tree weight classes, it would probably be good to send a short email to the mailing list to let operators know we're making this change. You can link to the spec as well for details.",FALSE
453,3f79a3b5_51ae08a0,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_driver.py,17152,"A comment here might have been nice: destroy_disks=False because check_instance_shared_storage_local() in the libvirt driver returns None when the image backend is rbd, which is ultimately what we're checking in init_host.",EVOLVE
454,5fc1f717_933516dd,91e700426b2ce5160d0877576c7265b983a2b29b,4f9bc724010f0c935bf83a6d19bdd805e86b7086,nova/conductor/manager.py,1286,"Two things here:

1. I think I noted in the original review that while all in-tree scheduler drivers are using placement now, there is the chance that out of tree scheduler drivers are not, which would mean the Selection.allocation_request is None. However, you can only get here if the check above passes meaning someone is using a request which requires placement, so they can't even make that type of request unless placement is involved, so it's probably safe to assume if we get this far, the scheduler is using placement.

2. The other thing is allocation_request is a PUT /allocations/{consumer_id} request and while PUT and GET have the same format, they could technically drift at some point which could break this code, but if that happens we have the Selection.allocation_request_version value to massage the data back to the format we need. I'm not sure if you want to leave a note about this little caveat or not. It should be pretty rare if this breaks at some point so maybe a note is asking too much.",DISCUSS
455,3f79a3b5_4dbca8d4,8e2c0faf1abc3727b8bfeba3180d7464f9476345,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/compute/views/servers.py,282,is this necessary? maybe just check version is enough?,DISCUSS
456,ffb9cba7_e7e1272c,76714f38932177b72c38bf0b7cb29045692bc789,74cefe4266a613d4c2afbb0c791e16eb7789aef4,nova/compute/api.py,275,name this kwarg,EVOLVE
457,9fdfeff1_908b6e1d,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/api/openstack/common.py,546,Ã¢Å“â€,DISCUSS
458,9fdfeff1_b3ee1b89,da34a5f05230c4bfcc828a223e1ff8434b05ce09,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/tests/unit/virt/libvirt/test_driver.py,7560,ditto,FUNCTION
459,3f79a3b5_7e1ca1c2,82884c897cac0fc0cb21de8838e02ee806e223d6,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/objects/block_device.py,380,"""cleanup"" is kind of an odd fit here, maybe ""reset"" is better? You should provide a docstring either way.

I'm altogether not sure I like business logic like this in the object itself anyway - if this is only called from one place, couldn't we just do this there?",EVOLVE
460,3fce034c_0118c7d0,f6667b05d2146c928468021e5569a34215e93020,e25d59078e61fe9f925dbef53dfe88e575d34dab,nova/tests/unit/objects/test_request_spec.py,989,And this works because in_tree has a default value of None and is set by the __init__ method.,DISCUSS
461,9fdfeff1_68c5ec3c,1c6fdc9aecba310630b6e74e861d31a4c3be1bed,a37a035c9d359b29fed6ea08bc99b93e51164e61,nova/api/openstack/compute/attach_interfaces.py,90,Also one more unittest case for no vifs.,FUNCTION
462,3f79a3b5_18c0d34a,4a5da5a3b471bb5592d0a97e93bb69152e6447c0,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/privsep/qemu.py,62,"Please could you add compression as an argument to images.convert_image() rather than encoding it here, making this behaviour explicitly controlled by the caller.",EVOLVE
463,5fc1f717_fa8b15bd,88c20a168ee89293751bd22ad621d1d8eb305693,75d4ba6752b0bebe6643d0efcdfcebdca2828a7c,nova/tests/functional/test_json_filter.py,35,any reason for overwriting the default 2.latest to 2.1 here ?,DISCUSS
464,ffd0ebdf_556ca807,9626b4c2b738ef1340dc7c550e9e941a0cbf626c,357b8b38e88300948bb2e07d1bbaabd1e9d7b60e,nova/notifications/objects/instance.py,254,nit: It can be 'instance.name'.,EVOLVE
465,9fdfeff1_ca75549a,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,828,backporting,EVOLVE
466,9fdfeff1_97285a97,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,733,"To support aggregates, we would need another arg, presumably a mapping of rp_uuid to list(agg_uuids). Alternatively, this arg could be a thing that can hold both pieces of information. Seems ProviderTree would fit the bill nicely; can we reuse that?

(Note to self: to support forbidden traits, we don't need extra information in this arg; we use the traits from here against the forbidden traits from the request groups.)",DISCUSS
467,5fc1f717_01cfa3b0,27128fc7cff1bbff20c813cb6c1a1e8af889e431,2384c41b781a84de98d0932f44d4b3c544c3fe3d,nova/virt/libvirt/driver.py,6051,PciDeviceNotFoundById would be a lot better than ignoring all exceptions here.,FUNCTION
468,9fdfeff1_ebb3ff08,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/api/openstack/common.py,576,"Could just return True once you hit a port:

for port in ports:
   if port.get('resource_request'):
      return True
return False",EVOLVE
469,9fdfeff1_c6f7768c,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/tests/unit/objects/test_request_spec.py,1398,than,EVOLVE
470,9fdfeff1_3c734618,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1707,"hmm, the allocations for the consumer (which is what allocation_on_rp contains) is *not* the inventory on the provider. Rather, it's simply the amount of that resource class that has been allocated to this consumer.

So, I think the error message here should instead be something to the effect of ""attempted to remove more resources from allocation of resource X against provider Y than were allocated to consumer Z"". Does that make sense?",EVOLVE
471,9fdfeff1_6ad7d224,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6247,nit: should probably document this in the docstring although I guess there were already cases in this method of raising this.,EVOLVE
472,9fdfeff1_94b8cbe5,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,337,this should be done after binding the ports.,EVOLVE
473,9fdfeff1_0366d552,5fc1f74cd2ec2f42b227086e87bd247059804064,8bf886744941a564d9522fe98658640473c44c0a,nova/api/openstack/compute/servers.py,215,Let's get Dan's opinion but I kind of prefer what you suggested in the other patch that we continue to pop this as before but pass an explicit kwarg to the compute API - that way there is less funny business with checking the search_opts for the all_tenants filter - I like the more direct approach.,DISCUSS
474,3f79a3b5_70317009,a5ff0a9d56f96a82102d64476500bd528fa50a49,f49bcd7782ac95ceb3a73dd49cd2986e97ef69f4,nova/virt/libvirt/driver.py,1075,Nope. This is going to execute during _hard_reboot().,FALSE
475,ffb9cba7_09aa73d3,8aae3e39e58a05ed50b891aeae261641f544ad1f,a40c7f3e8d06f0bc8918a25b60f73ec2c18add05,nova/compute/api.py,639,so is this whole block of code irrelevant now if _validate_flavor_image_nostatus() is no longer going to be called for volume-backed instances?,DISCUSS
476,5fc1f717_e2d702bf,bf7fccab6f021f96d008cc0be08d1777b9d824e1,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/compute/api.py,1496,it would be nice to have a unit test to prevent a regression in the future,FALSE
477,9fdfeff1_809d3f67,570ad369928c296aac59a3e81ceb45a4ff2e19a7,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,nova/compute/resource_tracker.py,974,"Why not just retry the _update_to_placement()? The others don't retrieve any fresher things from anywhere, do they?",DISCUSS
478,3f79a3b5_4b28067e,6e5b7fbf62c9079d1ba56ae2488eeedfc7ba3dec,47bcc39cd633cdbdca97bf8b3d94bccd127b940f,nova/context.py,443,I feel like we might be losing some detail here that is pretty useful in a real failure. How about at least catching NovaException for the not-log case and continuing to log for the anything-else case? I was actually kinda expecting to just catch NotFound and maybe some other likely things for the not log case.,FUNCTION
479,9fdfeff1_58932d50,fc962b62d4202d76f2c04166c97ace9d31c21e18,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/functional/db/test_virtual_interface.py,135,"You could just do:

  instances[i].destroy()",FUNCTION
480,5fc1f717_e7b09e8e,569775ce0a7ffc693ef12dba1a867a690fac088c,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,nova/compute/api.py,573,There is no image_id parameter on this method.,EVOLVE
481,9fdfeff1_38de6911,fc962b62d4202d76f2c04166c97ace9d31c21e18,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,184,"Hmm, I commented this out, ran the tests and nothing failed.",FALSE
482,9fdfeff1_ce2a568f,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/affinity.py,56,"It might be cleaner if you rebase on top of this which removes some of the old code in here:

https://review.openstack.org/#/c/628205/",EVOLVE
483,3f79a3b5_90fba146,b01f2746f4c1de3895a0a701d064df7fb902e464,c64b03d218c4d05b9db47eaf7660cdab9baa6468,nova/tests/unit/virt/disk/mount/test_api.py,32,Ditto.,FUNCTION
484,9fdfeff1_dfa9c223,5158b509703a111c3f1cd5dde05dfa5e50a81f20,16dda2774801cb829ca849506f077edb95e85253,nova/tests/unit/virt/libvirt/test_driver.py,18042,Put the new test closer to these existing tests.,EVOLVE
485,9fdfeff1_127106e1,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/tests/functional/test_servers.py,1230,nit: should probably update the docstrong on this in the ComputeDriver class to note that it can raise TooManyDiskDevices.,EVOLVE
486,5fc1f717_d56d87cc,73feb4a4987488b27e85cd83c86d3597dc6d3171,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/virt/ironic/client_wrapper.py,103,"This looks weird since we're assigning a list to what looks like a singular value, e.g. 'internal' or 'public'. But if I followed along in the PS8 comments correctly, this all gets passed through to KSA right? And KSA handles interface being a list? It would be nice to have a comment explaining this and if/when we can remove this, i.e. is there something we can do in ironicclient to fix this?

And yes I guess KSA is OK with this being a single value or a list:

https://github.com/openstack/keystoneauth/blob/83be7453fa0cd36b504b9ec268bd09525376b944/keystoneauth1/identity/base.py#L329

https://github.com/openstack/keystoneauth/blob/83be7453fa0cd36b504b9ec268bd09525376b944/keystoneauth1/access/service_catalog.py#L128",EVOLVE
487,9fdfeff1_94152b4c,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/functional/test_servers.py,6392,no,EVOLVE
488,3f79a3b5_6efc7a0a,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,nova/scheduler/client/report.py,790,"traits, aggregates and inventories",EVOLVE
489,3f79a3b5_8e49a8ba,be9a21a61c94ff37e664ae18d1ca8a2fcebf7a7a,47bcc39cd633cdbdca97bf8b3d94bccd127b940f,nova/objects/cell_mapping.py,283,"distinct(<col_expr>) is Postgresql specific. I think SQLAlchemy probably omits the expression otherwise, or fails, not sure.  But...this probably shouldn't be here either.",FUNCTION
490,5fc1f717_497ca4b5,521cb4b9006b53071d788b16688847ef448e60a5,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/cmd/manage.py,1130,OK so this is where we'd continue to map instances if _map_cell_and_hosts returned a cell_uuid.,DISCUSS
491,3f79a3b5_d9925a49,8a5c7b51cd558f5a7b3183d890a1ef5905bf643c,8545ba2af7476e0884b5e7fb90965bef92d605bc,nova/virt/libvirt/driver.py,5156,Still good - <somethine else> is x86)64 and 'q35' in machine type,DISCUSS
492,5fc1f717_9c696c26,8c0c5432a00adbde921ca688aa05b8cc749f2b59,357da989c194a8b59842629cb64b2809143a4eae,nova/virt/libvirt/driver.py,1464,"I know this should always be in here, but I'm still always nervous about this random dict from whatever vendor storage backend is being used in cinder, and would opt to be safe and default to {} if 'data' isn't in there. Although it looks like we have plenty of libvirt drivers that just blindly access connection_info['data'] so whatever. A bit nitty but then I'd change this to connection_info['data'] to be explicit, but it doesn't really matter.",FUNCTION
493,9fdfeff1_dd31e10c,65910122ef5d66d6804c3138f16f7e989be162ee,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,260,"Just realized something when I saw this, for the recent migrations we assume every instance_mapping/request spec has a corresponding instance left.

There can be instance_mappings older than Queens which no longer have instances since they got archived - orphaned ones (we have a lot of them downstream probably I should try to get https://review.openstack.org/#/c/560042/ in at least downstream before we run this and the queued_for_delete, else its never going to complete I guess :( and we return (done, done) for the queued_for_delete migration which will make it believe like its done. ).",DISCUSS
494,3fce034c_e414a9a2,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/virt/ironic/driver.py,2182,"actually, IronicDriver manages the port binding
(that is why we avoid in the compute manager from updating the port binding in _heal_instance_info_cache())

i guess you meant:
""In case of IronicDriver, port binding should not be update by the compute manager""

however i would refrain from referencing the computeManager here.

Maybe go with:
""""""IronicDriver manages port bindings for baremetal instances.
""""""",EVOLVE
495,9fdfeff1_ea2d5946,99a3823f98c593fd7f0a9e3fe3aab4126f9bb383,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/virt/libvirt/utils.py,320,"Note to self: what's this for, is it required, and if so are we still using it?",FALSE
496,9fdfeff1_0bbbe371,3730bd079104ad14f6992ad55cf8643911c916ab,bbfb3bcf792b0d712ec59259479c8701b1e31722,nova/tests/functional/test_servers.py,5502,nit: since this keeps getting copied you could move it into a helper method.,EVOLVE
497,bfdaf3ff_3828db84,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/resource_tracker.py,824,"I guess I'm not following this... if it's a new compute node, why would the scheduler client provider cache have anything in it for this provider?",DISCUSS
498,3f79a3b5_4c821c53,adffd410d665f84d279d686e716bb699e9386594,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,475,"For confirm_resize, we're on the source RT and I'm not sure if the instance would be in tracked_migrations (it might be though, see RT._update_usage_from_migration). Anyway, I guess this has to cleanup the usage for the old_flavor on the instance because we don't actually destroy the instance in the DB, but the guest is gone from the source hypervisor via driver.confirm_migration.",FUNCTION
499,9fdfeff1_b7b23e93,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,779,"I think for testing purposes you need to figure out a way to make the guts of this mapping deterministically ordered. Otherwise you can't prove that your ""allocation subtracting"" math is actually working (see possible bug commented above).

[Later] Okay, I talked myself out of the bug. Deterministic ordering still seems like a good idea for testing purposes, but not sure it has enough value to be worthwhile.

[Later still] Yeah, so you did that in the test case. You may safely ignore this comment, which I shall retain only to track my train of thought through this patch.",DISCUSS
500,9fdfeff1_143c042d,fda1655fdcb0504120c8061b97b46eb52fdaabdc,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,723,Why do we need this new wording on all of the choices? If you want to mention that all except the unique choice will change the serial when migrating instances to other hosts then just say that in the main description of the option.,DISCUSS
501,5fc1f717_453d09b9,074a2355a1b7f944942673153194f8aad8cb8144,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,40,This comment is useless now.,EVOLVE
502,3fce034c_86ae572c,8f1773a7af273e2739843a804fb4fe718c0a242d,9fd4082d7c076146ec314b86e0e4772d0a021712,nova/objects/request_spec.py,453,"I probably would have just made this:

 elif key in ('ignore_hosts',):

so that it was minimally changed and setup for the future, but that's just a nit.",FUNCTION
503,5fc1f717_b17933fd,5d6dbaf67c9501d1fefa39e42a04625e11cec13c,131f7606c179bd08bde3b7ae0e6bb0b59acf1545,nova/test.py,515,"and 'observed', to match up with the JSON comparison",EVOLVE
504,5fc1f717_66749036,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/tests/unit/pci/test_request.py,88,nit,EVOLVE
505,5fc1f717_9b85925c,2b15904afdc4bc7b17c34bc774386dec4eb3aa32,f130b295bb0e72ab9613018399ce423effeda37e,nova/tests/unit/virt/libvirt/volume/test_quobyte.py,37,++,DISCUSS
506,9fdfeff1_0e6afa18,9cb825b0147af3b191ea2989e5187e4afdadcb15,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/utils.py,296,This can go away now.,EVOLVE
507,ffb9cba7_3db8d9c6,b4ad9679b7fc7ec7a746bd6655b69e28334dd48e,13278be9f265e237fc68ee60acfacaa1df68522e,nova/virt/ironic/client_wrapper.py,134,"This is good as is, but I want to note for posterity some of the background/details.

This is tightly coupled to the ironicclient implementation, specifically [1]. The **kwargs to the get_client method is documented only as ""all the other params that are passed to keystoneauth"" [2]. This is vague and not completely true at least in terms of Adapter kwargs. It's also not a prescriptive/proscriptive interface, so ironicclient can change up the internals as it sees fit - as we saw very recently right next door with the addition of interface handling [3].

Basically, it sucks how the ksa pieces of this puzzle are put together. It's brittle and will keep breaking in ways similar to this one, and we should fix it.

[1] https://github.com/openstack/python-ironicclient/blob/060029ffcae8bbbd2315947cd059b701b5c31c39/ironicclient/client.py#L121
[2] https://github.com/openstack/python-ironicclient/blob/060029ffcae8bbbd2315947cd059b701b5c31c39/ironicclient/client.py#L66
[3] https://github.com/openstack/python-ironicclient/commit/d6eea403cbf0d11b06acbecc704f422a7e278462",DISCUSS
508,9fdfeff1_892c4d02,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/api/openstack/compute/servers.py,646,nit: you could remove this from this list since it's in the one below,EVOLVE
509,ffd0ebdf_239f7551,d786ae3841835d84c66ef1d29d3a7e0640945191,05d3c01a685de45dd8f98a46bc5c52f6bd08e7cd,nova/virt/libvirt/vif.py,525,"why are you setting this only for vhost user server mode?

ovn is still missing support for using server mode so with this check the patch will not correct the issue for ovn based deployments.",DISCUSS
510,9fdfeff1_12a23daf,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,99,"This 2.68 mention is going to have to change since 2.68 is taken now and you have to rebase. So either respin and change it here or remember to update it in the change that adds the microversion. Or just re-word this to be generic, like ""If the microversion is high enough, ..."".",EVOLVE
511,9fdfeff1_47dd406e,080587b75e14cadadfabc9ac007278b0b62f041a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,94,#ERROR!,DISCUSS
512,9fdfeff1_11b47ad0,b18e905de6a0ab24f90e6dee207214d126347e10,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,87,nit: period doesn't need to be escaped in a character class.,FUNCTION
513,9fdfeff1_ae34c9fb,2abf36a6989a597dcdbbe1282e81e51da86f1356,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/tests/unit/virt/libvirt/test_utils.py,524,This needs to be called test_<foo> or it won't run.,EVOLVE
514,5fc1f717_3e6da331,391ea45fa36aac2aaad6af21f5c2af2086f393c0,556cf103b22ab6bebecc9d824d6f918cda38fe3e,nova/conductor/manager.py,1010,so we don't persist the existing ignored hosts. Fine.,DISCUSS
515,ffb9cba7_f1ba65dc,12c3eb2d3a7e7f12a65d304ecfc14fed58d4ea58,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/tests/unit/api/openstack/compute/test_availability_zone.py,95,why?,DISCUSS
516,5fc1f717_42b400d2,42bf49c30e9fb142f49158a694c536a2eeab0d90,749f83568a368343924b0558e51ce1984ad3903e,nova/tests/functional/libvirt/base.py,58,"this would work but it would a better test if we could fiture out how to use the noop os-vif plugin instead.

with this mock

https://github.com/openstack/nova/blob/master/nova/virt/libvirt/vif.py#L703-L711

will never raise an excpetion and we might miss the error handeling path.

how about mocking _get_vif_instance

https://github.com/openstack/nova/blob/master/nova/network/os_vif_util.py#L247

so that plugin is replace with noop

the noop plugin does nothing but it will test the call signature and  it will provide a hook point for peopel to simulate raising exception in plug or unplug. 

https://github.com/openstack/os-vif/blob/master/vif_plug_noop/noop.py",DISCUSS
517,9fdfeff1_26393ea3,0b92325fe14eda062c78de2c3423ca4834861152,b164aaac1f036455205d2457abc3ae75769bf42f,nova/tests/unit/api/openstack/compute/test_shelve.py,68,Redundant with the functional test so I'm not sure we need this.,EVOLVE
518,ffd0ebdf_94c69616,faaf75688f56339e6a7a1116e352fc696853caac,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/privsep/utils.py,50,"This is pretty gross, and could be reduced to like five lines by using tempfile [1].

But not here.

[1] https://docs.python.org/2/library/tempfile.html",FUNCTION
519,9fdfeff1_60edbb23,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,241,"Why not start by iterating instance mappings that need to be migrated? Otherwise if I'm CERN with 70+ cells and everything in cells 1-50 are migrated, I have to do the query for the first 50 cells to start getting anything to process, right?",FUNCTION
520,bfdaf3ff_99c3aa38,5590eb3fe750b58f45d1b971290a6f219690d310,5a5d98d48a0dcf5e458c01d2a66c4abc9da3ec76,nova/conf/libvirt.py,485,"The docs say 4.4.0:

https://docs.openstack.org/nova/latest/admin/secure-live-migration-with-qemu-native-tls.html#prerequisites",EVOLVE
521,3f79a3b5_aee052f7,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_driver.py,17146,"I think the usual way to set these would be:

 self.flags(images_type='rbd', group='libvirt')
 self.flags(enable_libvirt_rbd_instance_dir_evac_cleanup=True, group='workarounds')",FUNCTION
522,9fdfeff1_1344ba73,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/unit/virt/libvirt/fakelibvirt.py,335,"This returns a list in py2 and an iterator in py3. That okay?

[Later] Guess so, same as L289.",EVOLVE
523,9fdfeff1_be292ef3,f261d47bc22b62d4940520442837f5a0b7e35641,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/virt/libvirt/volume/vxflexos.py,35,but,EVOLVE
524,dfd5e7cf_3922fca5,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,8312,"femtonit: passes pep8 but awkward to read, IMO",EVOLVE
525,3f79a3b5_8e5f0c0f,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,1181,change not needed if you have _checks_for_create_and_rebuild() call _validate_flavor_image(),FUNCTION
526,9fdfeff1_1f0aafd1,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,2946,ditto,DISCUSS
527,3f79a3b5_7b0981d9,cc0385f510854c64aaecd2e4c36a61d459fb3fdc,ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57,nova/api/metadata/base.py,684,"Should also handle it here:

https://github.com/openstack/nova/blob/ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57/nova/api/metadata/password.py#L71",FUNCTION
528,ffb9cba7_b1c6bb67,fa242aea72360a78e67a67fb4f2255c4c12407ac,ce5ef763b58cad09440e0da67733ce578068752a,nova/conf/ironic.py,99,might be useful to put s/all (including this host)/,EVOLVE
529,3fce034c_6ee768e6,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7312,"i think this is what you actully want to skip.

so maybe you want to just do the compute driver manages_port_bindings check here?",FUNCTION
530,3f79a3b5_f460a2a1,a19e109d85aa8f68aedf76ce61e69c02bbd19ecb,b8d751c67b8888a39532e916ac1bbc569ec6d38c,nova/tests/unit/compute/test_compute_mgr.py,6005,"What about just search for 'oops', something like self.assertTrue('oops' in six.test_type(e)) that's to avoid any fail is the tests for localization issues.",FUNCTION
531,9fdfeff1_51155548,411b81289305ca4675725ecdc3131944319d7586,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/compute/api.py,2293,"yep this works I am fine this this, else the other way I was suggesting in the previous patchset (sorry for not making it clearer) which might also avoid the extra save/returning the instance_mapping is to do something like this:

 def _update_queued_for_delete_and_user_id(context, instance, qfd)
     ...
     ...
     if not qfd:
         im.user_id = instance.user_id
     im.save()

from the restore function alone we pass the qfd as False and for the rest of the deletes its True. So we could just make use of that flag, might make the code cleaner.

Anyhow I don't mind either of the ways, whichever works for you.

I see you have the comment saying its because we didn't add this in the data migration which is good, which also means this is only for the transition period right ? After a while we could stop doing this once we are sure we would have caught all the NULL cases ? Maybe you could put a TODO to remove this.",FUNCTION
532,5fc1f717_5e574127,f6afbe5f47d1f9c98f121eef97eca1c313e85318,da9f9c962fe00dbfc9c8fe9c47e964816d67b773,nova/virt/hardware.py,885,"This isn't strictly speaking necessary given the additions on L697-L705, but it is indeed much better to set it explicitly and rely on Python scoping quirk.",FALSE
533,3f79a3b5_a75d09e6,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/tests/unit/test_metadata.py,1634,"I'm not sure this is right since target_cell is a context manager, so this assertion might always pass. It's probably good enough just to assert that mock_get_im isn't called.",FUNCTION
534,9fdfeff1_159acbb7,a1843a14b97c68e7c9d690ec7601db90aa6ec51a,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,346,this is going to be a pep8 error,EVOLVE
535,5fc1f717_e014314f,e4fa061f17353f49615d4850b562699d55a0641b,926e584136e7dce59f32065292aa4eb8120f628c,nova/console/websocketproxy.py,317,"oh, that's way nicer than the LazyLoader I would have hacked together.",DISCUSS
536,9fdfeff1_d603f60b,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,116,Now that I'm looking at the example in the docs patch on top of this why didn't we include the links?,DISCUSS
537,9fdfeff1_e3be43d3,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,334,"What would cause this to happen and why do we care? I'm assuming old code for the former, but I'm not sure about the latter. Do we need a TODO to remove this in a future release once we're sure this is being done?",DISCUSS
538,9fdfeff1_246a87ec,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/compute/manager.py,1581,Adding the raises to the driver interface docstring would be good.,EVOLVE
539,dfd5e7cf_9c120409,ed02d5db1bf94dee2e5d78b89abed85500656347,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/scheduler/filters/__init__.py,54,"does not need, you mean?",DISCUSS
540,9fdfeff1_e0d63950,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/scheduler/client/report.py,806,Are we OK to keep the name of this function? I mean it now refresh everything for the rp_uuid including inventories.,EVOLVE
541,3fce034c_64d199fb,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/virt/driver.py,1847,Compute driver manages port bindings,EVOLVE
542,bfdaf3ff_43f91dc6,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/objects/test_numa.py,181,"note to self: the unit is actually KiB, so this is 4096 bytes, not a 4 byte picopage.",FALSE
543,9fdfeff1_8ecbd770,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,702,"This means you need to bump the ironicclient wrapper minimum required version to 1.46 right?

https://github.com/openstack/nova/blob/75d52556066cf56b33e61bc4a80b6dc81b846c07/nova/virt/ironic/client_wrapper.py#L35",DISCUSS
544,9fdfeff1_a4c67767,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/conf/compute.py,825,You already mentioned this in the first paragraph.,EVOLVE
545,3fce034c_9809f2de,0d1310224818c204c52f67deee18efafd1269681,3a6d48697feee02380d60beeaa81ef619f9c94e3,nova/objects/request_spec.py,1059,"We should probably have a unit test for this, something like this:

https://github.com/openstack/nova/blob/3a6d48697feee02380d60beeaa81ef619f9c94e3/nova/tests/unit/objects/test_request_spec.py#L980",FUNCTION
546,9fdfeff1_d13a3c32,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/conductor/manager.py,1243,same,FUNCTION
547,5fc1f717_f771f9e1,77bc0f285d3e332b87692f8c5773d7b78954c206,d2342e61de386894677900eecffb262a59e1446a,nova/compute/resource_tracker.py,1478,also not used (could be @staticmethod),FUNCTION
548,9fdfeff1_6b7a2526,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2120,nit: I'd prefer to have this conditional out of this method and rather as a second check in L2207 as for the moment request groups are only for this feature. Meh tho.,EVOLVE
549,9fdfeff1_06d567e5,d883a1b3d174b9f8af373d254fe880c322df2ad2,883da6cb8129b96138339c24890b8871eb122111,nova/compute/manager.py,4381,Some pretty aggressive wrapping going on here eh?,DISCUSS
550,9fdfeff1_2ea1fef7,395ba18a913388ea184bfd4ae11eebc7a28471a8,f4796651df9cb211c071559cffc3e2e2fec8242e,nova/tests/unit/network/test_linux_net.py,1259,list,FUNCTION
551,9fdfeff1_b9d5031e,ab3c01e883a8db5a2d8843552261f18053f4d678,a75e70bd2d9507948b2e39e8d4f29992c8ad12bf,nova/tests/unit/conductor/test_conductor.py,2095,A test case that _fill_provider_mapping raises an exception is missing.,FUNCTION
552,9fdfeff1_2e3a02e7,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1044,HostState,EVOLVE
553,9fdfeff1_7b9c0f5d,c7490fcdb46fe883aefc2c85293973e9df226b3e,2bf79236a39aa4417fea39ab1f900bf150b05764,nova/compute/resource_tracker.py,103,Tolkien would be proud,DISCUSS
554,9fdfeff1_b29fb14e,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,2098,have,EVOLVE
555,3f79a3b5_0cee36fd,47ec5327c97c5916d9bc2b319bef8a7196fda60f,27b7bad88b531e0869f8e9af9ab951b921c37634,nova/compute/manager.py,766,Why couldn't this just use self.reportclient to begin with?,FUNCTION
556,3f79a3b5_08fe2938,50a4f4e1d1a4711ddaf0bf30eff0244826f028bd,62245235bc15da6abcdfd3df1c24bd856d69fbb4,nova/cmd/manage.py,419,/me mentions something about having a real consumers endpoint :P,EVOLVE
557,5fc1f717_6e03eb74,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4554,instance (line 4546),FUNCTION
558,9fdfeff1_3c4ca6c6,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1731,"ack, good catch.",DISCUSS
559,3f79a3b5_d7401a8d,ae6e1e1002bb23116b21ffa52e93250274cedd30,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/compute/rpcapi.py,37,"This made me think we log it at warning level, but I guess it's debug. I wonder if we should make that info level since now we'd only log it once.",EVOLVE
560,9fdfeff1_0c2b5d30,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,688,"well, kinda.. :) not the unnumbered request group.",EVOLVE
561,9fdfeff1_e5549000,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/tests/functional/test_servers.py,5447,Why not use _create_server?,DISCUSS
562,3fce034c_e8ea4caa,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c,nova/compute/api.py,3598,"This regressed volume-backed resize where the flavor disk is smaller than the current instance root_gb, see bug 1825020.",FALSE
563,dfd5e7cf_86eab372,90c350fce0a30e59de753fddd6648513cc326ef7,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/pci/manager.py,313,Fancy adding docstrings? :) Here and below,EVOLVE
564,9fdfeff1_c35f7f73,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/tests/unit/conductor/tasks/test_live_migrate.py,94,unrelated change,FALSE
565,3f79a3b5_1bee4dff,cc0385f510854c64aaecd2e4c36a61d459fb3fdc,ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57,nova/conf/api.py,203,querying the,EVOLVE
566,9fdfeff1_d11d5c0f,a4d348fd499328cd58fb786504b0dda37d677f57,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/powervm/driver.py,123,use_cache,EVOLVE
567,9fdfeff1_ac7e3f16,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,252,Why do we need this? I don't see im.cell_mapping used below. I know this data migration was based on populate_queued_for_delete but I don't think it was needed there either.,DISCUSS
568,3f79a3b5_de96cba0,54357f111de2401034f67b07f833a05e9ac9b99a,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/privsep/utils.py,47,"As noted in the bug, is there any worth in checking 4096 and failing that falling back to check 512?",DISCUSS
569,9fdfeff1_cae095fd,fd7e28f3bd85c13c0d9a93892767b4b37f1cbeaf,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/functional/db/test_virtual_interface.py,148,I removed the condition in the code again and this didn't fail...,FALSE
570,3f79a3b5_3bf906c5,67e2d32f000ea5db511eb00c27eadfaaf9283a16,8518dfef56259f5ee1fe92b5eaa5dabecb07b0d8,nova/objects/request_spec.py,903,Will we set this only for neutron ports now? Or do we want to set the unnumbered group's requester_id to the instance uuid? More generally why do we allow nulls?,DISCUSS
571,9fdfeff1_970cf194,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3483,"I guess we needn't those parameters, since we test simple case",EVOLVE
572,dfd5e7cf_c1bc25de,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,6646,nit: unrelated change,EVOLVE
573,9fdfeff1_49f5d256,68d9f4baf745d0b54d80e6e750212a1e1c71e882,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/compute/test_compute.py,10776,Could have left this in and asserted it's not called.,FUNCTION
574,ffb9cba7_7e18841c,186b37f8237010b5abd4ab4ad208a9ea400f8819,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/availability_zones.py,113,Add this to the docstring.,EVOLVE
575,3f79a3b5_b67fb6ba,6aa9ed7fcce9339b922b630b60afa21d3b70d7e4,eafef9556a3f91a2514fa3e029af329c771a7423,nova/virt/libvirt/driver.py,7334,"the check force_complete and abort are under this logic check
at least the name seems confusing now...",EVOLVE
576,bfdaf3ff_69175ba5,ed5362d09f655e8f04d0f9ccae22f9c4480a852c,c9ac27f1bcf81d0cf8a06414edcafc3a9068ae1f,nova/compute/manager.py,758,"I'm not sure how I feel about this. The implication here, by having a 'self.rt' prefix is that somehow what's happening here is somehow relevant to this thing called a ResourceTracker. It isn't, really. It's simply that we're deleting some allocations.

This is maintaining that never really true illusion (at least not since we moved to one resource tracker) that there's some separation between the manager and the resource tracker.

I agree that we should have a self.rt (for things like instance_claim()

But I reckon it is cleaner to have a self.reportclient, not a self.rt.reportclient if there is never going to be a self.something_else.reportclient

Earlier in the stack, you deleted a TODO of mine, which was to move a call to reportclient to be a call to rt so that we're only interacting with one layer of the rt, not sometimes punching through to the reportclient. But the way we have ended up doing things is to make the reportclient the placementclient, and thus lots of thing need to talk to reportclient, thus punching through is normal to the point of mentioning the rt at all is redundant.

Therefore self.rt.reportclient feels like noise.",FUNCTION
577,3f79a3b5_d27e6f6b,307aac508e5e0c2eea14941e781a4ad8f2b3bfa3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/compute/manager.py,529,"I'm not sure if this still applies when using futurist. Looks like it's not:

https://docs.python.org/3.5/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor

https://github.com/openstack/futurist/blob/master/futurist/_futures.py#L334

The latter just defaults to 1000 max workers. 1000 is obviously high enough for us, since even with py35 if you had 128 cores you'd have 640 max workers. But we should remove the comment since it doesn't apply to futurist.",EVOLVE
578,9fdfeff1_69b809e8,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,543,nit: this could be a staticmethod,FUNCTION
579,9fdfeff1_3742e5ac,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3484,This is needless,EVOLVE
580,ffb9cba7_31947d37,12c3eb2d3a7e7f12a65d304ecfc14fed58d4ea58,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/api/openstack/compute/availability_zone.py,77,"change for a list to a set which removes and duplicate host.

the same host shoudl not be list twice anyway by but that allow us to remove the if check and a set will be faster.",FUNCTION
581,5fc1f717_4ab72988,fbbe7694a0d4c80db5da5f90d46bd3e13a8c5276,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/scheduler/utils.py,311,is,EVOLVE
582,5fc1f717_58acde34,7931f85fe66d4e024d7dd5396dcf38378af85470,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,91,"Unlike mount, which is always called after connect(), which calls is_systemd(), disconnect doesn't call is_systemd() first. IOW it's possible to call the wrong one here after a restart of n-cpu.

If we follow Artem's suggestion above this not only isn't a problem, but nobody even has to think about it.",DISCUSS
583,bfdaf3ff_5ac7bb13,8f328c03b266b0d17da2f0e92ad319aa603c8e41,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/compute/manager.py,2336,"nit: might be worthwhile adding a comment here to remind developers to avoid leaking any host-specific details in the fault message; that's the main concern I have with including any and all exception messages here which aren't handled explicitly above, but I might be over-thinking this.

The alternative to this would be raising InvalidBDM from _prep_block_device or a new exception type for the max devices and then handling it in the block above since then we have more or less a whitelist of exceptions we know are OK to include in the fault message.",EVOLVE
584,9fdfeff1_b27bd589,77726e30792ea101c9ca3eb78beed8fd4d64f13e,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,174,Need a space here.,EVOLVE
585,3f79a3b5_b2031011,b3975a07752de81c8fca8e9604434e6d2a398cd2,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/tests/unit/cmd/test_status.py,475,"Since the check code for the status command still exists, I'm not sure why these tests were removed...",DISCUSS
586,9fdfeff1_f759028e,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/tests/unit/compute/test_compute_mgr.py,1799,Don't you want to assert this is called with use_cache=False?,DISCUSS
587,9fdfeff1_ea65a646,883da6cb8129b96138339c24890b8871eb122111,512397423092b2260b1a914bfcd4a54ba14f343c,nova/compute/manager.py,4219,"Replacing this amount of code duplication with a a function with extra conditionals feels like complicating things. I guess this new function will be used in more places later on to avoid further duplication to justify this refactor.
// later //
I see this will be reused also in prep_snapshot_based_resize_at_dest in I518ae675b7a67da64a5796e57e87860f0c3ef0db. So I'm OK with this.",EVOLVE
588,3fce034c_8bede68c,9aa071f12c7461a9108d96c5e71769d055d2c95d,063824125bd56684395761569a0a24c54767ccb6,nova/api/openstack/compute/servers.py,1226,I'm not really sure why we even have this when other action methods like _action_rebuild use _get_server which uses common.get_instance. Seems we could remove this method later and use _get_server but that's not something for this change to worry about.,FUNCTION
589,9fdfeff1_d27fd5dc,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/tests/unit/api/openstack/compute/test_serversV21.py,7343,This will have to be updated since 2.68 is taken.,EVOLVE
590,9fdfeff1_8f2c88ac,34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/objects/request_spec.py,796,"The above function is very difficult to follow, even with the (excellent) code comments. Maybe it's just me, but I feel the algorithm would be easier to follow if instead of doing the whole list(zip(itertools.product())) thing, you had a simple loop over the request groups (self.requested_resources) and determined the provider used for each request group within the loop.

In other words, do something like this:

 allocs = copy.deepcopy(placement_allocations)
 for rg in self.requested_resources:
     rp_uuid = self._find_provider_for_group(rg, allocs, provider_traits)
     if rp_uuid is None:
         raise ValueError(...)
     rg.provider_uuids = [rp_uuid]

And then implement _find_provider_for_group() to simply find the first resource provider that meets the request group's traits and resource constraints:

 def _find_provider_for_group(self, group, allocs, prov_traits):
     # NOTE that allocs is updated to have its resource
     # totals decremented if we find a provider having
     # matching resources...
     
     for rp_uuid, alloc_dict in allocs.items():
         # Check if the provider has all the traits this
         # request group required... skip otherwise
         if (not all(req_trait in prov_traits[rp_uuid]
                 for req_trait in group.required_traits)):
             continue

         rp_allocs = alloc_dict['resources']
         grp_resources = group.resources.items()
         # Check if provider has enough capacity for each
         # resource we're requesting in this group. If not,
         # skip it
         if not all(rp_allocs[rc] >= grp_resources[rc]
                    for rc in group.resources):
             continue
         
         # Cool, got a match. Decrement the usage counts
         # so next iteration of _find_provider_for_group()
         # accounts for this ""pick""
         for rc, amount in group.resources.items():
             if rc in rp_allocs:
                 rp_allocs[rc] -= amount
         return rp_uuid",FUNCTION
591,ffb9cba7_017ba7bd,57465aae77a7af605bbf1ffa29f9dc4b97783922,f6667b05d2146c928468021e5569a34215e93020,nova/db/sqlalchemy/api.py,661,"Will this be confusing?

""Compute host $nodename could not be found.""

[Later] Oh, I see y'all already discussed this in PS6.",DISCUSS
592,9fdfeff1_5a2e9792,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,741,"hm, we don't just want to ignore the unnumbered group?

I mean, I guess if it had network resources on it, we should blow up. But usually it won't, right? Just VCPU, MEMORY_MB, and maybe DISK_GB?",DISCUSS
593,9fdfeff1_4a4d2e98,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,165,This confuses me because above you say 2 pGPUs and I thought there would be a child resource provider per pGPU?,DISCUSS
594,ffd0ebdf_b27f35aa,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1042,"type is a reserved word, so should probably rename this variable. Maybe ""multplier_type""?

Would be good to add a docstring for this utility method to avoid confusion.",EVOLVE
595,ffd0ebdf_4d218a9f,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/weights.py,79,document this parameter and how it's used with the utility method,EVOLVE
596,3f79a3b5_095cb2ed,67fed7cc2d42e611e278b4a09fb0887ae8314aa4,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,206,"Hmm, this would also change the updated_at value but it wouldn't be reflected back in 'compute'...we should probably set the updated_at value as a result:

if online_updates:
    db_compute = db.compute_node_update(context, compute.id, online_updates)
    compute.updated_at = db_compute['updated_at']",FUNCTION
597,9fdfeff1_86471778,da34a5f05230c4bfcc828a223e1ff8434b05ce09,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1263,Can we log the actual exception here before the caller potentially swallows it?,EVOLVE
598,9fdfeff1_02e37835,86fb5fd4fe484838b2d70bcdd914fe04c020a7d6,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,469,This is no longer used in the response validation - here and below.,EVOLVE
599,9fdfeff1_9d3187ef,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/libvirt/blockinfo.py,196,"Why add this? This is really a user initiated failure to which an operator that reads the error in the log doesn't really have a solution. If a user hits this on server create, it's already logged higher up the stack and recorded as a fault. If the user hits this during volume attach, they get the 403 error response from the API and can see why it failed - I don't really see a reason to log an error here for an operator.",DISCUSS
600,9fdfeff1_6d416ca6,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3449,"This seems like another case of, why do we raise? We're asking to remove something that's already gone - why not just log it but not raise because the end state is what we wanted anyway.",DISCUSS
601,dfd5e7cf_3a1f6e6d,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/cpu.py,21,do we need to update this also?,DISCUSS
602,bfdaf3ff_a409e595,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/compute/manager.py,5423,"Unless of course we're attaching a volume to a shelved offloaded server, in which case the BDM is created in the API (reserve_block_device_name is not called because the instance doesn't have a host to call), and that means we'd fail the configured max check only on unshelve when _prep_block_device is called during unshelve. Just FYI...",FALSE
603,9fdfeff1_f131805a,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/conductor/manager.py,529,We should have already set it in the API before we hit this.,FUNCTION
604,ffd0ebdf_46189280,0ce581369838dbe6909bdd8847aefac2aff1177e,7381ec7d7c318bddd42e1d90a171d20b2ec6f49d,nova/tests/functional/regressions/test_bug_1790204.py,72,"actually, 1028",EVOLVE
605,9fdfeff1_eaa9947b,3534471c578eda6236e79f43153788c4725a5634,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,180,"I removed this and now the new test fails

Captured traceback:
~~~~~~~~~~~~~~~~~~~
    b'Traceback (most recent call last):'
    b'  File ""/home/osboxes/git/nova/nova/tests/functional/db/test_virtual_interface.py"", line 179, in test_migration_do_not_step_to_next_cell'
    b'    self.assertEqual(2, match)'
    b'  File ""/home/osboxes/git/nova/.tox/functional-py35/lib/python3.5/site-packages/testtools/testcase.py"", line 411, in assertEqual'
    b'    self.assertThat(observed, matcher, message)'
    b'  File ""/home/osboxes/git/nova/.tox/functional-py35/lib/python3.5/site-packages/testtools/testcase.py"", line 498, in assertThat'
    b'    raise mismatch_error'
    b'testtools.matchers._impl.MismatchError: 2 != 4'
    b''",FALSE
606,5fc1f717_8f56be5b,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,666,This can also raise ComputeHostNotFound so do you want to handle that and return an empty list like L661 above and L672 below?,FUNCTION
607,9fdfeff1_1c668252,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1712,++,DISCUSS
608,9fdfeff1_5af26e9c,a5d78b17e7f538c75eff938f4ace14c01c5d34b4,c1fb445b8d94e69d7878fad60c4653650052313a,nova/api/openstack/compute/migrate_server.py,87,"@validation.schema(migrate_server.migrate_live_v2_30, ""2.30"", ""2.67"")",FUNCTION
609,5fc1f717_af3a9a30,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/db/sqlalchemy/api.py,689,I think we could re-use this for the ironic case.,DISCUSS
610,3f79a3b5_9d3ab993,20a580b81729baf7d710a986fc07d6b3bfe2e76b,1e8c2c0dcb3ff9225407b890a6c99658b35764bc,nova/tests/fixtures.py,2085,This level of nesting is a bit too much to my taste but I was able to follow along so I can live with it.,FUNCTION
611,3f79a3b5_cae96518,5c21a00e89539bbb271ccfa05e4a2ba1cddae58e,90b96170d3f269165f649e8b61739cf31ffb78b8,nova/image/glance.py,164,any reason not to just make the default here 'images' and kill L186?,FUNCTION
612,ffb9cba7_d4ccc862,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/compute/resource_tracker.py,1552,unclaim_pci_devices ?,EVOLVE
613,9fdfeff1_fb7e6317,4e460a02e49f4227f189297f9ea37e13d03de5a5,c134feda3d9527dbc9735e4ae9cd35c4782f1fb4,nova/tests/unit/fake_policy.py,49,"don't see update here, it is not needed?",DISCUSS
614,dfd5e7cf_1dff0402,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/pci.py,21,ditto,DISCUSS
615,9fdfeff1_a4df6164,baebdfb995e077b92af7ca20a208ece264d376f4,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,nova/network/neutronv2/api.py,2032,"Don't we need to add requester_type (network, port, flavor) or something to be able to differentiate what data actually is?",DISCUSS
616,9fdfeff1_4af540ca,6c239c2390799fef03ba4f7d00762a4a96f62819,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/tests/unit/scheduler/client/test_report.py,3632,"In this case we can assert ""due to multiple subsequent generation conflict"" is in the exception that is raised.",EVOLVE
617,9fdfeff1_a47d17b3,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/compute/manager.py,1623,Same - would be good to add the TooManyDiskDevices raises to the docstring for this driver interface.,EVOLVE
618,9fdfeff1_9109e1dd,695dfc59f2adea9995c138a9694e6f4368fbf185,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/objects/request_spec.py,714,"This can be avoided with collections.Counter
In [28]: Counter({'a': 10, 'b': 20, 'c': 30}) - Counter({'a': 5, 'b': 10, 'c': 30})
Out[28]: Counter({'a': 5, 'b': 10})",FUNCTION
619,9fdfeff1_876a1aea,6b844af57eebda6317b1ed3bf5a2f85dcba0bc13,a6963fa6858289d048e4d27ce8e61637cd023f4c,nova/tests/fixtures.py,755,Presumably this is related to the issue.,DISCUSS
620,3f79a3b5_ec6f3af8,31e7f0bb82b93b50b5c50076fcd8c2d133f6eb00,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,416,s/the//,EVOLVE
621,9fdfeff1_08c164e5,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,167,no longer,EVOLVE
622,9fdfeff1_7bb40fd2,603c4cccc12dfad345d5552dc6ad5a206240a640,7f92674a80c8d76749067e86363370814b7f0429,nova/tests/unit/network/test_linux_net.py,913,ditto,EVOLVE
623,9fdfeff1_46d1462f,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,697,the RP,EVOLVE
624,3f79a3b5_62df060a,7a08c7714d90cd4766ffb27fab1a8ac3f431399c,7fa740491e53195021036af69a0ddfde183daef5,nova/tests/functional/db/test_build_request.py,509,Could have also been nice to add a simple test to ServersPreSchedulingTestCase which hits the actual full stack with only build requests in the DB so we could test marker logic there as well. But maybe this is good enough.,FUNCTION
625,5fc1f717_fd87ae60,0a91f3ce521c2ff165967fc99555cda118d23ed0,926e584136e7dce59f32065292aa4eb8120f628c,nova/monkey_patch.py,0,omg,FALSE
626,9fdfeff1_864eea35,2db2839be9864f054a430b2013fdc3ba09a4eb69,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,nova/conductor/manager.py,1252,RP,EVOLVE
627,ffd0ebdf_a303650d,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,209,same,EVOLVE
628,3f79a3b5_c1aaca6b,4128e13277c1413378773db351f3e4abc1451e6a,1882753ad0313a8c25294e0191fb5929ef395eef,nova/tests/unit/compute/test_compute_mgr.py,31,This needs to go away. uuidsentinel was introduced in oslo.utils 3.37.0. This file needs to continue using the nova fixture (see L70).,FUNCTION
629,3f79a3b5_07948f34,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,442,"Does ""if a
live-migration memory copy iteration does not make percentage increase of at
least 10% over the last iteration"" still apply though? Because before this change, if we reach live_migration_completion_timeout we just abort, right? But now post-copy is triggered if we're (1) not progressing or (2) we've reached live_migration_completion_timeout and the action is 'force_complete', but if I set live_migration_completion_timeout=0 will post-copy still be activated if the live migration iterations are not making progress as live_migration_permit_post_copy was originally intended?

Maybe this should just say, ""Note if you change
to not timeout, i.e. ``live_migration_completion_timeout = 0``, then there will be no automatic switch to post-copy unless ``live_migration_permit_post_copy=True`` and the live migration is not progressing.""",DISCUSS
630,3f79a3b5_50f18963,b01f2746f4c1de3895a0a701d064df7fb902e464,c64b03d218c4d05b9db47eaf7660cdab9baa6468,nova/tests/unit/virt/libvirt/test_guest.py,38,Ditto.,FUNCTION
631,9fdfeff1_7be87815,d9bd5b1377acf4468c89422fa471de6c8325d775,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/compute/multi_cell_list.py,431,"This warning could be confusing in the cell_down_support=True case where we still return results for that cell, but they are the minimal results. Maybe this should be DEBUG or INFO if cell_down_support is True?",EVOLVE
632,bfdaf3ff_26fb9247,03948731eb6b10818e9d8842d3b51c2378e708c2,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,184,"I don't see any new test coverage for this, which we should probably have given this was missed in the initial review. A simple way to test this would be to populate 2 cells with let's say 2 old instances, for a total of 4, and run the migration with max_count=2 and assert that we only migrated the 2 instances from the first cell processed, and then run it again with the default max_count(50) and assert that only 2 more were migrated.",FUNCTION
633,9fdfeff1_b635dcf9,68d9f4baf745d0b54d80e6e750212a1e1c71e882,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/compute/api.py,4290,"what if this is []?
what if there is more than block device?",DISCUSS
634,9fdfeff1_8b4353af,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/tests/functional/test_servers.py,5470,exist,EVOLVE
635,5fc1f717_b0c232e8,b339c6c862f114147277c5d1401edd27a8d6930f,a7773846974e66ac9bd9e5343a02d6e805d2ecaa,nova/compute/manager.py,1386,Shouldn't this be a set?,FUNCTION
636,9fdfeff1_a68edb24,d883a1b3d174b9f8af373d254fe880c322df2ad2,883da6cb8129b96138339c24890b8871eb122111,nova/compute/manager.py,4421,"Um, gross?",EVOLVE
637,9fdfeff1_a1121761,49a87d6fe332b02e8dca872a8b8d5197c7ba1fb5,ff728365635be8447bb124a9842934080a8f789a,nova/conductor/tasks/live_migrate.py,169,"Why wouldn't we still want this check?

And if that passes we'd still want to check the minimum source and dest compute service versions, re: https://review.openstack.org/#/c/634605/16/nova/compute/manager.py@6065",DISCUSS
638,9fdfeff1_7a96f641,135889d8b5991ec249a31767f5a11fd89908e38f,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/objects/request_spec.py,817,This could probably be a UUIDField right?,DISCUSS
639,9fdfeff1_0045d942,3fbf336a38556db1fce2e9744a3c9712bf463614,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,6,"Why all this? I guess because you copied nova.utils

https://github.com/openstack/nova/blob/master/nova/utils.py

and added Red Hat.",DISCUSS
640,3f79a3b5_936c9d34,27b7bad88b531e0869f8e9af9ab951b921c37634,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,nova/compute/resource_tracker.py,956,"are there any virt drivers left that don't at least implement get_inventory()? If not, this can/should be removed along with compute_utils.compute_node_to_inventory_dict() (if this is its only caller)",DISCUSS
641,5fc1f717_7bd32f02,f6afbe5f47d1f9c98f121eef97eca1c313e85318,da9f9c962fe00dbfc9c8fe9c47e964816d67b773,nova/tests/unit/virt/test_hardware.py,2412,"This should probably go in the commit message, as Matt pointed out.",EVOLVE
642,3fce034c_afdc9818,70f6018b1ba82359745d2a2bd1fdd7b828c5d3f7,02b26457f3c5773973f374f39e069d2a854e99f6,nova/db/api.py,256,I think it will be better to use same word for params and its' introduction,EVOLVE
643,3f79a3b5_40313b09,aceef76e03374501811e58d6c2f108c4a5ffddf1,bbe88786fc90c2106f9fae0156ee7b09ece9a83b,nova/tests/functional/regressions/test_bug_1550919.py,213,nit: normally the functional test should create the flavor using the API.,FUNCTION
644,3f79a3b5_b6143243,bd245c2aab9b14951c4aeb7fbdcbb2e86e341dc1,a0eacbf7fff60282007ddca705ef7331e8a4a6f8,nova/tests/unit/virt/libvirt/test_migration.py,798,same,EVOLVE
645,bfdaf3ff_da55321f,1857337234544eae5ae2fa1c3a9f5bae093e19d1,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,38,wrong import,FUNCTION
646,3f79a3b5_589deb55,4a5da5a3b471bb5592d0a97e93bb69152e6447c0,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/virt/libvirt/utils.py,311,"compress = CONF.libvirt.snapshot_compression and dest_fmt == ""qcow2""
images.convert_image(disk_path, out_path, source_fmt, dest_fmt, compress=compress)",FUNCTION
647,9fdfeff1_37d3ae62,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,641,Does this comment need re-working as well?,DISCUSS
648,5fc1f717_38ceb25b,391ea45fa36aac2aaad6af21f5c2af2086f393c0,556cf103b22ab6bebecc9d824d6f918cda38fe3e,nova/objects/request_spec.py,542,"nit: this is fine but ignore_hosts probably should default to []. that said i think this will also work.
because of 
https://review.openstack.org/#/c/647512/4/nova/conductor/manager.py
so i dont have an issue with defaulting it to None since the field is declared nullable and therefor any code that uses it should be able to deal with None.

https://github.com/openstack/nova/blob/95a87bce9fa7575c172a7d06344fd3cd070db587/nova/objects/request_spec.py#L70",FUNCTION
649,3f79a3b5_2bde7f3b,bdad0e1b75be9713e5c665f1ac96843e4df3106e,a0eacbf7fff60282007ddca705ef7331e8a4a6f8,nova/tests/unit/virt/libvirt/test_migration.py,748,"A docstring with a description of the test would be useful, since the test here and below are 99% the same. The difference is the original xml doesn't have an mtu value, and the expected does (but shouldn't due to the bug). So would be good to note that when starting with a source xml that does not have mtu set, the resulting xml should also not have mtu set.",EVOLVE
650,9fdfeff1_9e802fc1,0e3068e11e71d3c56e062cf649064fb13821d0ab,900fe1c2e8e90be914f283563c0664439db54b5a,nova/virt/libvirt/driver.py,5017,"femtonit: If you created this first, you'd be able to group all the consolepty stuff together. Definite nit though",EVOLVE
651,3f79a3b5_dac93a23,d0ba488c1df86905082a13cc8598548244db0fd7,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/tests/unit/test_cinder.py,237,nit: ..._with_service_name test case also could be nice to be maintained for existing config which contains service_name.,FUNCTION
652,bfdaf3ff_1d284d32,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/virt/powervm/driver.py,200,"I guess this is a note to self that needs to be committed at some point, so why not now?",DISCUSS
653,5fc1f717_791c256a,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,269,"This is just the primary key and not very user friendly. It would be better to use something like:

cms_by_id[cell_id].identity",FUNCTION
654,9fdfeff1_d4d4134a,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,315,"this check is incorrect

it should be after we bind the ports on line 338",FALSE
655,5fc1f717_9d7934fd,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,4017,allocate,EVOLVE
656,9fdfeff1_a8b3d4e8,1c6fdc9aecba310630b6e74e861d31a4c3be1bed,a37a035c9d359b29fed6ea08bc99b93e51164e61,nova/api/openstack/compute/attach_interfaces.py,54,we probably can add a unittest case ensure there is None value for vif?,FUNCTION
657,1f769fc5_3a22f053,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,166,"the NetworkInfo is a list of VIFs, not ports...",EVOLVE
658,9fdfeff1_b7d1de25,f5e79ed17c6dfbb45aa4ea149d73282ed1915d4a,907c7d2cfef0677e4280c1138064ee58ddeb611e,nova/virt/driver.py,980,"Please remove this chunk, since you're resolving the TODO.",EVOLVE
659,9fdfeff1_abcd045e,9311aceadf385e3c2655cf44aae720b9b7282eac,a90c8e1a359a236e06f3a78df74f55808bbef31b,nova/objects/block_device.py,371,"A docstring on this would be good, i.e. in what cases would this be used?

Maybe also rename this to ""reset_fields_for_detached_root_bdm"" so it's a bit more clear about usage.",EVOLVE
660,5fc1f717_1fce5c2c,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4527,"To be precise: ""when the compute host is disabled which has the required trait in placement.""",EVOLVE
661,3f79a3b5_3fad24e7,fee72b1a063bf79d9aad214ceb06eab8dcf558c2,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/volume/cinder.py,131,nit: Should this be 2. instead?,EVOLVE
662,bfdaf3ff_9a07631d,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3000,This method is not defined in base class. Imo it should be defined also there.,EVOLVE
663,9fdfeff1_eb9d9659,6021595f0d27427812e2ea9b9fecb8485223afe6,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/libvirt/guest.py,270,"this one seems need some reword, ""Error from libvirt during undefineFlags. xxx Retrying with undefine"" seems not correct, how about ""Error from libvirt during undefineFlags for guest xxxx. Retrying with undefine.",EVOLVE
664,9fdfeff1_65c32e59,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,547,"Don't need or want this really, see:

https://github.com/openstack/nova/blob/c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4/nova/objects/flavor.py#L194

That's a bigger change but I would remove this part of the docstring.",EVOLVE
665,9fdfeff1_23b994e8,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/objects/request_spec.py,526,"Why don't we just handle this with the other 3 in the condition above? The field doesn't get persisted, nor does it get overwritten if its already set on spec. Why do we need to set it to None if it wasn't originally set? Since it's not persisted, we shouldn't hit a case where the setattr on L533 tries to set it from the DB.",FUNCTION
666,9fdfeff1_9230c4ea,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/ironic/driver.py,902,"Probably not for this change, but in a follow up, wouldn't you want to update the node_cache for this node since you just fetched it fresh from ironic? Because your stale cache could break something elsewhere right? Might as well update it while you have the fresh thing (or put it in the cache if it wasn't there to begin with).",FUNCTION
667,ffb9cba7_692961e4,c97f9a8f736e1d7d19d71b84ea475f072d48766e,32c10fadb96b92b6402752dbf1d6405008fc7f34,nova/tests/functional/db/test_compute_api.py,14,Looks like this doesn't exist in this release.. not sure how we'd address this.,FALSE
668,9fdfeff1_0ed60729,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/api/openstack/compute/volumes.py,212,"Both list and show call this, which uses the summary view and then adds the tag.",FALSE
669,9fdfeff1_ca3147ef,634bc66c85fc5fa4b05f5ee0b23654c94157f37f,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5057,"Another nit: Could have kept this and just always returned. It's a no-op but the cleanup could conceivably be separate. However, it is a no-op so let's remove it here",EVOLVE
670,9fdfeff1_a22c7eac,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1263,"Seems we should definitely cache this for the lifetime of a single build server operation because again, if I'm creating 100 servers in a single request, and 50 of those are served by the same compute node resource provider, we're going to be looking up the traits on each provider 100 times when we don't really need to. Your cache would have to be passed by reference from schedule_and_build_instances to this method.",DISCUSS
671,9fdfeff1_40dbe17a,3fbf336a38556db1fce2e9744a3c9712bf463614,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/cmd/__init__.py,18,Why don't you remove this method?,DISCUSS
672,5fc1f717_c039acf2,2734b249605eb28fd1017bd8bd35fc262e03c97d,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/conf/libvirt.py,653,"I'd delete this whole paragraph, tbh. From the commit which added it, it looks like Matt lifted it from an IBM article which has since been deleted, probably because it was wrong (not that we realised that until recently). Discussion of O_SYNC just seems confusing.

If anything, I'd replace it with: ""we do not recommend changing the default"" ;)",EVOLVE
673,9fdfeff1_2b76e7a5,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3810,"this is wrong, did you mean group_uuid=FAKE_UUID?",DISCUSS
674,3f79a3b5_330d893e,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,nova/scheduler/client/report.py,786,This is no longer correct.,EVOLVE
675,9fdfeff1_8167d351,df494543dad41ae8c4526d16dcd024465c0303af,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,nova/pci/manager.py,298,"style nit:

  if not self.allocations.pop(instance['uuid'], None):
      return

  for dev in self.pci_devs:
      ...",EVOLVE
676,dfd5e7cf_d0ee5e87,9b7d0fa5b0c60c878914a6fdecfec538fb4a1748,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/virt/libvirt/guest.py,247,"this is a pep8 violation.
http://logs.openstack.org/40/627540/4/check/openstack-tox-pep8/b3eb386/job-output.txt.gz#_2019-01-07_17_12_01_911386",EVOLVE
677,3f79a3b5_8521c2a3,a60631fd3a5df3e81dd9141fc1dd60f7cdd6ba80,9cac4ba8c5795265632d85d576a4ff810bffd475,nova/tests/unit/pci/test_request.py,19,nit: This blank line is not necessary.,EVOLVE
678,3f79a3b5_cc3f3a82,7a08c7714d90cd4766ffb27fab1a8ac3f431399c,7fa740491e53195021036af69a0ddfde183daef5,nova/tests/functional/db/test_build_request.py,524,do we still need this for loop when len == 1,DISCUSS
679,9fdfeff1_b3bdbb69,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/api/openstack/compute/schemas/evacuate.py,46,x,EVOLVE
680,3f79a3b5_0eeb587a,1bea334251fd8f1babc04ddb7b732a267d9adfc1,7fa740491e53195021036af69a0ddfde183daef5,nova/virt/libvirt/vif.py,840,it will not work unless you modify the method to not set the VF netdev mac/vlan as libvirt is in charge of setting and clearing this in the case of macVtap,FUNCTION
681,bfdaf3ff_3d172af0,397f7ea9f686eaf8d0ca8f267f26e29ded710bb3,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,735,ditto,EVOLVE
682,9fdfeff1_cd57385a,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3627,nit: use mock_get.assert_has_calls([get_call] * 4) instead,FUNCTION
683,dfd5e7cf_0fcc865f,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/compute/test_compute_mgr.py,8458,style nit: could you drag this up after the bracket on the previous line. Should help you fix the indentation of the second VIF and make this more readable,EVOLVE
684,3f79a3b5_4e4b347f,ba0502182edacc62c02052a2f41e5d19738d9324,5f648dda49a6d5fe5ecfd7dddcb5f7dc3d6b51a6,nova/image/download/__init__.py,52,"Man, we really need to remove this.",EVOLVE
685,9fdfeff1_8ac6b667,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/tests/unit/virt/libvirt/test_driver.py,20723,OK I guess this is because even though we found the parent in the tree availableInstances=0. Would be nice to have a comment to that effect since all of these methods raise ComputeResourcesUnavailable with the same error message so there isn't a clear way to distinguish *why* you're getting ComputeResourcesUnavailable in the different cases.,FALSE
686,9fdfeff1_b3a4894c,869eb884b476b04642957ead2fda4c8a3ec44feb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1264,supernit - `Failure attaching encryptor: %s` would read better but this is still fine.,EVOLVE
687,3f79a3b5_deed0702,a7d542fb717489fa5d3605844124d0e1afc218f1,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/tests/functional/api_paste_fixture.py,14,"im totally fine with this as a safty mesure but from reading 
https://www.python.org/dev/peps/pep-0328/

im surprised this is needed as it seams relitive imports require a preceding ""."" to be valid after python 2.6

so these should all be absolute already no?",FUNCTION
688,9fdfeff1_2e018bb0,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,679,and here,EVOLVE
689,9fdfeff1_375f8a76,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2156,"okay, here you raise an exception...",FUNCTION
690,9fdfeff1_da972ceb,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/api_sample_tests/test_migrate_server.py,24,"It's gross that we even need this in a functional test where we can control the running compute services, but we could clean that up later. Maybe add a TODO?",EVOLVE
691,9fdfeff1_273c32be,29d617457be6c5d8a9cd01dd5b533204166cada3,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/libvirt/driver.py,5734,extra ws,EVOLVE
692,3f79a3b5_9b852856,d6172354e1e02d37bfcf37c0748a0dba0f7bd685,3e756ff674e5da58b854b6b65ae225e3f7f97556,nova/policies/servers.py,159,is this for resize also ? if so then we should think about naming in different way. we have not thought the case where policy is enfoirced for more than one action or resource.,DISCUSS
693,5fc1f717_ae2eb3f7,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4563,ditto,FUNCTION
694,9fdfeff1_a53596dd,31fe7c76009e1c6d7859036e44b057d081b059b5,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/unit/api/openstack/compute/test_instance_actions.py,342,"project_id=self.instance_project_id will we set once when the fake_get fuction is first parsed so it will always be 26cd....
it will not be revaluated. i dont think tha is nessisarially an issue just pointing it out. by the way i dont see this fuction ever called so i dont think it is needed in anycase.",DISCUSS
695,bfdaf3ff_ba16e7f0,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/manager.py,3900,"So, this should be called with the network_info as it was prior to the resize ?

just a thought, much like in live-migration save the old VIFs and use them here.

today its PCI device, what will tomorrow bring ? :)",DISCUSS
696,3f79a3b5_87917f53,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,454,"nit: not really your fault, but we could drop the indent to fix the formatting",EVOLVE
697,3f79a3b5_8f74cacf,ae6e1e1002bb23116b21ffa52e93250274cedd30,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/tests/unit/compute/test_rpcapi.py,599,I would have thought you could have used mock_log.debug.call_count here as a more direct way.,FUNCTION
698,9fdfeff1_ab2132b6,31f048c689c6c750b0199a412922c87149e17bbf,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,nova/tests/unit/test_fixtures.py,598,This isn't needed.,EVOLVE
699,9fdfeff1_13583af8,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/tests/unit/compute/test_compute_mgr.py,6619,"same, you went indent crazy",EVOLVE
700,9fdfeff1_2f831ccd,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3454,not used,FUNCTION
701,9fdfeff1_3953063c,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,566,"so....for the Boot from volume case, we may get None value for the image, that will skip the flavor extra spec validation?

Also like we don't have unittest ensure this is called.",DISCUSS
702,9fdfeff1_195b06f6,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6287,"except ""first"" is nondeterministic because vgpu_allocations is a dict.

I should have kept up with [1]; surely I would have noticed this :(

[1] Ibf210dd27972fed2651d6c9bd73a0bcf352c8bab",DISCUSS
703,5fc1f717_3811a054,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/conductor/tasks/live_migrate.py,216,ugh. this kind of embedded tribal knowledge is just terrible and is an example of why the PCI module is so hard to work with :(,FALSE
704,9fdfeff1_d1cb1c6f,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1678,This...,FUNCTION
705,9fdfeff1_34b7f1f7,bbab98066d9783cbfe00ccbc3d41d77bc5c24232,5e29bef617b6c228eb618f73184d40449bc51779,nova/objects/instance_mapping.py,212,"If the population is based on the value in db being NULL, and since in the previous patch of adding the field to the InstanceMapping object, the default value is nullable, this would run on an infinite loop : same mistake we had while populating queued_for_delete. We might want to add the user_id while creating the InstanceMapping object for the new instances in the previous patch like for queued_for_delete (https://review.openstack.org/#/c/633350/3/nova/objects/instance_mapping.py@112).",FUNCTION
706,9fdfeff1_53ccf85f,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/network/neutronv2/api.py,1734,"This could be:

rp_uuid = vif.get('profile', {}).get(ALLOCATION)

Remember you have a constant for allocation now.",FUNCTION
707,9fdfeff1_4e18a680,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_affinity.py,122,Why negative? We're going to set the min to 0.0 in https://review.openstack.org/#/c/628205/.,DISCUSS
708,3f79a3b5_b001a1b6,88037a7374ac5d1d99c01bce1b895795651a5ff9,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/workarounds.py,189,"And IIUC, this has to be rbd-only because we don't have any other shared storage imagebackends.",FALSE
709,3f79a3b5_ee824002,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/api/openstack/compute/flavors_extraspecs.py,42,this is allowed upstream,FUNCTION
710,5fc1f717_95e8d616,59d94633518e6f6272e9f0654bb908e332f97a96,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/tests/functional/libvirt/test_pci_sriov_servers.py,36,"a request for a future followup. For those of us who don't memorize what random PCI product IDs are, maybe a note saying the above refer to:

 1528: Ethernet Controller 10-Gigabit X540-AT2
 1515: X540 Ethernet Controller Virtual Function

and of course, 8086 refers to Intel.",EVOLVE
711,3f79a3b5_374b8e5d,6ac2b16d26cf1bb48bb44dcb74a55015cde00aa7,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/compute/api.py,2134,"If you make this @property you can avoid having to change code below to call this method, and avoid future bugs where people forget to and assume this has already been called once by the time they need it.",FUNCTION
712,dfd5e7cf_9ce0c4fc,ed02d5db1bf94dee2e5d78b89abed85500656347,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/scheduler/filters/core_filter.py,87,"did you notice this? :)

The filters for RAM, vCPU and disk have been deprecated because we use the placement service now for handling resource requests for these basic resource classes.",FALSE
713,dfd5e7cf_af2e9aa2,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/network/test_neutronv2.py,4131,"I'm not crazy. This isn't a thing, right? If not, could we put in a valid non-live-migration value?",DISCUSS
714,bfdaf3ff_e4160df2,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/api/openstack/compute/volumes.py,356,"How much thought went into this over a 409? 403 means you're not allowed to do something, whereas 409 means you can do the thing just not in the current state of the system (which in this case is because there are too many volumes attached to the server), so the user could detach other volumes if necessary to ""make room"", or contact their cloud support team to increase the amount of devices they need attached to their server...",FALSE
715,9fdfeff1_aaa9f0df,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,832,unplugging,EVOLVE
716,3f79a3b5_c7d5a549,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,205,. If your,EVOLVE
717,9fdfeff1_ba7ea316,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/conductor/tasks/live_migrate.py,209,"It would be helpful to document why this is a suitable heuristic for ""I'm a PCI passthrough device"" as we do for the RT [1]. Alternative, a property on the PCIRequest class ('is_sriov_port'?) would be a good usability improvement

[1] https://github.com/openstack/nova/blob/78d6aca9a6cfb2/nova/compute/resource_tracker.py#L311-L314",EVOLVE
718,9fdfeff1_738bc61d,bc57a916c4045a387c69f327eb3a9e74be5b1a33,bea316d479750452a42295d9980d9dac5a89934e,nova/conductor/manager.py,573,"For sanity reasons, we should probably make this a priority to cleanup in Train because conductor is full of this RequestSpec->dict->RequestSpec stuff. I have tried cleaning up some of that before but it's tiring.",DISCUSS
719,5fc1f717_f2b9becb,b58c0a775375ac8a3180ed2444d2fe066226731b,e65a5275eeecae6ab041db2f089ae5dc3eefd92c,nova/virt/libvirt/imagebackend.py,78,"Slight nit here, we could use oslo's excutils.save_and_reraise_exception here and set the context's reraise flag to False if we get EACCESS, then we don't have to raise explicitly.",EVOLVE
720,5fc1f717_9cd72cc0,8c0c5432a00adbde921ca688aa05b8cc749f2b59,357da989c194a8b59842629cb64b2809143a4eae,nova/tests/unit/virt/libvirt/test_driver.py,8348,device_path,EVOLVE
721,3f79a3b5_957f13bb,939a61d1c6054f24b6d47b5a6f1fa90fadc0c690,47bcc39cd633cdbdca97bf8b3d94bccd127b940f,nova/context.py,445,"I think this change could make sense, but want to point out this will completely hide raised NovaExceptions that are not handled by callers. Have we audited those? Or is that intended to be a followup activity?

For example, I noticed in a previously merged review, that without this log message, we use a blanket ""cell is not responding"" message when any exception other than InstanceNotFound was raised:

https://github.com/openstack/nova/blob/1d444704a24a7103fb3cb73e451e4bff292f6467/nova/compute/api.py#L2412

and we should probably do something like log the exception message in that case given this patch.",FALSE
722,9fdfeff1_694f76bd,68d9f4baf745d0b54d80e6e750212a1e1c71e882,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/compute/api.py,4290,This indent changed.,EVOLVE
723,5fc1f717_2b32d1a8,2734b249605eb28fd1017bd8bd35fc262e03c97d,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/conf/libvirt.py,657,"I just did some more digging, and this still isn't correct, although the answer unfortunately isn't succinct.

For nova-managed disks, i.e. local root, ephemeral, and swap disks, the default is 'none' if instances_path supports O_DIRECT, or (with this change), 'writeback'.[1]

For volumes the default is driver-dependent. It is 'none' for everything except smbfs and vzstorage which both use 'writethrough', but IIRC you have patches up to fix those.

[1] Incidentally, this is obviously wrong for the imagebackends which don't use instances_path: lvm and rbd.",EVOLVE
724,3f79a3b5_0e935801,fea28d77a740c7d0472814dab63feb27d30dfc82,f13debf2f0e5377b9d0b0bbd9422c6a79d2cc611,nova/db/api.py,1244,block_device_mapping_get_root_by_instance,EVOLVE
725,5fc1f717_dc1f4259,562862b5abe4d319e4b9ab691151b3fd46fb413a,2623acaba4573738faa61658af2d6006da6918a0,nova/virt/libvirt/volume/quobyte.py,48,"Yeah, usually the pattern is:

 def foo():
     global _foo

     if _foo is None:
         with lock():
             # check again <roll eyes>
             if _foo is None:
                 do_stuff_to_set__foo()
     return _foo

...so that you don't have to lock in the ""normal"" case, i.e. where _foo is already set.

Which is why I said ""Not that that's any prettier"" :)

I don't know how frequently this thing is accessed, whether it's worth doing the above.",EVOLVE
726,3f79a3b5_7dfc600d,619b81e81f99dad4601c4e0d567d7f138562856c,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/virt/libvirt/volume/net.py,69,"This was explicitly checking secret_uuid. Could it be possible that cinder is configured with auth_enabled=True, and a secret_uuid is provided by rbd_user is not? In other words, should it be a separate conditional block for rbd_user?",DISCUSS
727,9fdfeff1_b4ea01d5,f8626235614eb3cf66b0fdf9b9c3e70d3982f03d,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,828,backporting,EVOLVE
728,9fdfeff1_02ab0a1e,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1258,"You mean store the allocations in the Selection object, right? Because the Selection object already has allocation_request but that's a json string of the allocation_requests dict entry from the GET /allocation_candidates response.",DISCUSS
729,1f769fc5_23898422,cf7ee45e840925530d0f0a961ab8d6e1ccb481ca,a1dba961f0018a4995d208a290f4a859ce295840,nova/api/openstack/wsgi_app.py,16,"Tried this patch without this line in https://review.openstack.org/#/c/620561/15/run_tests.sh@222 (wsgi Fedora python3 deployment) and it's working(just 1 tempest test test_add_remove_fixed_ip is failing([1]) which seems regression of https://github.com/openstack/tempest/commit/d4cb10f1451af0d204722ea57eb52d46ebde783b), Seen 1 pass in CentOS so seems an intermittent but a valid issue.

https://logs.rdoproject.org/61/620561/15/openstack-check-rdo/puppet-openstack-integration-5-scenario-py3-tempest-fedora-28/1af14f9/logs/testr_results.html.gz",EVOLVE
730,ffb9cba7_547d38e5,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/conductor/tasks/live_migrate.py,375,"this should really use kwargs, given the amount of arguments here now",EVOLVE
731,bfdaf3ff_fd49fe5f,b19c2b7ccacfe3c464d1512049b0d2bc64b81350,5f9c8b45ffc5c2b9da5e3da6f2b4214b391d9900,nova/virt/hardware.py,1298,nit: I kind of feel like it'd be nicer to specify whether it was the image or the flavor (or both) specifying bad policies.,EVOLVE
732,9fdfeff1_588dd128,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,726,Can we remove this?,EVOLVE
733,9fdfeff1_a7ed19f1,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,1715,maximum,EVOLVE
734,9fdfeff1_8e064120,701d653b5ac9a85fe691c77d6d0611f690d00d3a,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,170,I wonder if there's some other way we should be checking this that doesn't rely on a free-form field?  I see the 'HV_DRIVER_QEMU' attribute defined in nova/virt/libvirt/host.py but I imagine we don't want to be importing libvirt specific code here,DISCUSS
735,3fce034c_fc880a72,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/cells/messaging.py,1015,"likewise, why not remove this block and the _sync_instance method? AFAICT not used anywhere else.",DISCUSS
736,3fce034c_c1a42dbc,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7280,"note:

doing the pop of the instace here is really hard to follow.

this only works because instance_uuids is effectivly an alias of self._instance_uuids_to_heal so when we pop
instance from the instance_uuids it modifies self._instance_uuids_to_heal",DISCUSS
737,9fdfeff1_ade90ab8,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/compute/manager.py,8373,nit: Can't you just use 'objects' here?,FUNCTION
738,5fc1f717_1ad72ef0,ced9c58503ed539787deee4d540b201445d03419,99ad674c26fdacfff72d84624ee060cf0e33304b,nova/privsep/linux_net.py,156,"Why is this any more horrid than many of the other things here? Unless this is for shock value to push a change later, I'm not sure that the _horrid bit is really necessary or useful here.",DISCUSS
739,9fdfeff1_0ebcc7b9,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,90,"Hmm, the partition_key is case sensitive here but according to the ironic config docs, the conductor_group option there is case insensitive:

https://docs.openstack.org/ironic/rocky/configuration/config.html#conductor.conductor_group

Is that also what gets exposed in the API for the node.conductor_group? I'm just wondering how we deal with case issues if let's say we have FOO in nova and foo in conductor config - will that work? Clearly most sane people would probably have config management setting the same values in both configurations, but I'm just wondering out loud.",DISCUSS
740,9fdfeff1_6ac272eb,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,139,Would be nice if these were defined in a variable in fakelibvirt so we didn't have to know where these are coming from and how they are matched up.,FUNCTION
741,9fdfeff1_b35ffbe3,26a3a718cbdaa6d3aa5121b684c5752724a572d6,3cfcd117ce7ddb5a8d94396191cde559db73fb86,nova/virt/xenapi/agent.py,431,"If the issue is that the command succeeds (exit code 0 presumably) despite printing to stderr, perhaps the right answer is to base your failure condition on the exit code rather than the emptiness of the stderr stream.

One way to do this would be:

 try:
     out, err = processutils.execute(..., check_exit_code=True)
     if err:
         LOG.warning(""OpenSSL stderr: %s"", err)
     return out
 except processutils.ProcessExecutionError as e:
     raise RuntimeError(
         _('OpenSSL errored with exit code %(exit_code)d: %(stderr)s') %
         {'exit_code': e.exit_code, 'stderr': e.stderr})",FUNCTION
742,3f79a3b5_32e399a1,799cbf1885975a0ea6f11c01100cb0fb91eaf06d,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/tests/fixtures.py,824,"It is nice to ignore such many warning messages at this time.
I feel it is nice to write NOTE which explains we can remove this 'ignore' after removing mox from all unit tests as Natsume-san is doing.",DISCUSS
743,9fdfeff1_4cd5b742,6cd52cfe9e2abe16a2a2a75659a031e07ad345e0,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/test_servers.py,2530,nit: this is copy/paste but doesn't make sense here since it's going to trigger the failure,EVOLVE
744,9fdfeff1_1f150a40,5158327bc8a2fbc4c3cabcf3fd964e5f61285fa1,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,745,ignore,EVOLVE
745,9fdfeff1_8e67ca4d,9cb825b0147af3b191ea2989e5187e4afdadcb15,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/conf/base.py,29,"this lets us remove some validation, see comment in utils.py",FUNCTION
746,3f79a3b5_ceec2429,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,3633,"all this code is related to changing the image, which can't happen in this code path, so it can all be removed.",FALSE
747,bfdaf3ff_f9f7b2f4,ae26aaacb12e2ccfca1ef0777441f3faab02d433,d2e13e6af091603228d858cc770b9089a91bd24a,nova/compute/manager.py,558,"not entirely sure why this is here... perhaps to prevent multiple copies of the reportclient's ProviderTree cache from being created?

If so, probably fine to just do this:

 @property
 def reportclient(self):
     return self._get_resource_tracker().reportclient

and not have the self._reportclient variable at all...

it's literally just a pointer redirection anyway.

Alternately, you could create the SchedulerReportClient() as an attribute of the compute manager and pass it as an arg to the ResourceTracker() constructor...",FUNCTION
748,3fce034c_554b5e86,82c79ceac30d7b97d68c2d71bdd0aae8c7038811,f389773f5255051f2f1cff4d0b0a08eafc0ac147,nova/tests/unit/privsep/test_libvirt.py,154,"I see os.O_NONBLOCK is 2048, so this happens to be safe, but if the bits overlapped, this wouldn't prove anything. Possibly worth an explanatory comment that we're actually relying on the value of os.O_NONBLOCK not overlapping with 32769. Or, if you're going that far, just hardcode the expected value as 34817.",EVOLVE
749,9fdfeff1_9c3bf637,2f21b1ba50e92311bc38426363ff09c495c81a05,a76eefed62db96fe51ef40e3209c187af3eb9834,nova/tests/functional/libvirt/test_reshape.py,115,"? I guess this is your way to fail if there is more than one key in mdevs? That's kind of gross IMO - why not just:

self.assertEqual(1, len(mdevs))?",FUNCTION
750,dfd5e7cf_b9b82c2a,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/conductor/tasks/live_migrate.py,323,"nit: don't think we need to wrap here, though I haven't checked",EVOLVE
751,9fdfeff1_6fd7e424,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,649,nit: this can be a staticmethod,FUNCTION
752,5fc1f717_cabceb07,81b0e5a0680883d68d12253af64f8e10200df746,4ede35281160b8d988ef5b775b97d81950d0c6e1,nova/virt/ironic/driver.py,910,"It doesn't look like we save this in the cache anywhere (nor do we at L925). I guess the thinking is that we'll just wait and update it at the next loop anyway.However, the problem is that this makes two subsequent calls to get_info() return different data if use_cache isn't consistent. I dunno if that happens anywhere, but it'd be something I would try to avoid for the future when someone puts another call somewhere in a cleanup routine or something. Because you might've headed down a path based on non-cached info, and then fail to clean up (or do anything else) based on the cached info.",FUNCTION
753,9fdfeff1_b755ba52,fb10f7ed0cd1566da3e068490300b1ebd053af8f,d89579a66ac38fd1e30cea55306e6e7b69bab5b9,nova/virt/hardware.py,313,does the change to InvalidRequest get unit-tested anywhere?,DISCUSS
754,9fdfeff1_47f3760b,29d617457be6c5d8a9cd01dd5b533204166cada3,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/libvirt/driver.py,7111,extra ws,EVOLVE
755,dfd5e7cf_6fdd1213,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/compute/test_compute_mgr.py,8462,"could we use somewhat valid values here, again on account of how poorly understood this stuff is",DISCUSS
756,9fdfeff1_f04dd5c3,e710df769b460b2a489cf620598504bc875c3b08,ecfdec5a6ed0de56c4a5b1649a17f5f229d9470b,nova/network/os_vif_util.py,296,"for anywone wondering why this is not VIFDirect
https://github.com/openstack/os-vif/blob/master/os_vif/objects/vif.py#L101-L119

VIFDirect is actully macvtap because reasons.
https://libvirt.org/formatdomain.html#elementsNICSDirect

we might remove or rename VIFDirect at somepoint once i confirm no one is using it for dirct mode sriov.",FALSE
757,9fdfeff1_894e5a36,35cbe9290cef244142522f6bcc253888460d09ea,ecea762eb9f6a15f1006ad574c5ab6c8a9cb24c5,nova/api/openstack/common.py,567,Side nit for future thinking - could we re-write this to just check the instance info cache for VIFs with a profile entry that has the 'allocation' key now?,DISCUSS
758,9fdfeff1_98d44249,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,726,"LOG formatting does not work this way, should be {""version"": ""1.46""}. Actually, why are you formatting a constant? :)",DISCUSS
759,3f79a3b5_c6666029,fcb26b5401ccd01e91577af4111d79b605788889,88951ca98e1b286b58aa1ad94f9af40b8260c01f,nova/exception.py,98,"This isn't *strictly* accurate anymore.

But it's probably fine.",FALSE
760,9fdfeff1_77a8b21f,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/functional/test_servers.py,5837,"not sure why you want to remove this comment, but okay. Sure, you test later in 6302 this, but meh.",EVOLVE
761,9fdfeff1_fb3f88b2,d9bd5b1377acf4468c89422fa471de6c8325d775,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/compute/multi_cell_list.py,427,Fix the alignment here.,EVOLVE
762,9fdfeff1_fb49c831,d9bd5b1377acf4468c89422fa471de6c8325d775,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/tests/unit/compute/test_instance_list.py,218,Seems you could copy and add a test based on this which passes cell_down_support=True and verify an exception isn't raised.,DISCUSS
763,9fdfeff1_0b46557c,cfc1cb218c2f4824819ecd36c391a251995f3a16,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,215,Huh? We haven't had to do this for years. The manifest takes care of this for us.,EVOLVE
764,5fc1f717_6f86b7de,8cd5d73dc180fc51b95637e9eeb6689fb773dae4,f58f73978e3c533304b06a4d1eb6abe3f229bc10,doc/source/conf.py,39,Why removed? Should make mention in commit message.,DISCUSS
765,9fdfeff1_b201f13a,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/tests/unit/api/openstack/compute/test_serversV21.py,7552,"We should also have a test wrinkle where image is not set so it would be an empty string.

So I think if you just added another test server which satisfies the conditionals (image, AZ and user_id) that would cover those.",FUNCTION
766,5fc1f717_26944837,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/tests/unit/pci/test_request.py,74,nit: newline above here,EVOLVE
767,3f79a3b5_9384d358,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/policies/servers.py,159,"Does this also affect resize? We count quota during resize to make sure the new flavor doesn't make the tenant go over quota.

https://github.com/openstack/nova/blob/6e8a69daf14a15fe0b0633f21f4112f19487e9da/nova/compute/api.py#L3426",DISCUSS
768,9fdfeff1_b7ea55a9,d0d51a653a25a651e204b940957d0eb3c85798e5,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,598,nit: this could be updated to mention dns_name as well.,EVOLVE
769,3f79a3b5_a6c6ef9a,36c992f72d988ff20e3e286c1065aa76db5aec03,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/cmd/test_status.py,631,"We shouldn't be doing this mock here since we have a db backing this test, it looks like we should just call cn2.destroy() after creating it as you suggested, or just set allocation_ratios on it like I suggested:

https://review.openstack.org/#/c/613499/9/nova/tests/unit/cmd/test_status.py",EVOLVE
770,3f79a3b5_75d277d2,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,240,"I did a couple of tests with devstack and found that console.log truncation happens for a normal, non-rbd instance during both soft and hard reboot. FWIW.",EVOLVE
771,dfd5e7cf_a0b57bf0,05f9beac77d3481fe41baa3ae6fb4d35385e8d79,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/conf/libvirt.py,487,Is there any check in the code that prevents the use of the two flag together? What will happen if both flag is set?,DISCUSS
772,9fdfeff1_d7507e61,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/tests/unit/compute/test_compute_mgr.py,1823,same,DISCUSS
773,9fdfeff1_333ff425,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/network/neutronv2/api.py,1739,"We don't know, so let's say ""may be"".",EVOLVE
774,5fc1f717_8d6221d8,67d5970445818f2f245cf1b6d9d46c36fb220f04,29e5b0ad7bde210f95885656768f0480d06882c0,nova/objects/request_spec.py,542,"Seems like maybe all of these should have default=None and just use obj_set_defaults() here. This works too, but it's a little less obvious I think (hence all the comments).",FUNCTION
775,9fdfeff1_af27d9c7,1ad3466a277d695c46142fe7e45b91b34b7674dd,eb93d0cffd11fcfca97b3d4679a0043142a5d998,nova/api/openstack/compute/instance_actions.py,177,"How about putting NOTE why Nova needs to use instance.project_id here like the commit message?
Periodic tasks could be forgotten easily, and the NOTE could help us.

Nice work anyways.",EVOLVE
776,9fdfeff1_d65a8981,5b8f5a201d72c3e45938a1eb020c913fa0d51efe,c0cd8fe8c1cb217063eacfa8aa3d4d46093c71a0,nova/api/openstack/compute/servers.py,459,this doesn't seem to be true,EVOLVE
777,9fdfeff1_93e820b3,d4a0e470fe9987950bc84ae2f658232bde8d95c7,33aad0fe41d86721c869d7c0d47cede2e500188f,nova/tests/functional/notification_sample_tests/test_instance.py,1537,Here,FALSE
778,dfd5e7cf_7b1e660d,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/block_device.py,527,I think this change should be done in the previous patch that introduce generate_device_name(),FALSE
779,5fc1f717_7bea01ad,82d2f6d2e399161d414e28b841323b9e8ad50563,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/virt/libvirt/utils.py,557,...then you could remove this,FUNCTION
780,5fc1f717_2fcb0a1e,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,673,same as above,EVOLVE
781,ffb9cba7_dfd74e23,2341f82533effbd21c993199b8f01953f1e0e7c4,b7a018f1265d9e0354e26822d32cbdc789819c35,nova/virt/ironic/client_wrapper.py,132,"This should be lazy loaded.
> ""Adapter.get_endpoint %s"", ironic_url_none_reason)",FUNCTION
782,9fdfeff1_52515bd8,65910122ef5d66d6804c3138f16f7e989be162ee,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,251,"seems true, maybe we don't need to ignore these, is the consideration tha there could tones of delted instances and thats going to take alot of time?",FUNCTION
783,dfd5e7cf_a74a6724,5b2021575a618d603685b97b694934c857e6f9c6,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/virt/libvirt/test_utils.py,523,ditto,FUNCTION
784,9fdfeff1_930d8090,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/tests/unit/network/test_neutronv2.py,4913,"I wouldn't have thought about using this, but it works. I probably would have mocked the LOG.warning call and assert it was called with the expected message, but this works and doesn't require mocking or caring what the logging level is.",FUNCTION
785,9fdfeff1_7b91aaf7,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3572,We don't need to do this validation if same_instance_type is True (cold migration so the flavor doesn't change).,FUNCTION
786,9fdfeff1_067e4c69,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1655,"If you're having to do this, I'm inclined to say you should ditch @retries and use @retrying.retry instead - see aggregate_add_host and aggregate_remove_host.",FUNCTION
787,9fdfeff1_736186a8,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/tests/unit/compute/test_compute_mgr.py,6612,Drop the intend a tab.,EVOLVE
788,bfdaf3ff_f90d7237,100ef6e2471a23c99e2f323d3a838dcca1fa9d43,562ba3958648cf3d7c0a1e23cd570baef69e9831,nova/privsep/linux_net.py,100,"It probably would have made more sense to combine the three of these, but that's a nice cleanup for later",EVOLVE
789,ffb9cba7_1b14fa9f,6eaa6db0ee01ee5a7b56bc3176914d85e697b96a,13278be9f265e237fc68ee60acfacaa1df68522e,nova/virt/ironic/client_wrapper.py,137,"Looks like this was handled since Ifc7b45d047c8882a41021e1604b74d17eac2e6e8 and that goes back to rocky so we should be good to backport at least that far, but it looks like before that there is an os_region_name kwarg (for queens) otherwise region_name would just be ignored. Reminder to myself for backports.",FALSE
790,9fdfeff1_4e3f46d6,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1049,multiplier_name,EVOLVE
791,dfd5e7cf_397e7c6b,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/conductor/tasks/live_migrate.py,350,"I'm inclined to say we should just use for loops rather than dictionary comprehension here, as this is pretty tough to parse",FUNCTION
792,9fdfeff1_37d425e9,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3473,"you can wrap line like this:

(self.req.api_version_request =
       api_version_request.APIVersionRequest('2.70'))",FUNCTION
793,3f79a3b5_7c3b9199,953aaea65091ead541def6cf56f56a23d899d7c9,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/db/api.py,1243,"This should be updated like:

Get the root block device mapping for a given instance.",EVOLVE
794,9fdfeff1_a1007335,900fe1c2e8e90be914f283563c0664439db54b5a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5003,The else case is completely missing here. This is a functional change!,FUNCTION
795,9fdfeff1_c33e88b8,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,47,Why don't you test live migration *with* a requested destination host?,DISCUSS
796,3f79a3b5_74fc480b,57637821a5a9b064ebe999a138d14256da961429,cfd07002ba679aec993cf67d5b604b21240c4142,nova/objects/virtual_interface.py,171,"list comprehension?

  [x for x in old_vif_list if x.uuid == port.get('id')]",FUNCTION
797,9fdfeff1_8a72f1ac,c0fd216780cfa9c17da385af63fa743d40434fa0,fe88d9e2c33af94139dbae896b95dcc45c412798,nova/virt/libvirt/driver.py,4959,Looks like we're dropping the check for 'CONF.serial_console.enabled' from this code path? I'm guessing we shouldn't do that,DISCUSS
798,5fc1f717_4bd86a52,ddc0aba5a54377178a5b2748afe2718aabbc267e,3b4d1303d03e6df57ec28d4d72756bebd62d7115,nova/objects/instance_mapping.py,279,I don't get this conditional. Can someone explain why this is here?,DISCUSS
799,bfdaf3ff_2d317f0c,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/provider_tree.py,262,"Recommend having get_provider_uuids() do one thing only. Consider adding a get_provider_uuids_in_tree() method that does the tree-traversal stuff you need to call from the resource tracker in these special circumstances. Having boolean arguments that change the returned result value or behaviour is a code smell, IMHO.",EVOLVE
800,3f79a3b5_624dcd92,80881918f676d218d076ca30a66214c312dd089f,a1dba961f0018a4995d208a290f4a859ce295840,nova/network/os_vif_util.py,502,unbound,EVOLVE
801,3f79a3b5_15ecc7ba,0ad0e879381eca21fae748cb5470b1e9818f8930,f13debf2f0e5377b9d0b0bbd9422c6a79d2cc611,nova/virt/powervm/driver.py,203,"though hast made a most grave mistake:

2018-10-31 22:08:01.683516 | ubuntu-xenial | ./nova/virt/powervm/driver.py:32:1: F401 'compute_utils' imported but unused",FUNCTION
802,9fdfeff1_26b522ce,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,762,is not supported,EVOLVE
803,3f79a3b5_772ee65b,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,166,"This is confusing. A better comment would be useful here. I think the gist is, this block is removing tracked PCI devices from the manager if (a) the hypervisor is no longer reporting those devices or (b) the PCI passthrough whitelist is no longer matching the devices reported by the hypervisor.",EVOLVE
804,3f79a3b5_c4796381,4ebd2504bb27afac7184d254aa6556fe61493a5d,fae92384a3d2d3299f7e25419b16ec7534f9233a,nova/tests/unit/conductor/tasks/test_live_migrate.py,636,"Was this something your editor happened to do for you, or was there a more specific you did it?

People might declare it unrelated, but meh, it's a nice cleanup.",DISCUSS
805,3fce034c_d58dc331,c0db968abc47672abac9c2a99554cece5c642d2f,acd64d1d805ad36004bc4c23d74ed7490bd43857,nova/tests/unit/scheduler/test_utils.py,465,This should be fake-host or the compute node host value should be 'test'.,FUNCTION
806,9fdfeff1_afb70c21,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/api_version_request.py,177,``POST /servers/{server_id}/action`` (rebuild),EVOLVE
807,5fc1f717_fc420c0f,43ce926dccae9e60611b1224ab06dcad8f650fce,b7bd97bc8896346e92d271a443d5ada9ab0074be,nova/compute/manager.py,1396,"I think this would be clearer as ""instance_uuids""",EVOLVE
808,9fdfeff1_0ddd4013,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/functional/test_servers.py,6325,Same - would be good to assert the allocation was set on the port prior to detaching it.,FUNCTION
809,3fce034c_a4b6a1f9,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/compute/manager.py,7189,"i think we can check for it and is_neutron in one conditional

i.e
if not utils.is_neutron() or self.driver.manages_port_binidings():
    return False",EVOLVE
810,3f79a3b5_c6fd59b9,364724ba6f7442cbaedcb270498cad549a571449,d1e38f06bb5282dd9bf81d979926a0ebbfd93caa,nova/image/glance.py,279,"it feels a little weird to me that we are calling methods by string value instead of just doing
self._client.list(context,**params)

i guess that would be part of the rewrite the module you were refering to in the commit.

anyway this makes sense its jsut intally i assumed
_client_method would be a http metod such as GET or POST but the fact its the name of a python method i find strange.

the change looks correct however based on what was stated in the commit message.",FUNCTION
811,5fc1f717_3386f015,74ef3a67096ca8203cd344e4ee32c71ab340ab1b,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/tests/functional/integrated_helpers.py,249,Why is this removed? I guess because nothing is passing False to it anymore.,DISCUSS
812,dfd5e7cf_61aa19d3,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,211,break?,FUNCTION
813,9fdfeff1_52744536,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,167,"nit: You might add, ""If 'flavor' is not in the instance then it is GET /servers/detail and we do not expose the flavor in the response when listing servers with details.""",EVOLVE
814,9fdfeff1_45f06a92,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,3596,"What about calling get_pci_requests_from_flavor here to validate the new flavor as mentioned:

https://review.openstack.org/#/c/620706/27/nova/api/openstack/compute/servers.py@a857",DISCUSS
815,9fdfeff1_75a11c46,1d44fbddefb11421523c8ae5815642da0e22f8ea,8364abecfafdbe2a7f65ea5e7b787bcbb6412844,nova/objects/request_spec.py,843,Ã¢Å“â€,DISCUSS
816,bfdaf3ff_da6c0b38,8f328c03b266b0d17da2f0e92ad319aa603c8e41,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/compute/manager.py,2320,This is what I was mentioning from change I20a5e8e5e10dd505c1b24c208f919c6550e9d1a4 to get a more specific error message into the fault.,EVOLVE
817,9fdfeff1_38106459,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1374,"raise_exc=False isn't necessary since I477afdfce746d405adf77134f57670563fd575e1

(I realize this is a straight refactor; this could be cleaned up later.)",EVOLVE
818,9fdfeff1_b948688a,55f455262144ab319a9ff480850aeece88b1dedb,20a46ece5701c9798a5e0df12c944237cb1ece3e,nova/scheduler/client/report.py,1758,"This seems like good behavior, but why aren't we actually looking at them? For really any operation, if we grew a new allocation for the instance, maybe due to external influences like a new volume or network allocation, this could potentially be fooled, right?",DISCUSS
819,9fdfeff1_8f3cdfbf,d0d51a653a25a651e204b940957d0eb3c85798e5,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,1523,"nit: might be better to name this parameter ""client"" or ""neutron_user_client"".",EVOLVE
820,3f79a3b5_87c32659,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,224,"This is kind of code-speak. It would probably be more clear to say, ""using ``[libvirt]/images_type=rbd``.""",EVOLVE
821,5fc1f717_913b9c36,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6724,"Can we please call this _free_pci_devices_for_instance() so that it is clear what this is doing? There is a very specific thing called ""instance allocations"" that refers to the placement allocation records for all the normal resources associated with an instance, and naming this method _free_instance_allocations() when it doesn't have anything to do with the ""instance allocations"" is supremely confusing.",EVOLVE
822,dfd5e7cf_dda41c0b,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,902,this should be same with your host1 obj,FUNCTION
823,5fc1f717_b34420b9,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c,nova/compute/api.py,566,I think we can remove this in a follow up as well.,EVOLVE
824,3f79a3b5_f76af680,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,180,allocated,EVOLVE
825,5fc1f717_3a7d4a1c,ced9c58503ed539787deee4d540b201445d03419,99ad674c26fdacfff72d84624ee060cf0e33304b,nova/tests/unit/network/test_linux_net.py,977,"I think this is just whitespace damage, and not in a good way.",EVOLVE
826,9fdfeff1_2dc12455,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/functional/integrated_helpers.py,356,"Another way to skin this cat is to wait for the interface_detach.end versioned notification, right? But maybe the test that is using this isn't using the fake_notifier so this is more generic.",FUNCTION
827,9fdfeff1_ce3c4932,debff531a8f0906cbdd38fbbb75e4c351d43412a,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1339,nit: extracting the calls into fucntion was not in the commit message but by doing so you have documented them significantly better then before so +1 :),DISCUSS
828,5fc1f717_3cc15830,3b86bba2dc4fc64e5768ae90267c20c095eef9fb,926e584136e7dce59f32065292aa4eb8120f628c,nova/cmd/manage.py,1911,"I don't think I had an else on this because the if block above either returns or raises, and it still looks weird to me to have an else block here since we wouldn't hit this code regardless, but I suppose I should look to see what's changed after this.",EVOLVE
829,9fdfeff1_f3440cba,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/network/neutronv2/api.py,1740,Throw the instance=instance kwarg in the warning() call as well.,EVOLVE
830,9fdfeff1_d62c569a,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,143,Same as above - why no links?,DISCUSS
831,9fdfeff1_0e20119b,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,104,"likewise, could use report client methods to pull the provider tree",DISCUSS
832,3f79a3b5_0eb751d3,c6380461f02b1a95551f26d27fd0af21f4bbb721,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/api/openstack/compute/services.py,247,"Yet another location where the service and compute node concept is being equated. :( They are not the same. There can be thousands of compute node records (and thus, resource provider records) associated with a single nova-compute service when Ironic is in use. This code is just flat-out buggy for Ironic...",FUNCTION
833,9fdfeff1_4d17c8ef,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/scheduler/client/report.py,1758,"And we might have a chance on retry because if we failed on a generation conflict, then on the next pass we'd fetch the current allocations with the current generation. At least that is the idea correct?",FUNCTION
834,5fc1f717_bfe4b50f,71e5c9ea4da49e6ef86cc176ac24216186db1092,3aa702686ba0e01e8931585636da8d9535098923,nova/hacking/checks.py,861,Merge docstrings,EVOLVE
835,3fce034c_ab3f6923,790b1dda86117acf4ce557f4d9e970d2484f1826,5868303f2c33021310eb4fade97828ef1757dc6b,nova/tests/functional/api_sample_tests/test_cells.py,17,"pep8 failure:

./nova/tests/functional/api_sample_tests/test_cells.py:17:1: F401 'api_client' imported but unused",FUNCTION
836,9fdfeff1_6d9c47bf,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/tests/unit/conductor/test_conductor.py,2104,"These would be better as Mock.assert_not_called() and Mock.assert_called_once() because if they fail they'll give better error messages than ""False is not True"" etc.",FUNCTION
837,5fc1f717_3b482c5a,a84a40676dcb12608363210072049bf01d720073,7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4,nova/privsep/libvirt.py,288,x,EVOLVE
838,3f79a3b5_93fd7d0b,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,nova/scheduler/client/report.py,794,"traits, aggregates and inventories",EVOLVE
839,5fc1f717_1d0ea43a,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,6734,likewise,FUNCTION
840,9fdfeff1_a874d8cf,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,188,assigning,EVOLVE
841,5fc1f717_b675fc33,afe767e332c0e07ef4a8ba4feca0cefe66c04f81,886850f50f62e97a5661d68c1689fdc932fb7b61,nova/conf/libvirt.py,657,"This is only true because we explicitly make it so. We *always* specify disk cachemode explicitly, so this comment isn't really relevant.",EVOLVE
842,1f769fc5_73d6a052,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/tests/functional/test_conf_max_attach_disk_devices.py,117,"The functional test fails here like

Traceback (most recent call last):
  File ""/home/zuul/src/git.openstack.org/openstack/nova/nova/tests/functional/test_conf_max_attach_disk_devices.py"", line 117, in test_attach
    self.assertIn(expected, ex.message)
AttributeError: 'OpenStackApiException' object has no attribute 'message'

and the wsgi seems to return as here expects:

 nova.exception.TooManyDiskDevices: The maximum allowed number of disk devices: 2 to attach to a single instance has been exceeded
 2018-12-20 19:51:26,107 INFO [nova.api.openstack.wsgi] HTTP exception thrown: The maximum allowed number of disk devices: 2 to attach to a single instance has been exceeded

Maybe here should be

 self.assertIn(expected, ex.response.text)",FUNCTION
843,5fc1f717_88616f14,b096d9303acfea81ca56394cab681d2b2eed2d91,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,700,We're in a loop but the return here is OK because we're in a reschedule block and in that case we'll only have one instance.,DISCUSS
844,9fdfeff1_fa8746b4,41b982c9feec3105247bc72d23d1470bcabc3a0f,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/compute/test_compute.py,10766,"This would be covering the non-shelved case, so with the below assertion of not being called in the shelved case we should be covered.",FUNCTION
845,3f79a3b5_ba7345e5,7009a4e5c9c2e0ecb78fdfe4c1f2fc7514f39990,1e8c2c0dcb3ff9225407b890a6c99658b35764bc,nova/conductor/manager.py,1287,You missed this - this is why you should rebase on my change.,FUNCTION
846,9fdfeff1_f919107a,47163c365bd986cddd8a9f87abcc1db590a01573,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/tests/unit/virt/libvirt/test_driver.py,8830,"As later, it seems like it would be more sane to create a LibvirtLiveMigrateData object here as elsewhere. That can be a later cleanup though",FUNCTION
847,3fce034c_326added,26e8d1a28a8b7dac4e42c97ababf719c3672fe28,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/tests/unit/compute/test_compute_mgr.py,4960,"you need to assert that _requre_nw_info_update is returning false as well :)

also do we have the other way covered ? e.g when compute driver returns True when calling manages_port_binding ?",DISCUSS
848,9fdfeff1_2b282784,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,342,This is kind of weird that we pass in show_server_groups=True but then are also checking the microversion. Why not just have the caller pass in show_server_groups based on the microversion? Because when this is called from detail() you're going to be checking the microversion for every instance even though show_server_groups will always be False for detail(). Just have the caller figure out the microversion and pass in show_server_groups and honor that boolean.,FUNCTION
849,9fdfeff1_cf74d06a,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/servers.py,815,"Why do we show server_groups but none of these other things? Meaning, if the server update response is meant to be more minimalist to match only what could be in the request, why return server groups (which can't change as part of the update)?

I guess we kind of broke this when we started showing the embedded flavor and trusted certs because the version check on those is in the view builder itself rather than in the caller.",DISCUSS
850,bfdaf3ff_a32b292e,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/objects/test_numa.py,151,note to self: This refers to 2GiB pages.,FALSE
851,5fc1f717_5864dee5,ef2ea8f1f4b717299b988eb3765a346ebd51ddf8,a37b16610de0c09ea99b4e8a731b82e5bc1bd229,nova/tests/functional/libvirt/base.py,52,The FakeLibvirtFixture() has a stub_os_vif flag to stub out plugging. It is defaulted to True so at L45 the 'nova.virt.libvirt.vif.LibvirtGenericVIFDriver._plug_os_vif' is already mocked.,EVOLVE
852,9fdfeff1_33008202,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/tests/unit/virt/test_hardware.py,1293,ditto,FUNCTION
853,9fdfeff1_8e4641c0,debff531a8f0906cbdd38fbbb75e4c351d43412a,55f455262144ab319a9ff480850aeece88b1dedb,nova/tests/fixtures.py,1418,"technically the name is  ""Port Bindings Extended""
https://github.com/openstack/neutron-lib/blob/master/neutron_lib/api/definitions/portbindings_extended.py#L43",FALSE
854,9fdfeff1_0a8bb8bf,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/compute/manager.py,5957,"This comment about the RPC cast is not true in all cases (attach_interface is a call, detach_interface is a cast). I would just remove the comment.",EVOLVE
855,9fdfeff1_49153b3c,da972e3432ef0f7a242510a52484bc5660d9806c,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/driver.py,160,"Initially I thought, this seems like an ironic-specific kwarg, but really any driver could implement a cache for this. So, I think it does fit in a generic way across any driver.",FALSE
856,bfdaf3ff_3aa2f74c,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3002,"It would be better to use constant here, but anyway it is not defined...",FUNCTION
857,9fdfeff1_ea90a250,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6292,ditto,EVOLVE
858,dfd5e7cf_9dae94e5,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,915,ditto,FUNCTION
859,5fc1f717_b538c8d2,3ba244a741f8fce023ad129628e96471f521aec6,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,nova/tests/functional/test_servers.py,4049,So can you now remove this goofiness from the base class?,EVOLVE
860,9fdfeff1_3aeaaeab,135889d8b5991ec249a31767f5a11fd89908e38f,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/tests/unit/objects/test_request_spec.py,896,nit: set some 1.0 field on this which you can assert is still there after the object is converted to 1.0 form.,FUNCTION
861,9fdfeff1_8626bcca,cfc1cb218c2f4824819ecd36c391a251995f3a16,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,42,"I don't think this should be nullable. I think if we load this from the DB and the column there is null, we should look further to find out what it is (i.e. look at the reqspec, or buildreq if it's there, or maybe even look in the cell).

I'm not sure where this is used yet, but since it wouldn't be for quota-querying purposes anyway, I don't think there's any good reason to have this be nullable for compatibility while we're migrating.",FUNCTION
862,9fdfeff1_f02d1095,74ce522ad847ad84220ee155adf8b008f51c49d5,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,5628,"I guess the only concern here would be if this call can race too, in the context that's being described in the bug. I don't know what get_by_volume_and_instance does, so *shrug*?",FUNCTION
863,9fdfeff1_32acc5eb,77726e30792ea101c9ca3eb78beed8fd4d64f13e,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,345,"This could be anything, it would be better to assert that ""Unable to remove device with"" is in what was logged, which you can do like this:

call_args_list = log.call_args_list
self.assertEqual(1, len(call_args_list))  # assert called once
self.assertIn('Unable to remove device with',
              call_args_list[0][0][0])  # first call, args, first arg",FUNCTION
864,9fdfeff1_77c37639,9ba910bb539b0172bab899852692a49d30645a14,a5d6833d77c961ea75488f0992b91d3166424381,nova/network/neutronv2/api.py,1895,"nit: ""port-resource-request""

https://review.openstack.org/#/c/584903/10/neutron_lib/api/definitions/base.py@110",EVOLVE
865,3f79a3b5_b31d4f11,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,181,"I think this is why tests are failing, you're breaking the signature contract.",FUNCTION
866,9fdfeff1_8b99137a,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/api/openstack/compute/servers.py,811,"It kind of sucks that we have to call this so early but I don't think we have any obvious places in the API resize method where we get ports so we could just piggyback on that for the validation.

Do we store the port resource request information in the info cache at all? If so, we could just check the info cache rather than doing a GET /ports from neutron which would be better for performance. Could also be a TODO for later if there is a need to store that information in the info cache (I feel like we've talked about using the info cache for a few things in this series).",FUNCTION
867,9fdfeff1_28b92414,d8f6882f547bd1a92fb38de5aed287d56bf8b233,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,624,why don't we call this method 'get_best_cpu_topology'?  It will call this method and also '_get_possible_cpu_topologies'. '_get_possible_cpu_topologies' will check the possible cpu topo also.,FUNCTION
868,5fc1f717_5b82a502,82d2f6d2e399161d414e28b841323b9e8ad50563,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/virt/libvirt/utils.py,550,"weird. Why not

 host_arch, machine_type = mapping.split('=', 1)

(currently (mostly) a copy/paste, so unrelated, no need to change it here)",FUNCTION
869,9fdfeff1_ca3b7099,6c239c2390799fef03ba4f7d00762a4a96f62819,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/tests/unit/scheduler/client/test_report.py,3456,This is definitely nicer to assert and clarifies the test. Thanks for adding these.,DISCUSS
870,9fdfeff1_cf5e3912,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/virt/hardware.py,190,general note that splitting the hardware.py changes out to a subsequent patch would have reduced the cognitive load on reviewing this change...,FALSE
871,3f79a3b5_6e4c4cca,be9a21a61c94ff37e664ae18d1ca8a2fcebf7a7a,47bcc39cd633cdbdca97bf8b3d94bccd127b940f,nova/objects/cell_mapping.py,282,"GROUP BY in SQL is used when the qeury contains aggregate functions, like sum() or max().  I don't see any of those here, so there's no need to use GROUP BY.",FUNCTION
872,ffd0ebdf_b2065520,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1050,"We could use validate_num_values for this also. Those two utility methods are how filters like AggregateCoreFilter get the allocation ratio metadata from 0 or more aggregates the host is in, validate the type (float) and pick the min if there are multiple. We should do the same for the weigher code.",FUNCTION
873,5fc1f717_9b3da0bc,a84a40676dcb12608363210072049bf01d720073,7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4,nova/privsep/libvirt.py,282,x,EVOLVE
874,9fdfeff1_53be7dd5,dea83854c42e30195d6b6794d102fa44c3ad0b72,35ce77835bb271bad3c18eaf22146edac3a42ea0,nova/scheduler/client/report.py,826,super-nit: newly-added,EVOLVE
875,3f79a3b5_7b8a8c65,d6172354e1e02d37bfcf37c0748a0dba0f7bd685,3e756ff674e5da58b854b6b65ae225e3f7f97556,nova/quota.py,1197,"as you know, all the policy enforment have been moved on API controller layer side long back. Can we move this check also on API controller side, with passing that info down till here? Not sure how easy that will be, thought ?

spreading policy enforcement all over the code make it hard to maintain and it can eaisly end up enforcing this policy for other APIs also.",DISCUSS
876,9fdfeff1_d3dab277,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/compute/manager.py,1564,wee!,DISCUSS
877,9fdfeff1_bf5923ff,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,985,ditto,DISCUSS
878,9fdfeff1_e274c6d2,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1261,"So for each instance being created, we're going to make this same call and then potentially turn around and ignore it because of this:

https://review.openstack.org/#/c/616239/33/nova/objects/request_spec.py@781

It would be really nice if we can make https://review.openstack.org/#/c/616239/33/nova/objects/request_spec.py@781 a property on the RequestSpec so we can do something like:

if request_spec.maps_requested_resources:
   ...

Or something because for the majority of server create requests that don't need bandwidth-aware port scheduling, this is going to add to the overall time it takes to build the instance(s), especially in the multi-create scenario if I'm creating 10, 50 or 100 instances in a single request.

That could arguably be optimized in a follow up though.",DISCUSS
879,ffd0ebdf_b4f4fa5c,faaf75688f56339e6a7a1116e352fc696853caac,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/privsep/utils.py,39,"Slight grumble about this not being an exact match for the original generate_random_string [1], but the point is to avoid collisions; and theoretically the file goes away quickly, so meh.

[1] https://github.com/openstack/nova/blob/8ef3d253a086e4f8575f5221d4515cda421abea2/nova/utils.py#L251",FUNCTION
880,5fc1f717_84deb8d7,cfac912c83ac9fb90e5e9fd90dda74ce5b2893f7,e608568518ed91a0cbf08f779c5adb851762d80a,nova/privsep/qemu.py,50,So this is the opposite of true?,DISCUSS
881,ffb9cba7_415e7f44,57465aae77a7af605bbf1ffa29f9dc4b97783922,f6667b05d2146c928468021e5569a34215e93020,nova/scheduler/host_manager.py,644,Could refactor _get_instance_by_host below to use this.,DISCUSS
882,5fc1f717_3066d0ef,59d94633518e6f6272e9f0654bb908e332f97a96,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/tests/functional/libvirt/test_pci_sriov_servers.py,47,have I mentioned how much I hate the pci_alias JSON-ish thing? :(,EVOLVE
883,9fdfeff1_771e72bc,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/scheduler/client/report.py,419,shouldn't we rather provide an exception ?,EVOLVE
884,9fdfeff1_819ef351,9f066ba0cab9c132ab641b817eb973438ba2f4cd,9419c3e05499e55beda93d664197a7b0f0011ff7,nova/compute/manager.py,531,a,EVOLVE
885,3f79a3b5_ec933d4c,ba2b5904b637215a3f15e9c669f261c537e6d3cd,288c537fcd3dd605dc3ad393ba1234199a782e05,nova/tests/functional/test_nova_status.py,16,"nit:
This blank line is not necessary.
And line 14-21 should be sorted by package name in alphabetical order.",EVOLVE
886,9fdfeff1_134927b6,a59198ae4940f27551166cbaeddc8ceedb20ff24,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/virtual_interface.py,304,"cool, so we have the marker's user_id updated with the FAKE_UUID here and also for the ""map_instances, so that we avoid infinite loops.",FUNCTION
887,bfdaf3ff_3fac0533,d602a7737fa96b4dfaede871df87c86c0aef7bd5,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/objects/build_request.py,84,"it looks like the original intent was to grab the objver kwarg that was passed in for the message associated with IncompatibleObjectVersion, which would be exc.kwargs['objver']. That said, I'm not sure we can (or should) count on the exception being an actual IncompatibleObjectVersion (as opposed to a subclass, or having its message overridden); so what you've done here is safer, if pretty heavy.",DISCUSS
888,9fdfeff1_44f7e7d5,99a3823f98c593fd7f0a9e3fe3aab4126f9bb383,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/privsep/qemu.py,61,"Was looking for unit test coverage of the new option, but the function doesn't appear to have any at all.",FUNCTION
889,5fc1f717_887bb8bc,891568eade76a3f559b7191e17d90d6b53b7b4e7,3cfcd117ce7ddb5a8d94396191cde559db73fb86,nova/virt/xenapi/agent.py,431,if so this would print the shared password to the warning log,DISCUSS
890,5fc1f717_0b3fb925,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4564,Assert that _get_image method is called.,FUNCTION
891,bfdaf3ff_696badb6,03948731eb6b10818e9d8842d3b51c2378e708c2,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,224,I'm not sure this is necessary - the query above won't return deleted instances unless cctxt has read_deleted='yes'.,FUNCTION
892,9fdfeff1_6f94c437,34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/objects/request_spec.py,675,mapping is incredibly generic. Can we please a) rename it to something more descriptive and b) add a docstring that indicates the structure of the parameters for this function?,EVOLVE
893,9fdfeff1_86ff9c00,cfc1cb218c2f4824819ecd36c391a251995f3a16,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,123,"This seems to me to just be papering over the fact that callers to create() need to be providing this value now. Since I expect instance mappings are created infrequently in the code (just in one place in compute/api right?) this seems like it's just there to avoid having to change a bunch of unit tests, which is not a good reason, IMHO.",DISCUSS
894,5fc1f717_5ff1446a,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4551,in the flavor,EVOLVE
895,3f79a3b5_02c8924b,7a08c7714d90cd4766ffb27fab1a8ac3f431399c,7fa740491e53195021036af69a0ddfde183daef5,nova/tests/functional/db/test_build_request.py,516,"So this test creates 3 build requests and the marker is the 2nd in the list, so we should only get the 3rd and final build request back, which is what gets asserted. Ã¢Å“â€",FALSE
896,9fdfeff1_53e2b802,131e37c61b699e555e8c7dff225e27b89ca3b4cf,29f9febba714e1e331ecbdbc077606603dfc3ca5,nova/compute/manager.py,5972,exists,EVOLVE
897,5fc1f717_190e4134,afbe4abba881c75fef2d4ef864334d5d91181d8c,00046e47db5d51ac4eb7f9d6e5d1e618663e806c,nova/tests/unit/compute/test_compute_api.py,6020,Ã¢Å“â€,DISCUSS
898,3f79a3b5_252a8ae5,801ef1adca667ecdf243464b083282418d5987e4,2b97e508381e7f1efe48799ee3d9b068b4fd5902,nova/scheduler/client/report.py,698,adds these to the tree and populate it.,FALSE
899,3f79a3b5_725fb8dd,b3975a07752de81c8fca8e9604434e6d2a398cd2,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/tests/functional/fixtures.py,1,"I still don't like this fixture. But removing it completely is for another patch, I guess.",FALSE
900,5fc1f717_86941c46,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/pci/request.py,215,"style nit: use the brackets, Luke",EVOLVE
901,3f79a3b5_477d156e,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/api/metadata/password.py,76,nit: drop the blank line,EVOLVE
902,9fdfeff1_5fed97b5,c467293b004bef254d5142ac4ee0b40364fc2ea1,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/virt/hardware.py,1539,nit: align like above,EVOLVE
903,3f79a3b5_5304fbc4,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,1004,I think you need to pass this through as a kwarg.,FUNCTION
904,9fdfeff1_a00d163f,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/servers.py,810,same - I would expect this to be conditional based on the microversion.,DISCUSS
905,9fdfeff1_f6e411e2,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,402,not sure why this is necessary,EVOLVE
906,5fc1f717_3258612f,4be0187ebc80eeaf6c9935ec76078a8d335b3add,926e584136e7dce59f32065292aa4eb8120f628c,nova/console/websocketproxy.py,319,"This seems a bit brittle, relying on the call order internals of ProxyRequestHandler. Would a lazy load of ComputeAPI (from __init__) have the desired effect?",DISCUSS
907,9fdfeff1_1303fe11,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/tests/unit/virt/test_hardware.py,1281,we also need test case for image properties?,FUNCTION
908,3f79a3b5_234d8d6f,11a5fcbb6a3302c581f763776496d0833cf80ab6,8d089111c8554e94e117ada3a7f51a42df59e84f,nova/scheduler/client/report.py,851,"nit: ""Always returns False""",EVOLVE
909,9fdfeff1_956b0484,86e94a11f7966578fd2c3f56eaf9db340535cdf7,570ad369928c296aac59a3e81ceb45a4ff2e19a7,nova/compute/manager.py,558,"OK, so you're making the ReportClient be instanciated by the ResourceTracker. That makes us having N objects instead of one. Any reason for it besides the refactoring purpose ?

Of course, given it's now a getter, we can easily drop the RT transitive relationship and instantiate whatever we want later. I guess it's what you want ? /me needs to check other patches in the series.",DISCUSS
910,9fdfeff1_c22d9e46,b50b0fd2ac72dd1b9409ba1836e89d9f8f9f6fbb,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/virt/libvirt/imagebackend.py,897,"This is user-defined, so this is not a trusted source either. If you have a look at how we handle this in fetch_to_raw we explicitly sanity check the backing file because we can't trust it.

Please don't duplicate that code here, when we can just use it directly to do the conversion for us, making this code redundant. Also please don't add any code which relies on a malicious qcow2 header having been previously detected, because there is no strong guarantee that this will always be the case in the future, and an innocuous and easy-to-miss mistake would re-introduce a severe security hole.",EVOLVE
911,9fdfeff1_a93d5ebd,35cbe9290cef244142522f6bcc253888460d09ea,ecea762eb9f6a15f1006ad574c5ab6c8a9cb24c5,nova/exception.py,2165,"nit: I'd like to avoid the less than symbol in the error message. Could we instead say, ""is not supported until microversion 2.72.""",EVOLVE
912,5fc1f717_c698e46b,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/tests/unit/pci/test_request.py,75,A docstring describing what you're trying to do here would be mighty helpful,EVOLVE
913,5fc1f717_df7774d3,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4572,"So this step will fail the test until the bug is fixed. 

To be able to merge the reproduction test before the bugfix you need to:

* comment this step out. and write in a comment that this is the expected behavior but the bug 1821824 makes it fail

* add something like

  server = self._wait_for_state_change(self.admin_api, server, 'ACTIVE')

to make the test pass until the bug is fixed, showing the _wrong_ behavior.",EVOLVE
914,3f79a3b5_93d93382,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/policies/servers.py,167,allow,EVOLVE
915,5fc1f717_6e002735,50a0c6a4b98a3ef1d893b0bb204a4a4868017cbb,da9f9c962fe00dbfc9c8fe9c47e964816d67b773,nova/virt/hardware.py,885,"Not strictly required now? Given that this is stable-only, I wonder if this is best left out, even though it's nicer. Merge conflicts, etc...",DISCUSS
916,9fdfeff1_fb72287c,12c38291b85a373905bd754bd210c7d1cac53662,d9bd5b1377acf4468c89422fa471de6c8325d775,nova/api/openstack/compute/servers.py,212,nix,EVOLVE
917,5fc1f717_b7b6def9,61f3cb49087a715bd6617c7762005cd7d142cf36,30550d3d947e13f4d23b207ff96373971710dd55,nova/virt/ironic/client_wrapper.py,133,"This is where we always pass in an endpoint so we wouldn't get here correct?

https://github.com/openstack/python-ironicclient/blob/2.4.0/ironicclient/client.py#L110

Or is the issue that when we get the ksa adapter above, based on configuration, it's not using the ""interface"" option which is set in config to 'internal' and ""valid_interfaces"" is nulled out in config? So the endpoint URL we do pass to construct the client is for the public endpoint.",DISCUSS
918,9fdfeff1_750fdc87,c97b4046edb3bcd7c4284cabd26c58be99f08532,a6963fa6858289d048e4d27ce8e61637cd023f4c,nova/tests/unit/conductor/test_conductor.py,343,"When I commented out the last assert from here, I started seeing the failed test as seen on the gate for this patch. So my current theory is that this asserts are failing at some point but the raised AssertError exception are caught with a except Exception: branch stopping a nova service internal execution. So when we remove the assert we let that service move forward processing a message and then failing on a code paths that was not run before.",DISCUSS
919,9fdfeff1_aca39f9d,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,258,"By soft-deleted here I assume you mean with status SOFT_DELETED, not instances records whose deleted value is != 0.",DISCUSS
920,dfd5e7cf_0a20f4af,9160fe50987131feda9429c4e95d573e176916b6,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/virt/libvirt/driver.py,230,"Wholly unrelated, but did libvirt change their versioning system at some point. 4.0.0 is quite the jump from 1.3.1 (I was checking to see how far off a 4.4.0 minimum was)",DISCUSS
921,ffb9cba7_b11e2d0a,12c3eb2d3a7e7f12a65d304ecfc14fed58d4ea58,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/tests/unit/api/openstack/compute/test_availability_zone.py,130,"Granted I could have left this mess in place, but man it's hard to read (and modify, which is why I formatted it).",EVOLVE
922,9fdfeff1_f246c27c,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/tests/functional/test_servers.py,1215,Why do you need this mock?,DISCUSS
923,bfdaf3ff_3f4ba559,fb4dcaccb041a6ae38a4e46c7ed83fc855c707db,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/image/glance.py,504,"...which isn't currently used anywhere, right?",DISCUSS
924,bfdaf3ff_f7da3de7,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/exception.py,2357,"nit: drop the colon in the middle of a sentence, it looks weird when rendered in the functional test (as an example). Maybe just do:

""The maximum allowed number of disk devices (%(maximum)d) to attach to a single instance has been exceeded.""",EVOLVE
925,9fdfeff1_3770a508,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/functional/api_sample_tests/test_servers.py,447,can we stub this method in the setUp method?,DISCUSS
926,9fdfeff1_41acbe34,dda0b9d95019ada2ea975fd1d5c434661dad09a7,3b79f635de4d3495f01ed98d1a8bcfaefe154b0b,nova/tests/unit/network/test_linux_net.py,1191,this should really be a list (ditto below),FUNCTION
927,3f79a3b5_06148341,36c992f72d988ff20e3e286c1065aa76db5aec03,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,211,"Just a note, but I think the pattern I've seen most for online data migrations within an object is to call save() on the object itself, which will run it back through _from_db_object, like when uuid was added to compute node:

https://review.openstack.org/#/c/277554/10/nova/objects/compute_node.py@234

Having said that I'm not entirely sure how much it matters if we do it that way or this way, but I can ask Dan Smith since he's kind of set the pattern on how we do online data migrations within objects.",DISCUSS
928,9fdfeff1_9e7fcfdd,a76eefed62db96fe51ef40e3209c187af3eb9834,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,169,RP,EVOLVE
929,9fdfeff1_aeb8e510,55f455262144ab319a9ff480850aeece88b1dedb,20a46ece5701c9798a5e0df12c944237cb1ece3e,nova/scheduler/client/report.py,1745,"ok so the new post condtion is that when this is called if it returns true then the souce has no allocation and that target has allocation and there is nolonger a precondition that the source node had alloctions.

if neither the source or target intially had allcoation do we expect this function to return True False or rasie a AllocationMoveFailed exception?

i mean i would also be fine with saying a precondtion of calling move_allocations is that allocation must exist to be moved but just taught i would ask.",DISCUSS
930,5fc1f717_d6d3e8ff,afe767e332c0e07ef4a8ba4feca0cefe66c04f81,886850f50f62e97a5661d68c1689fdc932fb7b61,nova/conf/libvirt.py,670,Ahem ;),EVOLVE
931,9fdfeff1_e1d19bcd,900fe1c2e8e90be914f283563c0664439db54b5a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5002,move _create_pty_device() to the 'else' case instead of _create_file_device(). The function just NOOPs in the serial_console.enabled case.,EVOLVE
932,3f79a3b5_ced77dbd,ef0a50df52abef022d67fa20a1bbba9bb23ad6c2,ad31f5d66d6df25555c2f1c5653ac754790f06df,nova/conf/libvirt.py,690,probably has one more ws is better.,EVOLVE
933,9fdfeff1_7b3638b7,d9bd5b1377acf4468c89422fa471de6c8325d775,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/compute/multi_cell_list.py,415,Can we get a unit test for this logic in this patch? The test changes in this patch are just passing cell_down_support=False everywhere the new kwarg shows up.,DISCUSS
934,9fdfeff1_59ee6e22,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6219,"This is pretty confusing to read. Unless parent='' has special meaning, I think it would be the same to say:

 if parent is None or mdev['parent'] == parent:

It's also more efficient :P",FUNCTION
935,3f79a3b5_5bd28534,cc0385f510854c64aaecd2e4c36a61d459fb3fdc,ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57,nova/conf/api.py,199,"Need to update the docs for this:

https://docs.openstack.org/nova/latest/user/cellsv2-layout.html#nova-metadata-api-service

I believe the blueprint whiteboard also points out some caveats discussed at the PTG about when you might want to run metadata-api globally depending on how neutron is setup, so that could be called out both here and in the docs.

Plus we'll want a release note for this, and tests obviously.",EVOLVE
936,5fc1f717_013d9aba,67d5970445818f2f245cf1b6d9d46c36fb220f04,29e5b0ad7bde210f95885656768f0480d06882c0,nova/objects/request_spec.py,539,persisted,EVOLVE
937,5fc1f717_8988b61f,d24275951d3ad0e0ae00621971278aeedf2bfd09,2a12e420c2934e49da5cb3e586407d3f6e1d6300,nova/compute/api.py,2445,"From L2491 if this is an instance from a down cell where the user_id is set from the RequestSpec, the user_id here might be None which will blow up because InstanceMapping.user_id is not nullable but RequestSpec.user_id and Instance.user_id are nullable. -1 for that.",FUNCTION
938,3fce034c_eb9eea61,469d58ed79aca342a2916d0f4f8ffd06df467fe4,a4743f982ac5348d0aa036f3afac530ac7c56ff8,nova/tests/functional/api_sample_tests/test_cells.py,26,nit: you could avoid the explicit 410 check with assertRaises by passing check_response_status=[410] to api_get.,FUNCTION
939,3f79a3b5_e04c0799,aceef76e03374501811e58d6c2f108c4a5ffddf1,bbe88786fc90c2106f9fae0156ee7b09ece9a83b,nova/tests/functional/regressions/test_bug_1550919.py,154,instance,EVOLVE
940,9fdfeff1_de2e72f9,f261d47bc22b62d4940520442837f5a0b7e35641,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/virt/libvirt/volume/vxflexos.py,41,no?,EVOLVE
941,bfdaf3ff_5e9264f8,571355d40f78b6dacbaf8fd3401f96a50708febb,0558d6d9c3ba2a9c49cb45c68c9d2e6b9ea88156,nova/network/linux_net.py,1673,I'm guessing this should be rolled into the previous change?,DISCUSS
942,5fc1f717_a0ad8032,2734b249605eb28fd1017bd8bd35fc262e03c97d,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/conf/libvirt.py,649,You started... do you want to finish?,EVOLVE
943,9fdfeff1_ff27ab1d,c467293b004bef254d5142ac4ee0b40364fc2ea1,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/virt/hardware.py,1541,same,EVOLVE
944,5fc1f717_7d815ac3,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,88,"this wasn't necessary. You could have just done:

 vif_pci_requests = objects.InstancePCIRequests(
                requests=pci_reqs,
                instance_uuid=instance.uuid)",FUNCTION
945,dfd5e7cf_39575c05,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,8348,"nit: You can dedent this whole thing with:

  if port_id not in port_id_to_pci_dev:
      continue

also, keys() isn't necessary",EVOLVE
946,9fdfeff1_fa032272,a5d78b17e7f538c75eff938f4ace14c01c5d34b4,c1fb445b8d94e69d7878fad60c4653650052313a,nova/api/openstack/compute/evacuate.py,78,"@validation.schema(evacuate.evacuate_v2_29, ""2.29"", ""2.67"")",FUNCTION
947,ffb9cba7_63e19cd0,f64a92b3cb6440dd48a4df2dfb61dbf92eb805fd,74cefe4266a613d4c2afbb0c791e16eb7789aef4,nova/tests/fixtures.py,2224,Why not make this signature match the method's exactly?,EVOLVE
948,3f79a3b5_04fd1b06,085fe6de688923540e13440f9189310e4cc15194,288c537fcd3dd605dc3ad393ba1234199a782e05,nova/virt/libvirt/driver.py,1074,"I've been thinking about some related cleanup issues recently, and I think we can simplify the cleanup discussion by explicitly pointing out that there are (currently) 2 types of cleanup:

* Migration: The workload is still present, but elsewhere. This covers cleanup after live migrate, cold migrate, and evacuate. We must not cleanup shared resources, only resources local to this hypervisor.

* Deletion: The workload is going away. Cleanup everything.

We have a bug that we're not cleaning up the instance directory for a migration cleanup if the backend is rbd.

Firstly we don't have a good way without a more invasive change of asserting that the operator doesn't have both rbd and nfs instance storage, hence the requirement for the workaround. The workaround is an assertion by the operator that they're not doing this, and this is safe.

is_shared_block_storage isn't set when called during evacuate cleanup, and destroy_disks is wrong in general because ComputeManager attempts to second guess the hypervisor, so ignoring these 2 values is correct.

The assertion therefore is:

* backend is rbd
* operator asserts that they aren't using shared instance storage
* it's a migration cleanup

Note that we must assert that it's a migration cleanup, because we also call cleanup(destroy_disks=False) from hard reboot, and we don't want to delete the instance directory in that case.

This looks correct to me, and a backportable workaround.

It's obviously a hack, though, and I'd like to see it replaced with a better fix. I think the way forward here is to pass the migration/deletion intent to cleanup and have the virt driver decide what needs to be cleaned up, rather than second guessing in ComputeManager.",EVOLVE
949,bfdaf3ff_9a60a603,545523a7d25bac319ff6d222ce70632be4d2f33d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_cpu.py,183,"doesn't it [0, 2, 6, 8 ] * 1.5 = [0, 3, 9, 12] ?",DISCUSS
950,9fdfeff1_2da604c3,b533eac84e83725aae4ed23f239d7893531656b7,18b6face6490e3552648db7c1c856b23cb4ea631,nova/privsep/linux_net.py,150,"This is weird, why not cmd.append('multi_queue')? (Recognize this is a straight cut/paste, so don't do anything; just seemed bizarre.)",FUNCTION
951,ffd0ebdf_83fe6103,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,208,remove this word,EVOLVE
952,3f79a3b5_1035f5db,88037a7374ac5d1d99c01bce1b895795651a5ff9,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/workarounds.py,189,"I was wondering if this should be more general and say ""migration"" instead? Because I think the cleanup of the instance directory will occur during other instance moves (live migration, resize).",EVOLVE
953,1f769fc5_f54810cd,0ce581369838dbe6909bdd8847aefac2aff1177e,7381ec7d7c318bddd42e1d90a171d20b2ec6f49d,nova/tests/functional/regressions/test_bug_1790204.py,70,"yup... good that you mention the role that the allocation ratio plays in this, since it's not actually the vCPU change that will cause the failure -- and since your flavor2 only changes the vcpus count, that's a bit misleading.",DISCUSS
954,9fdfeff1_679651f3,2c206de988e45d0375ff7a7bdeef877cc16b8096,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/compute/api.py,3615,"Why does this need to happen? Seems like masking a bug - there should at least be a comment. Also, request_spec.image might not even be there for volume-backed servers right?",DISCUSS
955,bfdaf3ff_a4ca4517,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/conf/compute.py,813,"This doesn't really give much useful information, but that could be fleshed out later I guess.

That doc also says it's only used by the libvirt driver but it looks like the vmware driver uses it also (so a bug in the glance docs):

https://github.com/openstack/nova/blob/89c2d1056b3f37bad243c7468d974ded71336a0f/nova/virt/vmwareapi/images.py#L152",EVOLVE
956,ffd0ebdf_e60c2644,0ce581369838dbe6909bdd8847aefac2aff1177e,7381ec7d7c318bddd42e1d90a171d20b2ec6f49d,nova/tests/functional/regressions/test_bug_1790204.py,71,"2056, not sure why we have 1024 in the fake driver.",EVOLVE
957,5fc1f717_1bde826c,2b15904afdc4bc7b17c34bc774386dec4eb3aa32,f130b295bb0e72ab9613018399ce423effeda37e,nova/tests/fixtures.py,2050,Do I get co-author credit for this? :P,DISCUSS
958,5fc1f717_81baeabd,954e1f38af5e20baacab255a5f9726a42c99863c,73edcfae7d5ea498fd17fa8e548ae1bd690f408a,nova/tests/fixtures.py,2235,"This is going to really confuse anyone who hits this for the first time without being aware of this new fixture. We need to be more explicit, something like:

""Your test is calling time.sleep(). In order to save gate time, the SleepPoisinFixture prevents time.sleep() from being called directly. If you really need to sleep, please call self.real_sleep(). Otherwise, please mock out time.sleep()""",EVOLVE
959,9fdfeff1_e003990c,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/tests/unit/scheduler/client/test_report.py,2864,"I don't know if 'getters' would be better in the name or not than 'things'. But I feel that 'things' adds nothing to the name. 

assert_getters_were_called()",EVOLVE
960,9fdfeff1_2d175a48,c0fd216780cfa9c17da385af63fa743d40434fa0,fe88d9e2c33af94139dbae896b95dcc45c412798,nova/virt/libvirt/driver.py,4959,"As an aside, dragging this out to a '_create_consoles_non_qumu_kvm' function might not be a bad idea for a future change",DISCUSS
961,3f79a3b5_6876bd93,ecaceeb08123671ef2819b4fc6be58b4d4fb259f,256e35fe49da9d3dac430c3b92d6ed2e5c500a12,nova/conf/libvirt.py,422,"Yeah, now this text totally make sense.",DISCUSS
962,5fc1f717_c9ed5e26,2a12e420c2934e49da5cb3e586407d3f6e1d6300,554f2c850707b85b178425c68166d49f34df5561,nova/objects/instance_mapping.py,66,"This fine, it will just raise NotImplementedError as normal.",FALSE
963,5fc1f717_0a7601da,fbbe7694a0d4c80db5da5f90d46bd3e13a8c5276,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/scheduler/utils.py,321,want each group to be,EVOLVE
964,5fc1f717_ab3993f2,074d3867bc4c074bdd8356e17424d2eb391ecf30,07627d4d3958c34d317037cdd62b88b3ad750392,nova/tests/unit/privsep/test_path.py,56,"What bugs me about this is it at least appears to represent a second invocation of the open mock. I'm guessing mock.mock_open has some kind of singleton behavior so that the return_value is the same no matter how many times you call it - but I suspect that's by luck rather than by design.

So it would be cleaner to get rid of 'handle' and change L60 to

 mock_open.return_value.write.assert...",EVOLVE
965,9fdfeff1_e3d70c4f,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,128,the,EVOLVE
966,1f769fc5_ba2e0041,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,228,How about logging a message here saying you got an unexpected number of VIF records in the database compared to what was stored in the instance_info_caches table?,EVOLVE
967,7fc4fb27_8e345be0,3225fb61f92e0fd736943acd2987710c569ba14f,c02e213d507c830427a86d6a4bb4f7a2f5158590,nova/api/openstack/common.py,570,nit: are,EVOLVE
968,3fce034c_b4fb1677,54cde449516bc4823c6be301fd9ad553c63ac388,0b48d9148bbde88bb6b50329f76b6a25db9ac986,nova/network/base_api.py,33,"Weee for potentially breaking hook code, but that's why we deprecated hooks long ago.",FALSE
969,9fdfeff1_b7d7fac0,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/pci/stats.py,105,"nit: why not

  if dev.extra_info.get('parent_ifname')

?",FUNCTION
970,9fdfeff1_7fe3bb07,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2163,"its technicall allowable for a pf to be used by ovs and the vf be managed by sriov.

e.g. the bandwith can be shared between both ovs and sriov.
im not sure this nameing scheme caters for that properly so this is likely
an oversigth that will need to be changed in trian.
ideally this would not contain the agentname.

you could work around this by using the neturon config to list
the interface twice and reserve capasity such that you can share the bandwith
between ovs and sriov  but in its current form im not sure how you will know the agent name as there is currently nothing that would allow you to determin that in the neutron port. if i can get https://review.openstack.org/#/c/635083/ to work then it shoudl help in that respect in the future.",FUNCTION
971,9fdfeff1_bfb3630a,08be016aec042558ca536fa3494cbc960b1cb734,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/unit/matchers.py,530,"This is going to give you 1, but (if I understand the error case correctly) you actually want 0.

Suggest instead initializing actual_child_idx to -1 above the loop at L506.",FUNCTION
972,5fc1f717_fb71110e,82d2f6d2e399161d414e28b841323b9e8ad50563,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/virt/libvirt/driver.py,4255,Can you get rid of the backslashes please?,EVOLVE
973,3f79a3b5_90ca93a0,f4253e095574b99f5313de2923f2e42e0cb75fed,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/tests/unit/compute/test_rpcapi.py,597,Could have renamed this while updating the change but meh.,EVOLVE
974,9fdfeff1_07e50509,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,496,maximum,EVOLVE
975,9fdfeff1_5bb10be1,603c4cccc12dfad345d5552dc6ad5a206240a640,7f92674a80c8d76749067e86363370814b7f0429,nova/tests/unit/network/test_linux_net.py,904,It should be in https://review.openstack.org/#/c/624591/ .,EVOLVE
976,9fdfeff1_eba8df8c,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/api/openstack/compute/servers.py,814,Same nit as https://review.openstack.org/#/c/630721/4/nova/exception.py@2157 in that we might want to make this more generic if you can still somehow work QoS into the error message as an example.,EVOLVE
977,9fdfeff1_a575ff99,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/network/neutronv2/api.py,1719,"Thinking out loud, if we don't get the port because it's already gone, should we just assume we failed a race and something else cleaned up the port? Or should we at least have an else block that looks for the corresponding vif in the info cache and if that vif has a binding profile with an 'allocation' stashed in it, we could log a warning that we were unable to cleanup allocations for the port but they might have already been cleaned up concurrently - or something to the effect that port resource allocations could have been leaked?",FUNCTION
978,3f79a3b5_065cb118,364724ba6f7442cbaedcb270498cad549a571449,d1e38f06bb5282dd9bf81d979926a0ebbfd93caa,nova/image/glance.py,142,"thanks for converting to the constant style :)

however if you pulled this out to the module scope you cloud use it to default the version param of _glanceclient_from_endpoint on line 74 and then you could remove all the self.IMAGE_API_VERSION useages on lines 156 and 163.

this is just a nit however.",DISCUSS
979,9fdfeff1_b70fb586,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3499,why we need this?,DISCUSS
980,9fdfeff1_2447ec1f,451d41a9deaf4bdba20509afc15a73df02e400f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,704,"A future improvement might be to only call ServiceList.get_all_computes_by_hv_type() if CONF.ironic.peer_list is None. Otherwise, add a new ServiceList.get_compute_by_hosts() method that allows you to filter to just the peer_list values.",DISCUSS
981,9fdfeff1_8da29099,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/functional/test_servers.py,6295,"Looks like this is simply due to the FakeDriver.spawn() not adding anything to self._interfaces, is that correct? That should be pretty simple to add:

def spawn(...):
   if network_info:
       self._interfaces = {vif['id']: vif for vif in network_info}
   ...",DISCUSS
982,9fdfeff1_c4413ba8,07ed1c3292b46ecddd32ba22386795df732f77a0,48ad73e1faf966badab1f0344baad9f4f4055abf,nova/privsep/path.py,74,"Maybe it'd be better to wrap it up with smth like this?
  try:
    os.utime(path, None)
  except OSError as e:
    if e.errno != errno.EACCES:
      raise e",FUNCTION
983,9fdfeff1_f68da47b,cca4c66375974622e42ca096a8c20e09d437a11f,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,nova/pci/manager.py,308,"it better to validate that that the dev_status_to_free in one of (fields.PciDeviceStatus.CLAIMED,                                       fields.PciDeviceStatus.ALLOCATED) in code",FUNCTION
984,9fdfeff1_52eac0d7,ba3fe17b0390ef7027a37d2577b6a3ea14548ce9,4d32b45c152c4dedcb9d01380f557338c3acb81e,nova/network/os_vif_util.py,297,"nit: we get the vif name above when building the datapath_offload variable, we could just keep a local variable for that and re-use it.",FUNCTION
985,5fc1f717_c9355ef9,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,260,"Repeating from PS17:

Just thinking out loud, but if the cell is down here this would blow up in some weird way right, like some kind of DBError? And we'd just choke and not be able to process any other instances in up cells. I realize this is an issue in other data migrations that are iterating all the cells (the one for queued_for_delete and the virtual_interfaces one). Seems we should be more resilient, but we could also deal with that in a follow up - maybe just leave a TODO for now since we probably need to handle down-cells in all of these multi-cell data migrations.",FUNCTION
986,9fdfeff1_8a7008a6,6c239c2390799fef03ba4f7d00762a4a96f62819,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1700,"In things that get logged you should spell this out ""resource provider"" so it's clear to the operator.",EVOLVE
987,3f79a3b5_8839f240,8456713513a13063421c19cfa1c9f20197c90e08,00091e423d6e43d5dd27df775a9f9d63072287de,nova/virt/libvirt/imagebackend.py,253,"ok so the only change in funtionality is that we cant run commands as root and since this not run as root anyway that is fine.

https://github.com/openstack/nova/blob/8545ba2af7476e0884b5e7fb90965bef92d605bc/nova/utils.py#L227",FALSE
988,9fdfeff1_ba0f552c,2e4e203c1a4c4f91dd1aabae8c8d7b745df99be7,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/manager.py,5636,"I know the original attach change uses instance.uuid but in 
 this brave new world of multi attach support shouldn't this be on the volume_id to avoid races between detach calls against separate instances?",DISCUSS
989,9fdfeff1_7d2e59a6,9d5e805009a7f773eac9b696ea8162a04ff73b0e,7381ec7d7c318bddd42e1d90a171d20b2ec6f49d,nova/compute/manager.py,5357,A docstring on this method would be nice to call out that the port is a string. I don't see any documention on the console.type.Console* objects about what those fields should be.,EVOLVE
990,9fdfeff1_164d7199,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/conf/compute.py,850,seems the only allowed negative integer is -1? so should we be more specific here to avoid possible misleading?,EVOLVE
991,1f769fc5_cbc81076,5f2ec710cf38be6c23e04ce40e8a298d50e3b79d,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,232,``literal``,EVOLVE
992,9fdfeff1_eeb5c3d1,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/tests/functional/api_sample_tests/test_attach_interfaces.py,232,Should this be replaced by _get_subs()?,DISCUSS
993,9fdfeff1_16a3be44,40b60e5cd9ca0e0941929ee0fcdee4633511b9e0,859a0ac11842101c902a98165277175d984c3352,nova/network/neutronv2/api.py,2054,"Technically we only need to do this if L2061 is True, correct? I'm not sure if that saves us anything, but since the two are linked semantically maybe it makes sense to only set this on the InstancePCIRequest if the port has resource requests.",EVOLVE
994,5fc1f717_cfe366d7,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,fb1fee6772bb101eac83845bac9022df77113aaa,nova/objects/request_spec.py,606,And this is where we *don't* persist the RequestGroup with the in_tree value.,DISCUSS
995,9fdfeff1_eb59bf8d,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/tests/unit/api/openstack/compute/test_server_actions.py,97,"As noted below, you could just handle that mock in a single location so it doesn't have to be copied to so many tests.",EVOLVE
996,9fdfeff1_6e3a61e6,2abf36a6989a597dcdbbe1282e81e51da86f1356,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/tests/unit/virt/libvirt/test_utils.py,531,"Whoops, pep8.",FALSE
997,3f79a3b5_b27cc2c7,61e188ed5efc2ea1b0448cde895e0cebb5ef690d,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/compute/manager.py,5760,I don't think this is the correct approach. The status should be checked for both retyping and migrating. This would break an attempt for retyping attached volumes.,FUNCTION
998,9fdfeff1_f22cfd93,448139b5a7876ffc86b625f5897fccafe3353786,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7557,"I'd probably log this yeah? That's an indication to an out of tree driver they have an interface change to make, but maybe not a big deal if they don't need this anyway - however, their driver wouldn't be doing the power sync state stuff properly right?

In other words:

try:
  vm_instance = self.driver.get_info(db_instance,
                                     use_cache=False)
except TypeError:
  LOG.warning('something about your driver is out of date'
  vm_instance = self.driver.get_info(db_instance)
vm_power_state = vm_instance.state",FUNCTION
999,9fdfeff1_258c4634,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,552,"Let's not tightly couple how this is used to what uses it, so remove this part.",EVOLVE
1000,9fdfeff1_85831bcb,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/tests/unit/pci/test_request.py,212,"nit: use flavorid throughout because as noted in the commit message, flavor tests use flavor_id for flavor.id and flavorid for flavor.flavorid.",EVOLVE
1001,9fdfeff1_6d43ac40,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,6057,for,EVOLVE
1002,bfdaf3ff_de3ac296,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/objects/test_numa.py,187,"Weird question, shouldn't this be 2 ** 20 + pagesize ?

can_fit_pagesize does two checks, a size check and a modulo check to see if the memory requested is actually a multiple of the pagesize. +1 will hit the modulo branch if the size check is somehow busted.",DISCUSS
1003,3f79a3b5_55de910f,5c4633e13017485466feb39b491008337ae96dce,1e8c2c0dcb3ff9225407b890a6c99658b35764bc,nova/tests/unit/conductor/test_conductor.py,2162,"mock_create_tags.assert_called_once_with(
    test.MatchType(context.RequestContext), inst.uuid,
    self.params['tags'])",FUNCTION
1004,9fdfeff1_85917256,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/compute/api.py,549,"The root disk could change on a resize, do you mean does not change for a volume-backed server? I guess this is coupled with the actual check for VolumeSmallerThanMinDisk which for resize isn't an issue because the *image* doesn't change for resize. Anyway, this is confusingly worded but I'm not sure what to use instead.

This does, however, leak details about what is validated and in the case of resize you *could* pass the root_bdm and it shouldn't be a problem because the image doesn't change and therefore if you passed create/rebuild it should be OK for resize. So that begs the question, do we actually need this root_bdm parameter to be optional? I guess so because otherwise we have to lookup the root bdm for no great reason in resize just to pass it here...",EVOLVE
1005,9fdfeff1_6a66a8f0,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,829,>=,EVOLVE
1006,9fdfeff1_521e295f,448139b5a7876ffc86b625f5897fccafe3353786,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7557,Do we not want to emit a warning log here? For out of tree people to update their driver?,DISCUSS
1007,3f79a3b5_5acc7832,eff37148c3a45b33f122505b5b359a761394f658,01cea1a045db22f274fb8a6886733bee3f213fb6,nova/tests/unit/virt/vmwareapi/test_vif.py,375,"Seems to me we need to add a test where the vif info has the dvs_id and pg_id. Assert that the returned network_ref contains the values from the vif info, and that get_network_with_the_name isn't called.",FUNCTION
1008,5fc1f717_1657d404,89a16f8c6a3c2bbf76fa6284ce51ff3a90ceb5e0,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/conductor/manager.py,635,Could we take this...,EVOLVE
1009,9fdfeff1_ad8446d4,49a87d6fe332b02e8dca872a8b8d5197c7ba1fb5,ff728365635be8447bb124a9842934080a8f789a,nova/conf/workarounds.py,189,I guess we should deprecate it first.,DISCUSS
1010,9fdfeff1_7438bd3a,a5a28ea8f0ab54b8e50b496bb999e7de02882183,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/virt/ironic/client_wrapper.py,106,"Since this patch depends on the ironicclient one, why not do it correctly right now?

That said, if you're trying to make this backportable to queens, aren't you going to have a tough time backporting the ironicclient lower constraint?",DISCUSS
1011,3f79a3b5_87880625,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,234,This should probably be a warning...because data loss is bad.,EVOLVE
1012,9fdfeff1_b21fb106,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/servers.py,396,self._get_server() is also hard-coding this when calling compute API.get() so in the patch that adds the microversion it would be nice to only have to check the microversion once for GET /servers/{server_id} which would mean checking that in this method and passing the cell_down_support flag to the _get_server() method.,FUNCTION
1013,9fdfeff1_d1b660da,fb10f7ed0cd1566da3e068490300b1ebd053af8f,d89579a66ac38fd1e30cea55306e6e7b69bab5b9,nova/compute/api.py,3616,this seems kind of indirect...is there no cleaner way to do this?,FUNCTION
1014,9fdfeff1_297f61e0,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,1210,Let's be specific and say that it's done by _validate_and_build_base_options.,EVOLVE
1015,5fc1f717_675d8eeb,2a8d417913fe32777393e796684d4712e827e2ac,28944d05f3fc415bc294e11202db7810bc354b5a,nova/tests/functional/api_sample_tests/test_servers.py,631,I really hate this. I understand what you're trying to do (force people to have to think about it) but it seems like a really impactful new requirement for what is really a pretty small gain.,DISCUSS
1016,9fdfeff1_2fb32e9a,49ec9c803ab5513fc25a8a9afc79914751433ebe,735c2181dc450195454cf4dc62a814ff1679abda,nova/network/neutronv2/api.py,527,its,EVOLVE
1017,ffb9cba7_281ad57c,d1f6dda85a8a69e6aed8b48125e15f2460453885,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/virt/driver.py,1848,"This docstring could definitely use some more information, similar to what is in the commit message. Something along the lines of ""Used to indicate whether or not the compute driver (or backing hypervisor) is responsible for managing port binding details, such as the host_id. By default the ComputeManager will manage port bindings and the host_id associated with a binding using the network API. However, some backends, like Ironic, will manage the port binding host_id out-of-band and the compute service should not override what is set by the hypervisor.""",EVOLVE
1018,9fdfeff1_4b9a1d14,9cb825b0147af3b191ea2989e5187e4afdadcb15,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/conf/cinder.py,27,"Not entirely related, but [1]. We can fix this in a follow up

[1] https://docs.python.org/3/whatsnew/3.6.html#deprecated-python-behavior",FUNCTION
1019,3f79a3b5_7cb33f36,073c330f52dfa535e6f787f5bb2fc8ec52f1be9a,514eaaef12dad2460fd4c2fffdc05a3db0490711,nova/scheduler/client/report.py,671,"OK so this is where the clear_provider_cache() from the ""if is_new_compute_node"" block comes into play. In the case of a new compute node, this would be False so we'd drop down and ensure the provider exists by creating it if it doesn't already exist.",FUNCTION
1020,9fdfeff1_7ad080ca,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/compute/api.py,4663,"pre-v2.29 you mean?

As for this question, I've wondered the same before and I think it has something to do with the wsgi controller code and how it handles passing force as None or False so just checking for Falsey could be unsafe. It's definitely weird and I'd get behind cleaning it up, but separately is fine.",DISCUSS
1021,9fdfeff1_9c56ed04,5cab213a5dac26e6efd3e87bfeb452c8b0c0edbe,859a0ac11842101c902a98165277175d984c3352,nova/network/neutronv2/api.py,2105,"This is the same thing as what you had in PS28. What I was looking for was this around L2059:

if resource_request:
    requester_id = request_net.port_id
    ...",FUNCTION
1022,5fc1f717_f08da87b,59d94633518e6f6272e9f0654bb908e332f97a96,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/tests/functional/libvirt/test_pci_sriov_servers.py,288,"good test addition, thank you Stephen.",DISCUSS
1023,3f79a3b5_b25625cd,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/compute/provider_tree.py,375,"ok so this is doint a tree walk up to the root node of the tree when name_or_uuid is not the root node.
if it is the route node the while is a noop befaus found.parent_uuid is None so we skip the loop.",FALSE
1024,9fdfeff1_0e3c3a2d,9cb825b0147af3b191ea2989e5187e4afdadcb15,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/conf/cinder.py,27,"This '?' is now redundant.

And given that the capture groups are not used where this is read (which the '?' would have actually broken), all the parens could go too.",EVOLVE
1025,3f79a3b5_a8697c23,11a5fcbb6a3302c581f763776496d0833cf80ab6,8d089111c8554e94e117ada3a7f51a42df59e84f,nova/tests/unit/scheduler/client/test_report.py,2969,I feel my hands tingling as time wrinkles and we approach the event horizon.,FALSE
1026,5fc1f717_f63b28c5,89a16f8c6a3c2bbf76fa6284ce51ff3a90ceb5e0,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/conductor/manager.py,649,...and this and put it into a private helper method and then re-use that below?,EVOLVE
1027,3f79a3b5_c82a7177,256e35fe49da9d3dac430c3b92d6ed2e5c500a12,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_migration.py,980,+1 for the re-indention to a sane format,DISCUSS
1028,3f79a3b5_366e69cb,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,595,"We get these values from the initial config options right? If so, let's use those here instead to make it clear.

In general, a lot of these tests look very similar so it would be nice to have a docstring per each test being modified to explain what it does - which will also explain how they are all slightly different.",FUNCTION
1029,5fc1f717_0079f4fa,481b4d7ad72f2538bc55e9468e37d3479fbc76e6,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/conf/utils.py,38,"ah, this is what you were saying in IRC, cool",DISCUSS
1030,bfdaf3ff_fa678f50,8f328c03b266b0d17da2f0e92ad319aa603c8e41,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/compute/manager.py,2327,here,FALSE
1031,5fc1f717_904c6477,59d94633518e6f6272e9f0654bb908e332f97a96,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/tests/functional/libvirt/test_pci_sriov_servers.py,249,"same comment as above.

also, have I mentioned how much I hate the stringified JSON-ish crap that is the pci passthrough whitelist configuration?",EVOLVE
1032,9fdfeff1_ad699425,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3628,Could also be: [get_call] * 4,EVOLVE
1033,3f79a3b5_4ecc1ebd,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,ec044885ff2c44202cc62cf85149b7993d4d0221,nova/compute/resource_tracker.py,812,"right, but as mentioned in my commit message comment, this will also blow away all compute node providers representing Ironic nodes... which could number in the thousands. So, each time a new Ironic node is added to a nova-compute service with thousands of existing compute nodes already being tracked, the entire provider tree will be blown away and slowly re-created each time update_available_resource() is called for each Ironic node...",FALSE
1034,5fc1f717_ac7a92ed,2b15904afdc4bc7b17c34bc774386dec4eb3aa32,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,90,not needed,FUNCTION
1035,3f79a3b5_4c68aeb9,d86125602775505d88f832831ec3c68a97d71fdd,6d0386058b9628bbfcf64abdd707ad87ee19353c,nova/tests/functional/regressions/test_bug_1806515.py,28,I guess this works to fail scheduling because we don't use the PlacementFixture.,FALSE
1036,3fce034c_95389b3d,fad704b21bd9760cb39219fc61b655d1e34861ea,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/tests/unit/test_metadata.py,324,"nit: assertEqual(expected, actual)",FUNCTION
1037,9fdfeff1_f2ac59a0,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,148,"same as above

Also, a nit but I'd probably split this whole chunk out into a private method like:

def _show_from_down_cell(...)

And then you just have:

if cell_down_support and 'display_name' not in instance:
    return self._show_from_down_cell(...)",FUNCTION
1038,3f79a3b5_0c72ef18,8e2c0faf1abc3727b8bfeba3180d7464f9476345,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/tests/functional/api_sample_tests/test_servers.py,374,It is not necessary. Remove it.,EVOLVE
1039,9fdfeff1_cbe2c8d4,9311aceadf385e3c2655cf44aae720b9b7282eac,a90c8e1a359a236e06f3a78df74f55808bbef31b,nova/objects/block_device.py,73,This is not a remotable method so we don't need the version bump.,FUNCTION
1040,5fc1f717_0887bfb8,b096d9303acfea81ca56394cab681d2b2eed2d91,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,717,This would also result in the instance being stuck in BUILD status.,FUNCTION
1041,5fc1f717_8a6103ac,81b0e5a0680883d68d12253af64f8e10200df746,4ede35281160b8d988ef5b775b97d81950d0c6e1,nova/compute/manager.py,7623,"I don't really like this because we generally don't make provisions for out of tree drivers, and this kind of thing is easy to just not go back and clean up. I know it's because we're worried about backporting a virt driver api change, but I don't really think we should be (worried about it).",DISCUSS
1042,9fdfeff1_b327eec7,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,31,Can't you reuse InstanceHelperMixin._wait_for_state_change?,EVOLVE
1043,9fdfeff1_3ed475bd,26c41eccade6412f61f9a8721d853b545061adcc,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,326,#ERROR!,DISCUSS
1044,9fdfeff1_7293b2fb,eb9fa2b2f75243313f6ad4bdb899d6aa68f0a173,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/api/openstack/compute/volumes.py,355,"And we can hit this from compute_api.attach_volume because that calls reserve_block_device_name:

https://github.com/openstack/nova/blob/9419c3e05499e55beda93d664197a7b0f0011ff7/nova/compute/api.py#L4034

Which is an RPC call:

https://github.com/openstack/nova/blob/9419c3e05499e55beda93d664197a7b0f0011ff7/nova/compute/rpcapi.py#L914",FALSE
1045,3f79a3b5_07ad6f82,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_driver.py,11434,"Rather than change this test, shouldn't it be a new test for the new option? Again, going back to my comment in the post-copy option help, there are two ways to activate post-copy, right?

1. we hit the completion timeout and the action is 'force_complete'

2. or should_switch_to_postcopy returns True because the post_copy option is true and the live migration has stalled (regardless of the completion timeout)",EVOLVE
1046,3fce034c_f5ffea31,82c79ceac30d7b97d68c2d71bdd0aae8c7038811,f389773f5255051f2f1cff4d0b0a08eafc0ac147,nova/tests/unit/privsep/test_libvirt.py,79,hairpin,EVOLVE
1047,5fc1f717_f127e4b5,a0c97f7fe7d0ff5af39670ac70e6eded4a5c0428,64b4f41b24bf876294d1e587909ab911ce8e0b48,nova/tests/unit/compute/test_compute.py,6309,"what is c.
later: oh its the admin context.
terrible name but ok that is just a nit.",EVOLVE
1048,9fdfeff1_7f0a1620,5158327bc8a2fbc4c3cabcf3fd964e5f61285fa1,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,744,creating,EVOLVE
1049,5fc1f717_b2352847,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,27,pep8: looks like this is now unused.,EVOLVE
1050,ffb9cba7_14eee087,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/tests/unit/compute/test_compute_mgr.py,8647,"Stiiilll wish these were separate tests, but I get why you're averse to this",EVOLVE
1051,3f79a3b5_972aa22b,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/tests/unit/pci/test_manager.py,336,from,EVOLVE
1052,5fc1f717_314428b8,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6734,This method name is also very confusing. Can we call it _allocate_pci_devices_for_instance() please?,EVOLVE
1053,3fce034c_98d7b224,a4543eaf2e55bfb3abd981aa9d743f39cd2559ce,0d1310224818c204c52f67deee18efafd1269681,nova/db/api.py,256,hypervisor_hostname,EVOLVE
1054,3f79a3b5_22c1b983,d779b33d72d6ef41651ce7b93fe982f121bae2d7,183f6238c1d98b04fdcee0fb70212f01f4012ae4,nova/compute/rpcapi.py,393,"Thoughts on passing require_all=True here so we don't fudge an upgrade because there are down cells with older compute service versions, i.e. let's say we are upgrading from rocky to stein, restarting the API in stein and all but one cell is upgraded and reporting in to stein, but there is one cell still with rocky computes, so the upgrade level for compat would be stein. Then if that rocky cell comes online, we would be sending stein RPC versions to rocky computes which would fail. Maybe that's really out of scope and as an operator you shouldn't enable that cell while the computes are backlevel, but the enable/disable cell stuff doesn't really have anything to do with whether or not you can send RPC messages to it. Anyway, this method will log a warning if there are down cells so maybe that's good enough. Otherwise nova-api would fail to start if there are down cells and we likely don't want that.",DISCUSS
1055,3f79a3b5_c7f69760,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7386,"I just realized there is no min value on this option, which seems weird, I would have expected to see min=0 on this option. That's sort of outside of this change but could be done in a separate patch.",FUNCTION
1056,9fdfeff1_d08dd531,c7490fcdb46fe883aefc2c85293973e9df226b3e,2bf79236a39aa4417fea39ab1f900bf150b05764,nova/utils.py,1365,"pretty sure it should, yeah.",DISCUSS
1057,9fdfeff1_c674f2d1,2db2839be9864f054a430b2013fdc3ba09a4eb69,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,nova/conductor/manager.py,1266,"Yeah, so as noted in the previous patch, I wonder if it would be worth using a ProviderTree [1] here instead.

[1] ...possibly gleaned via get_provider_tree_and_ensure_root. Though we shouldn't allow that guy to be cached on the conductor at all. Maybe pass in a flag to switch off caching.",FUNCTION
1058,ffb9cba7_540a188a,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/conductor/tasks/live_migrate.py,235,style nit: newline before this,EVOLVE
1059,3f79a3b5_2495b73e,514eaaef12dad2460fd4c2fffdc05a3db0490711,4ebd2504bb27afac7184d254aa6556fe61493a5d,nova/scheduler/client/report.py,278,"(thinking out loud)

If the existing ProviderTree is being operated on in a greenthread and is holding the lock, that's no biggie because that entire ProviderTree will go out of scope when any references to it do, so there ought not be any issues there.

(I'm not even certain if we have potential for that situation, now)",FALSE
1060,5fc1f717_51232f06,5d6dbaf67c9501d1fefa39e42a04625e11cec13c,131f7606c179bd08bde3b7ae0e6bb0b59acf1545,nova/test.py,515,nit: probably should rename this 'expected',EVOLVE
1061,9fdfeff1_7ee174fc,f3b7b972ddea69649cfa6c79cad5a4220a2588c7,9cb825b0147af3b191ea2989e5187e4afdadcb15,nova/utils.py,348,"I mean, we could raise ValueError here to not change the behaviour.",FUNCTION
1062,5fc1f717_7f396e3d,e660c6646b8f8dd02c0b64b20b6c2db630969315,2623acaba4573738faa61658af2d6006da6918a0,nova/virt/libvirt/volume/quobyte.py,68,"You need a lock here, although you can avoid this by setting _is_systemd once at the end and using a local variable before that. Not using a lock risks running this twice initially. As that's not really a problem, I suggest this is the best way to go here.

If you don't do either, there's a short window where a second concurrent caller can get an incorrect return of False from this function on a system which supports systemd.",FUNCTION
1063,3f79a3b5_676cca9d,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,247,"We should probably also call out this workarounds option from the images_type option help, since I'd probably see that before the workaround:

https://github.com/openstack/nova/blob/a189d1185c0a3458c28015a6cb46aac3bfa9d152/nova/conf/libvirt.py#L799

Similarly, I think https://docs.openstack.org/nova/latest/configuration/config.html#DEFAULT.instances_path should be listed here as related and you probably want to similarly refer to this workaround option from the 'instances_path' help for awareness.",EVOLVE
1064,9fdfeff1_ef9f544d,34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/objects/request_spec.py,784,do,EVOLVE
1065,9fdfeff1_7df2d99c,ccec9ba82de7c9525981a34bb126e9ca98042d04,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/objects/instance_mapping.py,38,"and this doesn't do it, huh?",DISCUSS
1066,9fdfeff1_6fc8f2a7,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/virt/libvirt/driver.py,5943,nova-net is _sometimes_ useful :),FALSE
1067,5fc1f717_20958b32,b02bfea9347a7a056cb85bf42e93364bfc6eb065,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,118,"The above check has been added since 2013 with I63c36811a57982e826f22f827f86d40ff6a6210e

Now we can remove most part because of jsonschema validation.",EVOLVE
1068,9fdfeff1_2ee42b3c,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/tests/unit/virt/ironic/test_driver.py,1127,"This line looks redundant with L1128. (Ah, I see it's just a copy-paste from test_get_info_not_found_in_cache)",EVOLVE
1069,9fdfeff1_3290a14a,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,158,"Use attribute access notation, not dict:

instance.created_at

The reason the dict-like access works is because of the NovaObjectDictCompat on the Instance object which we want to eventually remove.",FUNCTION
1070,9fdfeff1_d3339f12,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/unit/api/openstack/compute/test_migrate_server.py,624,this comment seems wrong,EVOLVE
1071,9fdfeff1_ca6d9e32,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,73,Where does compute1 come from when you started a compute service named 'compute'?,DISCUSS
1072,9fdfeff1_a05ba31f,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,256,"If this is empty we can just continue, right? We don't need to make a query to the cell database for a bunch of instances we're not going to use.",FUNCTION
1073,9fdfeff1_35707472,8d9c231632605a54c6c8b262cf4e510c1a215aea,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/functional/test_servers.py,6351,Don't you need to do the mock stuff before actually creating the server? Otherwise you could race.,FUNCTION
1074,9fdfeff1_7a327bf4,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,749,note to self: Is this true for cyborg?,FALSE
1075,bfdaf3ff_9f6f3191,fb4dcaccb041a6ae38a4e46c7ed83fc855c707db,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/tests/functional/test_images.py,101,"Hm.

IRL what we send across the wire to glance doesn't contain 'instance_owner'. We're hacking that into the metadata just long enough for it to travel into GlanceClientWrapper.create(), where we parlay it into a POST to the glance /v2/images/{image_id}/members endpoint. So IRL by the time we get here, we should *not* see 'instance_owner' in the metadata; but we *should* be able to do a GET /v2/images/{image_id}/members and see self.api_fixture.project_id in there.

I haven't fully grokked at what point the glance fixture intercepts things. We may not be able to do a true simulation of that part of the flow here. But one way or another, we need test coverage for the delta in nova/image/glance.py, and I don't think we have it.",FUNCTION
1076,9fdfeff1_71d7d0ef,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/compute/api.py,2449,"In this case the RequestSpec.user_id could also be None, so _save_user_id_in_instance_mapping might not actually change anything, but it shouldn't hurt either.",FUNCTION
1077,5fc1f717_30c25087,b927748c257e705903c2aa0ffa47b19914e31ede,59d94633518e6f6272e9f0654bb908e332f97a96,nova/tests/unit/virt/libvirt/fakelibvirt.py,186,"oh look, some constants with meaningful names! \o/",DISCUSS
1078,5fc1f717_fc81ac4b,e75b9d0bc938dd7c32dd9356ad62ead85c275866,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,5941,"This is already in the base class:

http://git.openstack.org/cgit/openstack/nova/tree/nova/tests/functional/integrated_helpers.py#n414",EVOLVE
1079,9fdfeff1_c47b80bc,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3569,use instance.image_meta to get the same thing but in an ImageMeta object - note you'd have to do image.status rather than image['status'] because ImageMeta doesn't use the dict-compat mixin.,FUNCTION
1080,1f769fc5_f8010eb1,63d77bf63fd474d10fd7cac5f725784737bafa1a,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,235,"nit: to be extra clear, could probably add, ""ensure that the instance directory itself, specified via ``[DEFAULT]/instances_path``, is not shared..."".",EVOLVE
1081,dfd5e7cf_21e2d130,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/tests/unit/pci/test_request.py,262,++,DISCUSS
1082,9fdfeff1_aa74909a,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,829,needed,EVOLVE
1083,bfdaf3ff_dd7645d9,7cb53a855a0490a836f90ad4cb945e5bcd83c753,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/api.py,3592,"this seems causing test failure, you passed ImageMeta here and it should be image?",DISCUSS
1084,3f79a3b5_edff18ae,97865392e4d22960a455901a5428a9995b93c90e,5c633ac52da0ec7f5de99008868dd0dce96ae56f,nova/compute/utils.py,204,"I don't think this will cut it for the libvirt driver during boot from volume.

We get close to this code during bfv here:

https://github.com/openstack/nova/blob/ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57/nova/compute/manager.py#L1682

but if the bdm has a device_name specified, we skip that one:

https://github.com/openstack/nova/blob/ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57/nova/compute/manager.py#L1670

furthermore, if the bdm doesn't have a device_name set, we'd call the driver:

https://github.com/openstack/nova/blob/ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57/nova/compute/manager.py#L1598

and the libvirt driver implements that method:

https://github.com/openstack/nova/blob/ba163cd5fd3e6ea9a42f0b8082e8e096885f0c57/nova/virt/libvirt/driver.py#L8984

So you should definitely set the max to like 1 and then try to bfv with 2 bdms with devstack and libvirt and make sure I'm not missing something, but if you can do that and it doesn't fail, it's likely because _prep_block_device isn't hitting this code path during bfv so we're not enforcing the limit.",FUNCTION
1085,3fce034c_b58a7718,c0db968abc47672abac9c2a99554cece5c642d2f,acd64d1d805ad36004bc4c23d74ed7490bd43857,nova/tests/unit/scheduler/test_utils.py,433,"You could link this to the ComputeNode object in the test by adding hypervisor_hostname='test' to the object above. The mock covers it up, but it might help people connect the two things.",EVOLVE
1086,ffd0ebdf_724b0d87,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1045,"This should be made generic, maybe just ""multipliers"".",EVOLVE
1087,3f79a3b5_ec61a810,1c9d745cb9aed1565e45002ff2a375bda9fa9417,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/compute/api.py,4298,"A comment here would be good, i.e. ""The begin_detaching() call only works with in-use volumes, which will not be the case for volumes attached to a shelved offloaded server since those volumes will have 'reserved' status.""",EVOLVE
1088,9fdfeff1_12b8fdc5,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,2096,nit: looks like this could be a staticmethod,FUNCTION
1089,3f79a3b5_a1f5fccd,e65f25b1c8f4e8edb2720aa509969b2b268abf1a,ebe93fd07643847cc65b439058dc998839c5783f,nova/objects/compute_node.py,233,"seems these lines can be combined, you have just assinged lots of values here...",EVOLVE
1090,9fdfeff1_f18e0426,fb10f7ed0cd1566da3e068490300b1ebd053af8f,d89579a66ac38fd1e30cea55306e6e7b69bab5b9,nova/api/openstack/compute/servers.py,658,"I can see the organizational benefit from alphabetizing the exceptions, but mixing formatting changes with functional changes in the same commit makes it difficult to determine what the functional changes are.",EVOLVE
1091,3f79a3b5_ba9fc54c,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,640,same,FUNCTION
1092,5fc1f717_f7af2b7a,40f6672f53794b563f4c7e27ede7b59a1d63c14a,73aaead294b9df412305abb1cb01aac95477bcc1,nova/tests/unit/compute/test_compute_api.py,1850,"My usual comment: since the mock is unused, this could be

 new=mock.Mock(return_value='nova')

and get rid of the generated param.",FUNCTION
1093,dfd5e7cf_d945f044,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/conductor/tasks/live_migrate.py,195,"nit: line above this. Also, ""At the moment"". The below could be bullet points",EVOLVE
1094,9fdfeff1_74d05ef8,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/tests/functional/test_compute_mgr.py,75,ditto,EVOLVE
1095,9fdfeff1_47df8d39,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/exception.py,250,"403 should be for authorization failures, not bad input or failed preconditions. This is a pretty classic 400 in my opinion, not a 403.",FALSE
1096,bfdaf3ff_73f176cd,e7ae769cc7cee0406d5819ca7aa88c69ccec9a0a,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/unit/objects/test_compute_node.py,454,"Can we add a positive test for version 1.5 to prevent this happening again. It's not the first time this has happened and I doubt it'll be the last

Ditto for the rest of the these changes",FUNCTION
1097,9fdfeff1_0b2b9e82,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,339,try to remove,EVOLVE
1098,3fce034c_7cabbad5,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/cells/manager.py,171,"Curious, any reason not to just remove this line and the whole _sync_instance method?",DISCUSS
1099,bfdaf3ff_99b64a3e,3ab8220bb0848bd5a5322783bd6e404da6d3f855,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,645,"Is there any reason why we can't just *always* use the user-context client for updating the dns_name attribute?

Nothing wrong with this code, but it seems like it would be easier to just always call _reset_port_dns_name() and remove the condition around network.get('dns_domain') and just always use the ""neutron"" client (as opposed to the ""port_client"" which is the admin client).",DISCUSS
1100,9fdfeff1_3658c7f8,be7e417bc7df90b4f062a1fd81cd4d53dda37eeb,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,2533,you can use decorator instead of this.,FUNCTION
1101,9fdfeff1_e1147643,026b135d879fb0f67bb1de191fa57681205b0ac7,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/storage/rbd_utils.py,328,"This is the security hole: you're doing format inspection. It doesn't matter if you do the format inspection during a convert or in an info command; it's still the same format inspection.

In order for this to be secure you would have to pass the input format to qemu-img info explicitly, in which case you wouldn't need to run it anyway. But you can't pass it, because we don't have it in this context. IOW: you can't do this here.

If a user can construct a malicious qcow2 header, declare the file as raw, and have it processed by this code, then this code will detect it as qcow2 (despite it being raw) and honour the malicious header.",FUNCTION
1102,5fc1f717_9770d074,a5d174c29f160ff01063be2583a2afe22088be2d,a76eefed62db96fe51ef40e3209c187af3eb9834,nova/tests/functional/libvirt/test_reshape.py,98,temporarily,EVOLVE
1103,3f79a3b5_31278969,4dc9b75b0d44b0a0cd3253e5b673f1b8f1c01e0c,ac0172594db79b863cef94c7b2c6f8afebac924a,nova/tests/fixtures.py,2044,by default would skip the results from down cells.,EVOLVE
1104,9fdfeff1_ca505035,33644fbc8ebbca43d4d706d38501314a07ae5e66,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,675,guess what a future patch could do for these hard-coded strings? :),DISCUSS
1105,dfd5e7cf_1a314a0c,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,38,could we use filter_utils ? as compute_utils. I was having a litlle bit difficulty when I see utils.xxx below as we are in utils.py already. But maybe it's just me. :),DISCUSS
1106,9fdfeff1_2aab0a88,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6273,same,EVOLVE
1107,9fdfeff1_be41c065,9311aceadf385e3c2655cf44aae720b9b7282eac,a90c8e1a359a236e06f3a78df74f55808bbef31b,nova/objects/block_device.py,380,"The spec only says that volume_id and attachment_id will be nulled out on detach of the root volume:

https://specs.openstack.org/openstack/nova-specs/specs/stein/approved/detach-boot-volume.html#proposed-change

So why are we nulling everything else out?

Also, we will still continue to show the root volume when listing volumes attached to the instance right? I mean with a GET /servers/{server_id}/os-volume_attachments call:

https://developer.openstack.org/api-ref/compute/?expanded=list-volume-attachments-for-an-instance-detail#list-volume-attachments-for-an-instance

Based on that we might want the device_name (and as of https://review.openstack.org/#/c/631948/ the tag). Otherwise what is the API going to be showing for the volume_id when the root volume is detached? Just None? Looking at https://review.openstack.org/#/c/623981/11/nova/api/openstack/compute/volumes.py I guess yeah we'll just show None for the volume_id and with the new microversion we'll also show the boot_index, so if you see a volume attachment with volume_id=None and boot_index=0 it means the root volume is detached.",DISCUSS
1108,5fc1f717_bd602237,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,90,"and then you could have done this here:

 from nova.pci import request as pci_request",FUNCTION
1109,dfd5e7cf_39a51c05,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/conductor/tasks/live_migrate.py,201,"nit: as elsewhere:

  if self.instance.pci_requests is None or not len(
          self.instance.pci_requests.requests):
      continue

guess we could also add a '__bool__' function to 'InstancePCIRequests' to allow us to simply say:

  if not self.instance.pci_requests

but that's a nice-to-have",FUNCTION
1110,9fdfeff1_d0c6d668,9ba910bb539b0172bab899852692a49d30645a14,a5d6833d77c961ea75488f0992b91d3166424381,nova/tests/unit/network/test_neutronv2.py,3064,"note that this is default return value for a mock, so not necessary. I see it's just copy/paste though, so no worries.",EVOLVE
1111,3f79a3b5_6d7af2cc,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7397,"I was wondering if this should check is_post_copy_enabled but looking at live_migration_force_complete, that will trigger this code:

https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/virt/libvirt/migration.py#L548

And if post-copy is not enabled, then it will just pause the VM to complete the transfer.",FUNCTION
1112,9fdfeff1_3939d8d7,47163c365bd986cddd8a9f87abcc1db590a01573,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/tests/unit/virt/libvirt/test_driver.py,11880,Why do we need to convert these into dictionaries in the first place? Couldn't we just compare the objects if we started returning a dict from '_generate_target_ret'?,FUNCTION
1113,5fc1f717_bceea81e,24fe74d126f23bea56c87524b1005a2aaacb870c,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4555,"nit: I'd prefer to assert this is the case we expect by checking the error message:

ex = self.assertRaises(...)
self.assertIn('need to have a non-zero size', six.text_type(ex))",FUNCTION
1114,3f79a3b5_2db04528,52b89734426253f64b6d4797ba4d849c3020fb52,f5984400373716ee5473266ab2a15bcd74f604fc,nova/conf/workarounds.py,224,"if we back port this which im ok with 
we should default to True on the sable branches.

the reasoning behind this is reletivly simply.

1.) this would be a behavior change to backprot with the default of false as live migration however broken would no longer ""work"" following a minor update.

2.) ovs-dpdk, vpp, snabb, and vrouter all support vhost-user which requires hugepages to be used as nova cannot configure a non hugepage memory backing currently that meets there needs. one of the key factors in calculating the appropriateness of any of these vhost user backends over sriov is the fact they allow live migration. defaulting to False would retroactively change that calculation. if yo remove livemigraton from equation the only motivating reasons for not using sriov are security groups and vxlan/tunneling support.

note that vhost-user backends are most common in NFV deployments where hardware tends to be uniform. additionally
when huge pages are used without CPU pinning the failure rate
for live migration is much lower and in production is typically not an issue.

3.) this can cause issue when people use cpu pinning or have
non uniform hosts so this is valuable to backport for deployment that are not using vhost-user backends. as such i am not arguing we should not backport the feature but just the default on stable is wrong.",FUNCTION
1115,9fdfeff1_b12e01a3,2e84ab93528727b20f3f802016e9af6939e69ea0,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/libvirt/guest.py,245,"nit: ""; target_dev ...""",EVOLVE
1116,dfd5e7cf_ee2cc448,05f9beac77d3481fe41baa3ae6fb4d35385e8d79,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/virt/libvirt/driver.py,364,"we are validating the disk_cachemode config option and loging warnign for invalid cache modes here in the creation of the libvirt virt diriver.

we should proably Log an error and raise an excpetion to stop the compute agent form starting in this function also around line 381 if both tunneld and tls migration are enable to adress sylvain's comment.",FUNCTION
1117,5fc1f717_ee435b3e,e438b926202b1b13f9a04dbf16551cdb0e8ae566,95501d6f7876a9c218351d4e418e3f9779cca46d,nova/tests/unit/privsep/test_libvirt.py,43,b'I am a fish',FUNCTION
1118,bfdaf3ff_198f1624,ed5362d09f655e8f04d0f9ccae22f9c4480a852c,c9ac27f1bcf81d0cf8a06414edcafc3a9068ae1f,nova/compute/manager.py,7679,change this to a warning() please,EVOLVE
1119,bfdaf3ff_be7350e7,07403a490bb6d390e8e923a1d4fec1dd969e5089,571355d40f78b6dacbaf8fd3401f96a50708febb,nova/network/linux_net.py,1455,"This isn't the same thing. We were explicitly not checking exit codes here previously, whereas now we're checking for [0,2, 254]. That said, the exit codes don't appear to be documented in the man page so I'm not sure what this should be looking for.",FALSE
1120,3f79a3b5_1e1ea60e,5d1a50018510b2b281ad33895ae2d9555f5d5b05,11a5fcbb6a3302c581f763776496d0833cf80ab6,nova/scheduler/client/__init__.py,21,nit: add a TODO to remove this proxy and just have callers hit the necessary clients directly.,EVOLVE
1121,5fc1f717_b06400bb,b927748c257e705903c2aa0ffa47b19914e31ede,59d94633518e6f6272e9f0654bb908e332f97a96,nova/tests/unit/virt/libvirt/fakelibvirt.py,205,"ooh, neat, learn a new trick every day. :)",DISCUSS
1122,9fdfeff1_262bdd33,cd7df1864634f09a728bfa9adcb78c431e05ae51,549f899d9b31714c2efbfa476822257cec83bd8a,nova/privsep/path.py,75,"We can't do this. This will potentially create an empty file in the image cache. The image cache doesn't verify the contents of files, only that they exist, so this would potentially lead to a situation where the only way to recover is for the operator to manually delete things from the image cache.

This is most likely only required due to some behaviour that nfs lacks by default. Perhaps something relating to flushing? We need to find and address the root cause rather than adding a workaround which is likely to bite us at some point.",FUNCTION
1123,9fdfeff1_446402e6,85985dbf91df81c7d66118ae29b2a2787f3ede86,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/api/openstack/compute/views/servers.py,344,"you can use context directly, the line 244 already get that.",EVOLVE
1124,ffd0ebdf_a81ee46d,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,202,"nit: we are really inconsistent about what we call this thing. If you run the nova-api-metadata script, then the actual services table entry is called ""nova-metadata"", but we refer to the thing as nova-api-metadata and nova-metadata-api all over the docs.

To be consistent, if we're talking about the service, let's just say nova-metadata. If you want to mix ""API"" into the wording, then say ""the nova-metadata API service"".",EVOLVE
1125,3f79a3b5_84233d57,f2fd72a31bd15053076febaa2f85949228beacc8,8d089111c8554e94e117ada3a7f51a42df59e84f,nova/tests/unit/api/openstack/compute/test_server_metadata.py,82,This can be removed.,EVOLVE
1126,5fc1f717_5db42c82,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,6724,likewise,DISCUSS
1127,dfd5e7cf_ea033041,9160fe50987131feda9429c4e95d573e176916b6,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/tests/unit/virt/libvirt/test_driver.py,10463,what's this suffix here for?,DISCUSS
1128,9fdfeff1_8f1a717a,634bc66c85fc5fa4b05f5ee0b23654c94157f37f,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,695,"nit: could have reduced the diff somewhat by just returning True here and cleaning it up later. As is though, this is still mostly readable",EVOLVE
1129,5fc1f717_932004fa,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c,nova/compute/api.py,3596,"Still don't see a patch that calls get_pci_requests_from_flavor in here, I guess you're working on that yet.",DISCUSS
1130,dfd5e7cf_87bc0306,5b2021575a618d603685b97b694934c857e6f9c6,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/tests/unit/virt/libvirt/test_driver.py,18739,"There is not an assertion for mock_direct_io.
It should be added.",FUNCTION
1131,dfd5e7cf_cadf4cd4,9160fe50987131feda9429c4e95d573e176916b6,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/conf/libvirt.py,483,"Do we want to add a follow-up that actually starts the ball rolling on this deprecation, starting with the 'live_migration_tunnelled' option?

Later, ah, we need particularly new versions of libvirt/QEMU. OK, let's leave this now, but a TODO above the offending config option might not be such a bad idea",DISCUSS
1132,9fdfeff1_8ac23633,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/unit/virt/libvirt/fakelibvirt.py,764,nit: type is a reserved keyword so would be better if this were dev_type or _type or something.,EVOLVE
1133,dfd5e7cf_0f9278f7,f72f5c52d152852dcecabbf592194addad185c74,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,253,"relatively small nit: since the code on lines 229-234 and 248-253 is identical, it would have been fine to remove lines 224-234 entirely since the else: block would handle it.

That said, if you wanted to put some sort of LOG message in the conditional block in line 224-234 that differentiated the situation where len(db_vif_ids) < len(cached_vif_ids), then the duplicate block of code would be more reasonable...",EVOLVE
1134,9fdfeff1_38cbd6a5,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,720,"In this message you use ""partition key"", in the one below you use ""conductor group"". I'd prefer we settled on ""conductor group"".",EVOLVE
1135,ffb9cba7_fbe1e6ff,13278be9f265e237fc68ee60acfacaa1df68522e,b7a018f1265d9e0354e26822d32cbdc789819c35,nova/virt/ironic/client_wrapper.py,120,"Looks like we don't have to change any docs here either:

https://github.com/openstack/nova/blob/fef4696e005b12c2316e652d17d2310d573dd0e7/nova/utils.py#L1182",EVOLVE
1136,dfd5e7cf_0649e3ce,90c350fce0a30e59de753fddd6648513cc326ef7,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/pci/manager.py,295,nit: Maybe make this a constant? It is a tuple though so we don't have to worry about anything modifying like a list/set.,FUNCTION
1137,ffb9cba7_01296799,57465aae77a7af605bbf1ffa29f9dc4b97783922,f6667b05d2146c928468021e5569a34215e93020,nova/scheduler/host_manager.py,652,nit: return None explicitly,EVOLVE
1138,9fdfeff1_e524feb1,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/driver.py,160,"Note: if the intent is to backport this fix, I'm not sure if the addition of virt driver method signature change is going to be OK with stable policy. We should ask mriedem to confirm.",DISCUSS
1139,9fdfeff1_1e3ecc8b,36a064ac7896b3483973060664e660888006fa0c,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/compute/manager.py,5452,"so, could we just get rid of this? as we have two exception handling in the block_device.py",EVOLVE
1140,3f79a3b5_bf71d09b,c637958a0e1ab7839be560fa4430d73968d66336,62c09a335c586ab176aba3de5a13febc36f29940,nova/scheduler/utils.py,470,"Ah you forgot to check for None here as mentioned earlier:

http://logs.openstack.org/42/625942/1/check/tempest-full/5fcb021/controller/logs/screen-n-api.txt.gz?level=TRACE#_Dec_18_18_33_51_556093",FUNCTION
1141,9fdfeff1_9b075cca,12c38291b85a373905bd754bd210c7d1cac53662,d9bd5b1377acf4468c89422fa471de6c8325d775,nova/api/openstack/compute/servers.py,214,so we,EVOLVE
1142,3f79a3b5_cb516767,5cdb825394f3015ef4b1224eb7d9f55633d217e9,801ef1adca667ecdf243464b083282418d5987e4,nova/scheduler/client/report.py,850,Does this mean we don't have to refresh inventories here and we would be from on ? Sorry I am not very proficient with the whole provider sharing concept. Probably not a big deal anyways in terms of performance since if the whole refreshing config thing is disabled we would not reach here.,DISCUSS
1143,5fc1f717_29dc2273,2a12e420c2934e49da5cb3e586407d3f6e1d6300,554f2c850707b85b178425c68166d49f34df5561,nova/tests/functional/db/test_instance_mapping.py,210,Why not just include the test in InstanceMappingTestCase?,DISCUSS
1144,5fc1f717_82595e5b,9cee6a2bd3435522b90d614b120efbf7bc9d802f,9419c3e05499e55beda93d664197a7b0f0011ff7,nova/db/sqlalchemy/api.py,4277,i guess this is the minium chage that may fix trasient deadlocks the only real consern i would have is the deadlock will still happen and this might mask the negitive sideffect delaying fixing them but i think that is a resonable tradeoff,FALSE
1145,9fdfeff1_ed355c46,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3332,A comment would be nice to indicate this should be removed because its allocated value results in 0.,EVOLVE
1146,9fdfeff1_f174ed69,c2331d692445796d604d27d2388309f2eb545d31,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/tests/functional/api_sample_tests/test_servers.py,453,ditto,EVOLVE
1147,9fdfeff1_4b524b15,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,440,"Rather than stub this out, can't we just use the APIs to create a server group (in setUp) and then create a server in that group? Then we can avoid the redundant test_servers_post and server group stub in all of these functional tests, and use the real APIs.",DISCUSS
1148,9fdfeff1_8879d4c8,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/pci/manager.py,188,ResourceTracker,EVOLVE
1149,3f79a3b5_8c480689,31e7f0bb82b93b50b5c50076fcd8c2d133f6eb00,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,420,post-copy,EVOLVE
1150,9fdfeff1_40ad21e7,3fbf336a38556db1fce2e9744a3c9712bf463614,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,35,Why is this added? It wasn't in nova.utils.monkey_patch().,DISCUSS
1151,ffb9cba7_5e2ee0a5,186b37f8237010b5abd4ab4ad208a9ea400f8819,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/api/openstack/compute/availability_zone.py,93,"Actually duplicates above appear to not even matter since we'll still process the hosts properly (I wrote a test) but it does mean we'd needlessly run through these loops more than necessary. I'll leave the test in place anyway. Really making sure we do the duplicate handling properly would probably mean refactoring this code into a private method, then mocking that to call the actual function but then count how many times it's called (once per zone+host combo).",EVOLVE
1152,dfd5e7cf_a181e14c,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,180,if,EVOLVE
1153,3fce034c_98a572b8,a4543eaf2e55bfb3abd981aa9d743f39cd2559ce,0d1310224818c204c52f67deee18efafd1269681,nova/tests/unit/scheduler/test_host_manager.py,1144,Why this?,DISCUSS
1154,9fdfeff1_430378bf,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,172,"Same, assert it's False.",FUNCTION
1155,5fc1f717_32046f15,b58c0a775375ac8a3180ed2444d2fe066226731b,e65a5275eeecae6ab041db2f089ae5dc3eefd92c,nova/tests/unit/virt/libvirt/test_imagebackend.py,1882,"You can do this by using assertRaises() as a context manager:

 with self.assertRaises(...) as cm:
     self.assertIs(e, cm.exception)",FUNCTION
1156,9fdfeff1_574ece96,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/functional/test_servers.py,6321,"thanks, it helps reviewing",DISCUSS
1157,3f79a3b5_570f7c37,4a5da5a3b471bb5592d0a97e93bb69152e6447c0,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/privsep/qemu.py,60,This part is still well test in test_utils.py,FALSE
1158,dfd5e7cf_e150490d,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,189,nit: think this might unnecessary (.get defaults to None),EVOLVE
1159,dfd5e7cf_bd0fd82c,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/ram.py,20,ditto,DISCUSS
1160,9fdfeff1_ac3f1f23,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,266,"I'm a little lost here. You want to migrate (a) instance mappings for SOFT_DELETED instances (which can be restored with the restore server action API), but you also want to migrate (b) mappings for instances that are not deleted (soft or hard). Looking at:

https://github.com/openstack/nova/blob/eb93d0cffd11fcfca97b3d4679a0043142a5d998/nova/db/sqlalchemy/api.py#L2136L2161

You can pass both a ""deleted"" and ""soft_deleted"" filter, but it looks like what you're saying is you can't do something like:

deleted=False
soft_deleted=True

Because then you'll only get back SOFT_DELETED instances, i.e. (a) above but not (b).

Is that correct? So you just get them all, even if they are otherwise hard deleted.",FUNCTION
1161,9fdfeff1_53a07890,d4a0e470fe9987950bc84ae2f658232bde8d95c7,33aad0fe41d86721c869d7c0d47cede2e500188f,nova/tests/functional/notification_sample_tests/test_instance.py,1588,"The following is better.

  self._wait_for_notification('compute.exception')

or replace line 1537 with above.",FUNCTION
1162,3f79a3b5_a7818948,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,203,querying,EVOLVE
1163,9fdfeff1_564e99c1,5b8f5a201d72c3e45938a1eb020c913fa0d51efe,c0cd8fe8c1cb217063eacfa8aa3d4d46093c71a0,nova/api/openstack/compute/servers.py,476,"mm, that's a tad icky, why not do what the docstring says and return it?",FALSE
1164,3f79a3b5_47e2f537,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,204,. If you,EVOLVE
1165,9fdfeff1_8e1e8e6e,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,905,invalid value?,EVOLVE
1166,9fdfeff1_afddccdd,7baa1c93099283967e158d4b2d18419f465d644b,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/tests/functional/regressions/test_bug_1671648.py,80,"The way this is used makes a guy wonder whether the intent was to call the method, rather than waiting until the end of the test case.

[Later] FWIW, the test still passes when I do that ^

Seems to me like the overridden node list is just there for the compute service to pick up during start_service. If it were going to have an impact anywhere else in the test case, it would have screwed things up by always being set to the *last* node list we set_nodes()d.",FALSE
1167,3fce034c_44904b4f,02b26457f3c5773973f374f39e069d2a854e99f6,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/tests/unit/objects/test_request_spec.py,998,"Should we check that in_tree is there before we downgrade the object.

Maybe not necessary since that's effectively confirming that python works, but it has a nice flow to it.",DISCUSS
1168,3f79a3b5_07e87d11,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,205,globally,EVOLVE
1169,9fdfeff1_4a2c4e01,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,31,"The super class already has self._wait_for_state_change but I like this version better, since the version in the parent class uses that ""from_status"" which is always very confusing to me. At some point I'd like to move everything over to this version.",DISCUSS
1170,3f79a3b5_25d5fc48,fd540e2135c26d8c297695a3fa73d993655f0ad8,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/image/glance.py,485,"good catch.
based on the docs you found 

https://docs.openstack.org/python-glanceclient/latest/reference/api/glanceclient.v2.images.html#glanceclient.v2.images.Controller

the final argument is the location metadata which is required.

this also echos the code in horizon 

http://git.openstack.org/cgit/openstack/horizon/tree/openstack_dashboard/api/glance.py#n542

so this all seam correct to me",DISCUSS
1171,5fc1f717_c6149143,b63c42a0d4836fd0364cb306145d3474619f1e19,a8f9a6277055e2c106c2af4f4c56766d417c0cd6,nova/tests/functional/test_servers.py,6742,we don't have this exception in _fill_provider_mapping method now. So I'm doing a revert for this patch https://review.openstack.org/#/c/648605/,EVOLVE
1172,9fdfeff1_03f4955a,95c01d25e95da9a5ad704e8f945f03a252b42ed5,5fc1f74cd2ec2f42b227086e87bd247059804064,nova/api/openstack/compute/views/servers.py,168,"This is where I'd handle None:

avz = instance.availability_zone or ""UNKNOWN""",FUNCTION
1173,9fdfeff1_6260d636,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/objects/request_spec.py,726,Comments here would be nice for each condition. First is the allocation drops below 0 so it can't be a candidate resource provider. Second is the provider does not provide the required resource class.,EVOLVE
1174,5fc1f717_fcc5953e,59d95fabf796a3b33c2e086c4c27eeb2811eda20,edc130bc226e0e073b9fa102e8e77d6ba0834440,nova/tests/functional/test_servers.py,0,You'll have to fix this up accordingly once the preceding patch is modified as noted.,FALSE
1175,5fc1f717_8f779ed4,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,504,"I very much like this and am surprised you are already aware of the terribleness that is the RequestSpec persisting these kinds of per-operation fields, i.e. why RequestSpec.reset_forced_destinations exists.",DISCUSS
1176,3f79a3b5_4b917b44,87493307a467ff75265d681d9d908589e6ac8094,bdad0e1b75be9713e5c665f1ac96843e4df3106e,nova/virt/libvirt/migration.py,320,"nit: ""Save off the hw address and MTU presented...""

Could also link to https://bugzilla.redhat.com/show_bug.cgi?id=1449346 for the MTU thing - or link it in below where your NOTE lives.",EVOLVE
1177,bfdaf3ff_0a8793d9,fd19aeafbce0fa11821b2a064bd694b078613c2f,30ecd69ac17392f2bad6343e7df9301de884557c,nova/objects/numa.py,154,nit: I would move this below by one line.,EVOLVE
1178,9fdfeff1_69ef4de9,3a9d8316dcf5677b25938dfbfa0b898f072c0aa0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/objects/request_spec.py,839,And this.,EVOLVE
1179,5fc1f717_87649e23,e2185168f812286dd140936df64261e67568a410,549f899d9b31714c2efbfa476822257cec83bd8a,nova/api/openstack/compute/instance_actions.py,171,"Oh wow, obscure.",EVOLVE
1180,9fdfeff1_ff5fabe2,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,944,ditto,DISCUSS
1181,9fdfeff1_05d3ab02,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/pci/request.py,220,"Yeah so I think this is wrong - glad I asked. This should be flavor.flavorid because that's the user-facing string version of the flavor, not the internal integer primary key. This would likely blow up with a TypeError or something if we had a functional test for this.",FUNCTION
1182,dfd5e7cf_69ed2eee,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/virt/hardware.py,1050,"Is it safe assume that the host smallest page size is always 4k?
If a host smallest page size is 2MB then this code allow oversubscription of the 2MB pages. Would oversubscribing 2MB pages cause problem?",DISCUSS
1183,9fdfeff1_f201b96b,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,174,instance.user_id,FUNCTION
1184,9fdfeff1_522edcfa,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/tests/unit/objects/test_request_spec.py,1345,"technically, no, this only fits to rp1 and rp3. rp2 has a egress inventory of 2 which is less than the requested amount of 3.",EVOLVE
1185,9fdfeff1_33cd3eb7,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/compute/manager.py,2129,"A comment here would be good, especially with an example of what this would be, i.e. in the minimum bandwidth based scheduling case, this is a dict, keyed by port_id, to resource provider UUIDs that fulfill the port's requested resources.",EVOLVE
1186,5fc1f717_d39f6c4f,74ef3a67096ca8203cd344e4ee32c71ab340ab1b,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/tests/unit/virt/xenapi/test_xenapi.py,3383,Why is this needed? Seems totally unrelated.,DISCUSS
1187,bfdaf3ff_fdd68227,397f7ea9f686eaf8d0ca8f267f26e29ded710bb3,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,736,ditto,EVOLVE
1188,9fdfeff1_858ca47f,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/exception.py,2157,"nit: QoS is the only type of port that can have resource requests today, but I imagine there will be future use cases for ports have resource requests for things besides QoS, so this might be a bit too specific. You could maybe make it generic and yet still useful by re-wording as: ""Creating servers with ports having resource requests, like a port with a QoS minimum bandwidth policy, is not supported with this microversion.""

And then could leave a TODO to mention the specific minimum microversion in the error when you add that microversion.",DISCUSS
1189,5fc1f717_2ee9bfe1,50a0c6a4b98a3ef1d893b0bb204a4a4868017cbb,da9f9c962fe00dbfc9c8fe9c47e964816d67b773,nova/virt/hardware.py,859,"For future readers, the error occurs specifically because if sibling_sets is empty we never iterate over this loop and therefore sibling_set is undefined.",FALSE
1190,dfd5e7cf_6f31920b,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/conductor/tasks/test_live_migrate.py,677,"I feel like these should be separate functions, but I'm also ok with them as-is",EVOLVE
1191,9fdfeff1_ecb4abf4,fcdc5f1a6029e34f9cb4ff92e974134be1272bcc,8f38da3bf7ecae8a78888a2e64b90e5011c59d20,nova/virt/libvirt/driver.py,6758,OK and this is always going to be a LibvirtLiveMigrateData now because we're no longer handling old computes passing legacy dicts back and forth. That was all removed with Ibcb6bf912b3fb69c8631665fef2832906ba338aa in Rocky.,EVOLVE
1192,9fdfeff1_94efbde7,f8626235614eb3cf66b0fdf9b9c3e70d3982f03d,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,828,Stein,EVOLVE
1193,3f79a3b5_380c8841,e7ef319ce49be1e0e6df76f1be2072aa489d9513,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/objects/instance_pci_requests.py,90,"you proably want to set a default to 
""legacy"" or ""preferred""
when loading old objects from the db.",FUNCTION
1194,3f79a3b5_283525d3,256e35fe49da9d3dac430c3b92d6ed2e5c500a12,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/tests/unit/virt/libvirt/test_driver.py,11433,"I think by this change we lost test coverage over the if starting at: 
https://review.openstack.org/#/c/619143/8/nova/virt/libvirt/driver.py@7404",FALSE
1195,9fdfeff1_1310e34d,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1411,string name of host,EVOLVE
1196,3f79a3b5_1d173e44,183f6238c1d98b04fdcee0fb70212f01f4012ae4,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/compute/rpcapi.py,399,"We should probably do the same for this:

http://logs.openstack.org/82/623282/2/check/tempest-full/0a4f66a/controller/logs/screen-n-api.txt.gz?level=WARNING#_Dec_11_06_09_01_928385

http://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22The%20nova-osapi_compute%20service%20version%20is%20from%20before%20Ocata%5C%22%20AND%20tags%3A%5C%22screen-n-api.txt%5C%22&from=7d

I'm kind of surprised no one has complained about that. Maybe no one is running nova-api pointing at cell0 for [database]/connection.",FUNCTION
1197,5fc1f717_cf31265b,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/objects/compute_node.py,426,"I think this would yield the same result - it's a LIKE query on the nodename which for Ironic should be an exact match sine the nodenames are UUIDs.

So if I'm forcing to a specific baremetal node but not specifying a compute service host, like:

openstack server create --availability_zone nova::c733ba69-0832-4e55-bd4a-781404f2fb36 ...

Then we'd would just query this method with c733ba69-0832-4e55-bd4a-781404f2fb36 for the hypervisor_match value and should get at most 1 entry in the resulting ComputeNodeList.",FALSE
1198,9fdfeff1_ee2b8330,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/api/openstack/compute/volumes.py,73,Call summary because summary doesn't include tags.,EVOLVE
1199,bfdaf3ff_784ae355,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/scheduler/client/report.py,313,"if you take my advice about having a separate function on ProviderTree that does the tree-traversal stuff here, instead of passing a whole_tree=True argument, you might consider making that new function ProviderTree.remove_subtree() and wrap the removal code into the function. You can have ProviderTree.remove_subtree() return the list of remove UUIDs, as well, so that lines 314-315 will be possible.

That way, you wrap the related tree-fetch-and-removal code together in a single-purpose method on ProviderTree and leave ProviderTree.get_provider_uuids() method as-is.",EVOLVE
1200,dfd5e7cf_5a07d21d,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/io_ops.py,21,ditto,DISCUSS
1201,9fdfeff1_0ca9f4db,ecd0d0c3572f77b844e5dd9657204d23ada12318,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/tests/unit/compute/test_instance_list.py,240,nit: I'd remove this because it won't be so new in a few years.,EVOLVE
1202,9fdfeff1_933a60e3,fee7f24f26c803bab1a52adef8eb01947c4fbe12,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,169,Why not use obj_fields.HVType.QEMU here and do a case insensitive check?,DISCUSS
1203,9fdfeff1_23fc393d,95c01d25e95da9a5ad704e8f945f03a252b42ed5,5fc1f74cd2ec2f42b227086e87bd247059804064,nova/api/openstack/compute/views/servers.py,472,"See comments in:

https://review.openstack.org/#/c/591657/29/nova/api/openstack/compute/views/servers.py@507",FALSE
1204,dfd5e7cf_0f232607,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/compute/test_compute_mgr.py,8530,profile,EVOLVE
1205,9fdfeff1_e3c5d10b,5fc1f74cd2ec2f42b227086e87bd247059804064,8bf886744941a564d9522fe98658640473c44c0a,nova/compute/api.py,2425,"This seems like something we should be handling in the view builder code rather than in the compute API code, I mean with the ""UNKNOWN"" value.",EVOLVE
1206,5fc1f717_69aa2a86,d24275951d3ad0e0ae00621971278aeedf2bfd09,2a12e420c2934e49da5cb3e586407d3f6e1d6300,nova/compute/api.py,2443,"nit: I'd probably say ""a future release"" to be safe, because if we land this in Stein, people will be migrating before getting to Stein or during Stein, and then if we are going to drop in Train we'd have to add a blocker migration so people can't get to Train without running the online data migration first, so it's a tricky dance - you'd have to leave the online data migration in Train so people that upgrade before completing the data migration can still do so, meanwhile dropping the compatibility code in the API....

Anyway, ramblings but I've seen enough of ""drop this in Pike"" or ""drop this in Queens"" type stuff still lying around to know we're not great about following up.",EVOLVE
1207,3f79a3b5_fce561d0,953aaea65091ead541def6cf56f56a23d899d7c9,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/db/sqlalchemy/api.py,3835,"I'm not sure the rule about when we should use ""@pick_context_manager_reader_allow_async"" or ""@pick_context_manager_reader"", but I saw [1], it seems it would be used when we already have an async operation, and in here, we can see called from [2], it seems not a async process.

So, I think we could use @pick_context_manager_reader is OK. And I still think it's better to get some idea from other.

[1] https://review.openstack.org/#/c/249235/6/oslo_db/sqlalchemy/enginefacade.py
[2] https://review.openstack.org/#/c/614672/10/nova/objects/block_device.py@340",EVOLVE
1208,9fdfeff1_b8490661,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,91,s/may/will/ to make it a bit less ambiguous?,EVOLVE
1209,9fdfeff1_a4d75c23,451d41a9deaf4bdba20509afc15a73df02e400f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,743,"I presume that

 node_list = self.ironicclient.call(""node.list"", **kwargs)

handles regex expressions on kwargs like conductor_group?",DISCUSS
1210,5fc1f717_f33aa832,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c,nova/compute/api.py,550,nit: we should just remove this (let's not encode who calls this and why) and make root_bdm=None. Could be done in a follow up.,EVOLVE
1211,3f79a3b5_079dd669,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,226,"This reads like if you enable this workaround, you'll hit DestinationDiskExists and blow up. But what you mean is, if you're using [libvirt]/images_type=rbd but instance files (console log, kernel/ramdisk images, etc) are not on shared storage, you will hit DestinationDiskExists failures if the server is ever moved back to the same host with old files.

Correct? I'd probably re-word that to avoid confusion.",EVOLVE
1212,3f79a3b5_a3530bde,1d47f5be170f97840aba3dba72cc4d60f5659fc1,900413d7c228ce0f59f5b4de96a1b28b212c4503,nova/compute/api.py,3597,"This looks reasonable in the case of an upsize, but I think you'd want to put this logic in a helper function and only do the claim/enforce _if_ it is an upsize. In the case of a downsize or 0 change, there's no need to claim/enforce.",EVOLVE
1213,9fdfeff1_66924a4e,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,741,is %s'ing this going to produce anything informative? <RequestGroup at 0xabcd1234> ?,DISCUSS
1214,dfd5e7cf_7b9f4650,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/compute/utils.py,207,Why don't we check the number of disks if req_letter has already been set at this point?,DISCUSS
1215,bfdaf3ff_2468951f,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/conf/compute.py,817,"This won't render in rst properly, needs to be:

Possible values:

* Negative integer means unlimited
* Any integer >= 0 represents the maximum allowed

http://logs.openstack.org/77/616777/7/check/openstack-tox-docs/749c290/html/configuration/config.html#compute.max_disk_devices_to_attach",EVOLVE
1216,3fce034c_6141b90b,6f07f769020bdbe5328b3991fc5e9bc89815a970,a40bce7f80fc002b1a4d774b1f9394adb747016e,nova/tests/unit/scheduler/test_utils.py,115,diff noted in commit message,EVOLVE
1217,9fdfeff1_96d081f9,2ad333c54a8cf28a45bb263b24baac0e2ec81db5,b2299908d3bad434dd25d6c6bb0a9e6b4ab9eba2,nova/compute/manager.py,4478,could it be better to also change these to flavor? since you changed everything else.,DISCUSS
1218,9fdfeff1_df450719,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_linux_net.py,884,ditto,DISCUSS
1219,9fdfeff1_6ac9b677,7d9e3882e1a54ce421c36380817a1f619ccf250d,1948ce59c06aacc3fb9a71cbf8b099db8467da01,nova/pci/manager.py,329,recommend free_claimed_devices(),EVOLVE
1220,3f79a3b5_4eb65efe,8a5c7b51cd558f5a7b3183d890a1ef5905bf643c,8545ba2af7476e0884b5e7fb90965bef92d605bc,nova/virt/libvirt/driver.py,5124,"Is it necessary?
Why isn't 'caps' passed as an argument of '_guest_needs_pcie' method?",DISCUSS
1221,9fdfeff1_bfcda331,c467293b004bef254d5142ac4ee0b40364fc2ea1,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/api/openstack/compute/servers.py,645,You could add these to the test_create_instance_numa_topology_wrong unit test.,EVOLVE
1222,3fce034c_357e8719,c0db968abc47672abac9c2a99554cece5c642d2f,acd64d1d805ad36004bc4c23d74ed7490bd43857,nova/tests/unit/scheduler/test_utils.py,527,nit: add hypervisor_hostname='fake-node',FUNCTION
1223,3f79a3b5_f75faf49,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/scheduler/client/report.py,680,"nit: this is usually refered to as ""early exit"" but that works too.",EVOLVE
1224,9fdfeff1_8e1c3714,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/api/openstack/compute/volumes.py,229,This is only called by detail view and for the old os-volumes API.,FALSE
1225,9fdfeff1_2d3cc491,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/scheduler/client/report.py,1685,NOTE,EVOLVE
1226,3fce034c_7599ba1d,82c79ceac30d7b97d68c2d71bdd0aae8c7038811,f389773f5255051f2f1cff4d0b0a08eafc0ac147,nova/privsep/libvirt.py,229,"fwiw, I suspect the 'p' was deliberate",EVOLVE
1227,bfdaf3ff_3a2517ac,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3001,lets have a docstring as its being used outside of this module,EVOLVE
1228,9fdfeff1_00150249,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/servers.py,433,Why is this not conditional on the microversion?,DISCUSS
1229,9fdfeff1_f4621bad,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,768,"What does Train have to do with libvirt > 3.2.0? I guess you're assuming that we'll bump to 4.0.0 in Train?

https://github.com/openstack/nova/blob/bff3fd1cdbc441bf8d0bbe91099c2b2c57578b31/nova/virt/libvirt/driver.py#L230

Which Kashyap is working on:

https://review.openstack.org/#/c/632507/

But ^ only bumps minimum required libvirt to 3.0.0.

Or am I missing something here?",DISCUSS
1230,9fdfeff1_1ab00add,135889d8b5991ec249a31767f5a11fd89908e38f,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/objects/request_spec.py,819,unnumbered,EVOLVE
1231,9fdfeff1_78310c0b,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1365,x,EVOLVE
1232,3f79a3b5_943fa4b2,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/workarounds.py,202,"You need to indent these lines otherwise formatting is wrong:

http://logs.openstack.org/78/618478/8/check/openstack-tox-docs/ce664df/html/configuration/config.html#workarounds.enable_libvirt_rbd_instance_dir_evac_cleanup",EVOLVE
1233,3f79a3b5_3f414038,073c330f52dfa535e6f787f5bb2fc8ec52f1be9a,514eaaef12dad2460fd4c2fffdc05a3db0490711,nova/scheduler/client/report.py,1581,"Has there been any discussion of redoing whatever we were trying to do, now, instead of the next pass? For some people they may want to have long intervals between now and ""next"". Does that matter?",DISCUSS
1234,5fc1f717_e7096bdd,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/tests/functional/db/test_instance_mapping.py,304,How about a mapping for an instance that doesn't exist? Like residue after manual cleanup or after a periodic compute purge and before a db archive?,DISCUSS
1235,3f79a3b5_8f112afc,fb33dcfb92809255787f23463ceaf1496579c270,5d1a50018510b2b281ad33895ae2d9555f5d5b05,nova/conf/compute.py,666,"just curious, a compute node need a manual SIGHUP to refresh cache seems weird... lack of background :(",FALSE
1236,9fdfeff1_8b154e42,96524e18fd2d0a11aa0c3c078a401b72839009d7,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/tests/unit/pci/test_manager.py,339,from,EVOLVE
1237,ffb9cba7_f52b032d,ae659668b5679cf7223474193d3b9a584dd3f016,78e742662edd164c46382c31e106884762fed029,nova/tests/unit/compute/test_rpcapi.py,604,"Why is this called twice?

[later] because mock_minver.return_value = 0 so we don't set LATEST_VERSION so we don't short out of _determine_version_cap.",DISCUSS
1238,9fdfeff1_c1b38999,9311aceadf385e3c2655cf44aae720b9b7282eac,a90c8e1a359a236e06f3a78df74f55808bbef31b,nova/objects/block_device.py,378,"See comments in https://review.openstack.org/#/c/614750/ about the device_name but I don't see a good reason why we'd reset on detach and then have to generate a new device name on attach - the boot_index remains 0 and you can only have one bdm with a boot_index of 0:

https://github.com/openstack/nova/blob/d5bde60e5680962394e263a662a2f331b6da93cd/nova/compute/api.py#L1413

So I would expect the device_name to not change. You also can't change the disk_bus or device_type on attach so that wouldn't affect the device name either. Plus, at least for the libvirt driver, the device_name is not used anyway - meaning what you get in the guest might be something different from what nova says.",FUNCTION
1239,bfdaf3ff_c459895a,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/functional/test_conf_max_attach_disk_devices.py,28,"Similar to TestLocalDeleteAttachedVolumes - could move into InstanceHelperMixin later and DRY that up (TestLocalDeleteAttachedVolumes would have to be changed to use that mixin, so maybe not worth it).",EVOLVE
1240,3fce034c_53e001fb,acd64d1d805ad36004bc4c23d74ed7490bd43857,02b26457f3c5773973f374f39e069d2a854e99f6,nova/objects/compute_node.py,278,Same as mentioned.,DISCUSS
1241,9fdfeff1_371bc5ca,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/unit/api/openstack/compute/test_serversV21.py,3812,good to add one more case for sg not existed,FUNCTION
1242,9fdfeff1_d78f1e2c,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,716,Ã¢Å“â€,DISCUSS
1243,3f79a3b5_48e8a112,ecaceeb08123671ef2819b4fc6be58b4d4fb259f,256e35fe49da9d3dac430c3b92d6ed2e5c500a12,nova/virt/libvirt/migration.py,388,nit: timeout,EVOLVE
1244,5fc1f717_1816244b,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/conductor/tasks/live_migrate.py,218,++,DISCUSS
1245,9fdfeff1_94820b4f,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/scheduler/client/report.py,872,"Next respin, can we get rid of the male-centric wording? RPs are not men.",EVOLVE
1246,9fdfeff1_daa3629d,684e4ffc522c6e0f6079308274b1899046e45120,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,141,response,EVOLVE
1247,9fdfeff1_cb387bd4,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,349,Again I don't see why this is a list - it's either None or a single value. A list is potentially confusing to an end user making them think that a server can be a member of multiple groups when it can't.,FUNCTION
1248,bfdaf3ff_f9d01253,8a649f44541a8a6a743c4c77fd38c32651f7bf34,0bfb81b4dff5eb572ce8cd9e00f2a77134ce2816,nova/network/l3.py,121,So you've switched the order of the functions...,FALSE
1249,9fdfeff1_b6eef7ea,be7e417bc7df90b4f062a1fd81cd4d53dda37eeb,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/api/openstack/compute/views/servers.py,348,"I don't we will get a None value for sg. If there is None return, the exception should be raised, so the code will go to the line 351. So I think this if condition is useless.",FUNCTION
1250,ffd0ebdf_6eaea82f,2df1fbb5ac58a922fa8659ecf1779bc63ebce1c4,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,203,multi,EVOLVE
1251,3f79a3b5_d4351cd6,f2c6dd9767e4dfb6cf78df91df545c086cb95650,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/workarounds.py,197,issues? Workarounds normally link to a bug for more details.,EVOLVE
1252,9fdfeff1_672ad1e7,2ad333c54a8cf28a45bb263b24baac0e2ec81db5,b2299908d3bad434dd25d6c6bb0a9e6b4ab9eba2,nova/compute/manager.py,4545,are,EVOLVE
1253,1f769fc5_f3463022,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/compute/utils.py,208,"The reason why here doesn't consider the type 'ide' (which maximum number is fixed with 4 without configuration in this patch) is this method is not called in 'ide' condition, right?",DISCUSS
1254,bfdaf3ff_440ef98d,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/compute/utils.py,164,nit: might want to add a short blurb about this method also doing max device validation.,EVOLVE
1255,ffd0ebdf_ad2cb699,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/ram.py,35,ram,EVOLVE
1256,3f79a3b5_9221a952,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/compute/provider_tree.py,378,"then we get the list of all the uuid in the tree
remove the root node and all its children
and return the uuids of all the resource providers we just removed.",FALSE
1257,bfdaf3ff_3a2bd730,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/provider_tree.py,250,"If you want to be super clear here, you could say ""all the providers in the whole tree of which the provider named in name_or_uuid is a member"" or something like that. It took me a moment to translate ""associated"" properly.",EVOLVE
1258,9fdfeff1_36a9a78f,be7e417bc7df90b4f062a1fd81cd4d53dda37eeb,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/functional/api_sample_tests/test_servers.py,439,I prefer to use a real InstanceGroup obj,FUNCTION
1259,9fdfeff1_454ee5c1,d8f6882f547bd1a92fb38de5aed287d56bf8b233,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/tests/unit/api/openstack/compute/test_server_actions.py,551,is it weird that this is the same for both entries?,DISCUSS
1260,5fc1f717_8215514b,5418e8ea6688ca4c717d8b511720a20047656a1f,51aa230d2f0afe8a8fa9c5fb58f187ef1b243371,nova/tests/fixtures.py,1835,Should really add this in the patch that first uses it.,EVOLVE
1261,bfdaf3ff_a3ea49a9,661dd591c94a9203c1a63e17789b83539a364527,84d94171d93a89af9fc71f6a326a988842c64d5e,nova/conductor/tasks/live_migrate.py,195,"At

A newline before after this line would make this slightly easier to read",EVOLVE
1262,5fc1f717_8927ec12,6e49bb3809a151452f1ec0a7f2526cd4d9a9ee9c,6ebb2c4cae65cb437e17a8c02fe5174a9825d8e0,nova/tests/unit/scheduler/client/test_report.py,1658,Fixtures can be used as context managers so we can we just use that fixture here for OS_DEBUG and not for all tests in this class?,FUNCTION
1263,3f79a3b5_c7be97af,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7387,"A comment here would be nice to indicate what this is checking and if true, what happens. There is a lot of confusing code in this method so it really needs to be documented well.",EVOLVE
1264,9fdfeff1_268f5d24,1df30a2c42f74e74b344581f56fb1a0c131a2774,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/virt/libvirt/guest.py,247,"I really don't like putting vif type specific checks in this code. https://review.openstack.org/#/c/627537/1/nova/virt/libvirt/vif.py is definitely more generic - why was that abandoned?

I think at the very least there should be a comment in this code that vhostuser is special since target_dev is not set for that vif type.",DISCUSS
1265,3f79a3b5_ebe3a701,bdad0e1b75be9713e5c665f1ac96843e4df3106e,a0eacbf7fff60282007ddca705ef7331e8a4a6f8,nova/tests/unit/virt/libvirt/test_migration.py,794,"Same as above - would be good to have a comment/docstring explanation of the test. In this case, the source xml starts with an mtu value set so its OK for the destination xml to also have mtu set.",EVOLVE
1266,9fdfeff1_aa65bab0,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6240,A bit of time traveling here but OK.,EVOLVE
1267,9fdfeff1_8ea02af6,395ba18a913388ea184bfd4ae11eebc7a28471a8,f4796651df9cb211c071559cffc3e2e2fec8242e,nova/tests/unit/network/test_linux_net.py,1239,list,FUNCTION
1268,3f79a3b5_eb164ea2,ba0c1fbc6cd84e33ab35e6d467fd2a361e6cc7fa,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,419,"I think we don't have to say the backward competibility here, we just say ``abort`` is the default behavior.",EVOLVE
1269,3f79a3b5_0e9b86c6,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,nova/tests/unit/scheduler/client/test_report.py,2987,"hmm, previous unit tests were incorrectly failing to reset. nice catch here and below on line 2994.",DISCUSS
1270,bfdaf3ff_64177d53,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/tests/functional/test_conf_max_attach_disk_devices.py,54,"It would also be good to have a negative scenario where the max is 1 and the user tries to boot with two volumes (a root OS image volume and an empty data volume with no boot_index set for example).

Actually, reading this further, that's the scenario I described, it's booting from volume with 2 volumes. The name of the test and comment is a bit misleading.

Maybe just call it test_boot_from_volume_max_exceeded.",EVOLVE
1271,9fdfeff1_72a5c99e,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,2102,requester_id,EVOLVE
1272,dfd5e7cf_6f5c644b,f72f5c52d152852dcecabbf592194addad185c74,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/functional/db/test_virtual_interface.py,213,rewritten :),EVOLVE
1273,3f79a3b5_4e3c94bc,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/compute/api.py,745,"leave this here, just adjust the name appropriately",EVOLVE
1274,9fdfeff1_6ee4730f,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/api/openstack/compute/volumes.py,362,"We could add a show_null_device kwarg that can default to False to preserve old behaviour, but that's a nit.",FUNCTION
1275,5fc1f717_7d3d51b9,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,106,"This case is tested with test_create_with_name_leading_trailing_spaces, fine.",EVOLVE
1276,3fce034c_38dc7e45,a4543eaf2e55bfb3abd981aa9d743f39cd2559ce,0d1310224818c204c52f67deee18efafd1269681,nova/db/api.py,248,hypervisor_hostname,EVOLVE
1277,9fdfeff1_6f39d2f0,c5bb7b5dd4175d5017449de680895120942a36dc,61ce428525101000ff7134b201e61fa8c3999f80,nova/exception.py,1809,"why not just ""node id: %(node_id)s"" to be consistent with the other exception",EVOLVE
1278,3f79a3b5_ec2d33fb,f4253e095574b99f5313de2923f2e42e0cb75fed,c9dca64fa64005e5bea327f06a7a3f4821ab72b1,nova/tests/unit/compute/test_rpcapi.py,599,"Regarding the unit test failure in the next patch (debug log message not called), it seems to imply that different, parallel test set NO_COMPUTES_WARNING to True before these two calls could complete. Not sure how to handle that.",FUNCTION
1279,bfdaf3ff_7d3159a2,94f9892a9fd99dcc3d803694e138c83145f9ac02,357b8b38e88300948bb2e07d1bbaabd1e9d7b60e,nova/notifications/objects/instance.py,238,This is fine although I'm not sure instance.name would ever return None.,FALSE
1280,9fdfeff1_1ae9efb5,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/conductor/tasks/live_migrate.py,213,for?,EVOLVE
1281,3f79a3b5_a9c25e87,67fed7cc2d42e611e278b4a09fb0887ae8314aa4,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,188,"""this online migration code""",EVOLVE
1282,5fc1f717_5e052610,03e8d196183829269521f6ddbd38f3edbacaefa3,556cf103b22ab6bebecc9d824d6f918cda38fe3e,nova/objects/request_spec.py,605,"Maybe make it more generic so we don't have to update it next time we add one?  ""Don't persist these since they are per-request""",EVOLVE
1283,9fdfeff1_7b2dd844,12c38291b85a373905bd754bd210c7d1cac53662,d9bd5b1377acf4468c89422fa471de6c8325d775,nova/compute/api.py,2701,all_tenants,EVOLVE
1284,9fdfeff1_79e4923c,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6222,could do this in the loop; but this is arguably clearer,FUNCTION
1285,9fdfeff1_317adef0,b18e905de6a0ab24f90e6dee207214d126347e10,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,86,"Optionally, you could control this in the regex itself. More below.",FUNCTION
1286,9fdfeff1_8b43533f,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3804,"same, this is redundant",EVOLVE
1287,5fc1f717_4e006f68,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4560,ditto,FUNCTION
1288,9fdfeff1_2069fdbc,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,818,"OK I see you copied this - can we pull this out into a private helper method, something like:

def _get_image_meta_obj(image_meta_dict)
   ....",EVOLVE
1289,bfdaf3ff_74b2d5e8,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/virt/hardware.py,1050,"Just read the code, https://github.com/openstack/nova/blob/master/nova/virt/hardware.py#L982. We doesn't allow the cpu pinned instance to overcommit the memory. But the cpu pinned instance without memory page request is going to this branch also.",DISCUSS
1290,9fdfeff1_78058cc1,344e0fcb74f0e4057af0a72ae4924b4f2e2baed9,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,4948,"This table came with the original change. I assume that it is not valid after the change and should be updated.

As far as I understand the current change it ensures that we always have exactly one log device(type) that should be listed here.",EVOLVE
1291,dfd5e7cf_f93b14ce,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,8335,nit: newline before this?,EVOLVE
1292,1f769fc5_baffe0ff,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,167,"this should be ""context"" not ""cctxt"".",EVOLVE
1293,9fdfeff1_7a9e4008,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/api_sample_tests/test_migrate_server.py,71,Double gross.,FALSE
1294,5fc1f717_bce004fa,43ce926dccae9e60611b1224ab06dcad8f650fce,b7bd97bc8896346e92d271a443d5ada9ab0074be,nova/compute/manager.py,1389,probably want to update this to indicate that you're also considering group members that are migrating to this node.,EVOLVE
1295,bfdaf3ff_9ac9a379,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3013,i dont think you can assume all VIFs here will have ['profile']['pci_slot'].,FUNCTION
1296,9fdfeff1_cbf6b1fa,c5bb7b5dd4175d5017449de680895120942a36dc,61ce428525101000ff7134b201e61fa8c3999f80,nova/pci/request.py,183,"please update the doc string when you with :raises as well.
Also you should clarify when you return None (when VIF don't have pci_slot)",EVOLVE
1297,3f79a3b5_8a64cde7,5c21a00e89539bbb271ccfa05e4a2ba1cddae58e,90b96170d3f269165f649e8b61739cf31ffb78b8,nova/image/glance.py,178,"Just noticed this, if the controller kwarg was specified and this loop runs more than once, this pop() will always get you 'images' after the first time.

Your change fixes this incidentally, so ++",DISCUSS
1298,9fdfeff1_c6c1fb55,570ad369928c296aac59a3e81ceb45a4ff2e19a7,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,nova/tests/unit/scheduler/client/test_report.py,3003,Why don't these tests move to nova.tests.unit.compute.test_compute_utils?,EVOLVE
1299,9fdfeff1_09c5bd3d,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,633,Why don't we make this a public method?,FUNCTION
1300,3f79a3b5_71e9c47f,bf45bd89a104ddf108fcf6676c59195878d432a8,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,420,mention the config here,EVOLVE
1301,ffb9cba7_141260b2,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/conductor/tasks/live_migrate.py,359,NOTE? (Surprised hacking doesn't pull you on this),EVOLVE
1302,9fdfeff1_92c7c845,c4c6e0a8942af963a681f95176f41b8078e41b36,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,180,"@yonglihe: not related to this patch so please ignore this comment.

@mriedem: looks like we should have put this ""links"" in the first common response part like after L151. Apparently we have links in the response of GET /servers/{server_id} as well and we missed it for server show from down cell :( . I guess its not fixable/not that important.

Does it make sense to add this now from 2.71 since we are making a change? - maybe not since 2.71 is addressing something different.",DISCUSS
1303,3f79a3b5_96fdda3d,6aa9ed7fcce9339b922b630b60afa21d3b70d7e4,eafef9556a3f91a2514fa3e029af329c771a7423,nova/conf/libvirt.py,396,"the option seems means we can change it on the fly (through SIGHUP?) but looks like it's only using in timeout options now, will this kind of `choice` option works seems need some info",DISCUSS
1304,9fdfeff1_e8dd5241,bc57a916c4045a387c69f327eb3a9e74be5b1a33,bea316d479750452a42295d9980d9dac5a89934e,nova/tests/unit/conductor/test_conductor.py,1027,"ugh, the surface area of this test is way too big, just like the build_instances() function itself...",FALSE
1305,9fdfeff1_4fd92420,080587b75e14cadadfabc9ac007278b0b62f041a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,103,"See my comment later, but you're assuming that this is _other_ hosts not ""the list of hosts"" (which would include $self)? That doesn't seem very config-mgmt-friendly.

I would think that requiring that we be in the list helps to make sure that if they set partition_key, they also saw/set this option, and makes it more declarative.",FUNCTION
1306,dfd5e7cf_279517e5,9cd315ef07bacc3c70fc6db4efdbbd3048747f19,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,243,nit: Add white space,EVOLVE
1307,9fdfeff1_a53d28c5,735c2181dc450195454cf4dc62a814ff1679abda,9ba910bb539b0172bab899852692a49d30645a14,nova/exception.py,2156,"Once you have a microversion nailed down, you might want to re-word this to be more like MultiattachNotSupportedOldMicroversion so it's more clear that creating a server with a port with resource requests is not supported because the microversion used is not high enough instead of some other ""not supported"" situation, like nova-computes not being upgraded yet, or policy checks failing, something like that.",DISCUSS
1308,9fdfeff1_6953cde3,bc57a916c4045a387c69f327eb3a9e74be5b1a33,bea316d479750452a42295d9980d9dac5a89934e,nova/conductor/manager.py,678,"Note to self, technically this could raise ConsumerAllocationRetrievalFailed which would be uncaught in this method. I don't think we'd change the status of the server so it would be stuck in building status and no fault would be record, I'm not even sure anything would be logged.

Technically claim_resources could also raise AllocationUpdateFailed and we'd be in the same situation.

Anyway, I guess my point is later we should think about pulling this while loop code out into another method so we can add proper error handling (and make this overall build_instances method smaller).",FALSE
1309,9fdfeff1_53cd0bb5,344e0fcb74f0e4057af0a72ae4924b4f2e2baed9,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5025,We only have one case left and maybe should inline the two functions above to make the code much shorter and easier to read and understand.,EVOLVE
1310,9fdfeff1_5a53f717,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/objects/request_spec.py,721,"note to self: in cyborg terms, the Neutron port corresponds to a PF, which may provide multiple accelerators if a) they were requested in the same group, and/or b) they were requested in separate groups with group_policy=none.",FALSE
1311,dfd5e7cf_9d977491,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_affinity.py,133,ditto,FUNCTION
1312,3f79a3b5_2cd3f237,47ec5327c97c5916d9bc2b319bef8a7196fda60f,27b7bad88b531e0869f8e9af9ab951b921c37634,nova/scheduler/client/__init__.py,28,"Is this even used any more? I think probably not... anyway, something to cut in a future patch.",DISCUSS
1313,9fdfeff1_cf0e0b8b,0deb1fa105f3f7110acef95c7b12ece5930f29ca,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/tests/unit/objects/test_instance_mapping.py,177,"could be better to test all versions? like in 
https://review.openstack.org/#/c/614035/15/nova/tests/unit/objects/test_request_spec.py@819",FUNCTION
1314,3f79a3b5_3f2ce092,073c330f52dfa535e6f787f5bb2fc8ec52f1be9a,514eaaef12dad2460fd4c2fffdc05a3db0490711,nova/scheduler/client/report.py,1583,"Using ResourceProviderUpdateFailed as an example, I find it pretty hard to track and confirm that there is a log of some kind when such an error happens. I did find a LOG.error near the two places where it is raised, so there is some audit-ability, but it might be hard to associate that log message with the exception raised here because we're swallowing the first one and this second one is not explicitly caught and logged when _update is called, it just percolates out as part of the top-level exception handling in place to keep the long-running process alive.

Not necessarily here, but at some point, we may wish to pass the helper_exception as exc into ResourceProviderSyncFailed so when that top-level logging happens, we have some association. Or we may wish to do some logging here.

Failures during periodic jobs and the RPC handlers tend to be terribly hard to debug for people out there, so the more noise we can get into the logs the better.

That said, this particular situation isn't so much a failure as one of several expected ways in which things can temporarily go wrong that will be fixed later. However, if things get into a situation where the excepted things keep happening (perhaps because of concurrency issues) we will need lots of log in order to have any visibility.",DISCUSS
1315,9fdfeff1_f8f4c589,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/tests/unit/virt/libvirt/test_driver.py,17931,This is an object so use dot notation: instance_ref.uuid,FUNCTION
1316,9fdfeff1_31afd57d,695dfc59f2adea9995c138a9694e6f4368fbf185,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/objects/request_spec.py,809,It's hard to follow what is actually changed by this method.,FALSE
1317,9fdfeff1_7a3ac0e7,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/unit/api/openstack/compute/test_migrate_server.py,628,"Assert the validation error is for what we expect, e.g.:

ex = self.assertRaises(self.validation_error, ...)
self.assertIn('force', six.text_type(ex))",FUNCTION
1318,bfdaf3ff_84a141ac,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/compute/manager.py,1608,"Heh, the comment doesn't seem to align with the code here. This was written in 2013 though so I'm not sure what the thought process was at the time (ndipanov wouldn't be around to answer).",EVOLVE
1319,5fc1f717_dc41340c,3f18b702afe20cc7e3c3a1ccbdb2dbcc286bdbbb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1265,You don't need this in the log message because you're using LOG.exception so it will get traced anyway.,EVOLVE
1320,5fc1f717_360c503a,89a16f8c6a3c2bbf76fa6284ce51ff3a90ceb5e0,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/conductor/manager.py,670,"This is not handled either so this is a latent bug and I think you could just report a low priority bug in launchpad stating if we fail in this while loop during rescheduling the error is not handled and the instance is left in BUILDING/scheduling state or whatever rather than ERROR/None state. Then we have some time to work on fixing this without the pressure of RC1 for Stein and all that.

I would also like to refactor this while loop code out into a separate method for sanity because this build_instances method is already way to large to test and maintain in isolation very easily.",FUNCTION
1321,9fdfeff1_1fc4d80d,d24043d61610ff3bde6913fa907e63e920cbb9b4,c43c1d3fb9da5dd0a13e1f15623a696212f095ff,nova/tests/unit/api/openstack/compute/test_serversV21.py,6079,"We should really make sure this is the 400 we expect, so do something like this:

ex = self.assertRaises(...)
self.assertIn('Invalid PCI alias definition', six.text_type(ex))",FUNCTION
1322,9fdfeff1_a6c11231,ccec9ba82de7c9525981a34bb126e9ca98042d04,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/objects/instance_mapping.py,105,"Alternatively we could have just called:

self.obj_set_defaults()

Which should set all fields to the default unless they are already set.",FUNCTION
1323,9fdfeff1_e9795930,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3575,nit: alignment is gross here,EVOLVE
1324,9fdfeff1_77c2f236,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2161,"as discussed on irc we have no way to determin the agent name today so for stien using bandwith based schudling means
you cannot share teh pf between ovs and sriov agents.

this is resonably common use the FDB agent extention to both provide dhcp/routing to the sriov devices when using dvr without having to hit the top of rack switch.

for stien we will simply need to declare that this usecase is out of scope and state that only one agent may manage bandwith fo a singel interface. we shoudl put that in the docs somewere but that can be in a follow up patch.",EVOLVE
1325,3f79a3b5_97f9941c,97262477d104bb4866d490a062ea710a55e2d8a4,0a993d95f8584b10cfee56f42cc3f7e37a57f1ca,nova/tests/functional/api_sample_tests/api_sample_base.py,129,"This line should be added in the parent patch ( https://review.openstack.org/#/c/621398/ ).
The functional tests of the parent patch fails.",DISCUSS
1326,9fdfeff1_4efff900,abe5a4b64dcf678903d3db555caa2fb7f1fa01ee,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/api_version_request.py,169,"responses, otherwise could be confused.",EVOLVE
1327,5fc1f717_c890d7f0,b096d9303acfea81ca56394cab681d2b2eed2d91,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,772,Shouldn't this be a continue like L728?,DISCUSS
1328,9fdfeff1_b3c28e52,bc57a916c4045a387c69f327eb3a9e74be5b1a33,bea316d479750452a42295d9980d9dac5a89934e,nova/conductor/manager.py,720,requested_resources,EVOLVE
1329,9fdfeff1_a5c65f15,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/tests/unit/pci/test_request.py,274,nit: we should really be using a Flavor object for these tests because that's what the API passes to get_pci_requests_from_flavor but I realize it's a latent issue.,FUNCTION
1330,9fdfeff1_71feab06,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,893,"This is a nice test. Arguably we don't really need it given the redundancy with all of the other specific multiplier tests, it's good to have it here anyway.",DISCUSS
1331,5fc1f717_16c97057,afe767e332c0e07ef4a8ba4feca0cefe66c04f81,886850f50f62e97a5661d68c1689fdc932fb7b61,nova/virt/libvirt/driver.py,443,"Note that we always return a non-None disk_cachemode, so we never use the qemu default.",EVOLVE
1332,3f79a3b5_c23061ed,a0fd2af6a0e3022cd94afca555223980b3d70b30,e0d641b0636ad1910219ee12786894b72fc0092b,nova/scheduler/utils.py,473,"Since this was missed in tests before, we should probably have a test case where we hit this code with spec_obj.requested_resources set to None.",FUNCTION
1333,3f79a3b5_8704e21b,4224afc5850e7969ff3df3e1218aebfffc8887f3,ed4fe3ead62c09ec7de7b6a11072295a99997b4f,nova/compute/api.py,4664,This 'if' can be removed,FUNCTION
1334,5fc1f717_6e59b958,afbe4abba881c75fef2d4ef864334d5d91181d8c,00046e47db5d51ac4eb7f9d6e5d1e618663e806c,nova/compute/api.py,2447,might be good to put a LOG.info() in here...,FALSE
1335,9fdfeff1_c6db9279,0b92325fe14eda062c78de2c3423ca4834861152,b164aaac1f036455205d2457abc3ae75769bf42f,nova/api/openstack/compute/shelve.py,92,"I was wondering if we should be using a 409 for these errors but looking at MultiattachNotSupportedOldMicroversion we handle those as a 400 error. One could maybe argue that you could perform the operation if you detach the ports and thus get around a 409 conflict case, but maybe that's just slitting hairs.",DISCUSS
1336,9fdfeff1_3cd8261c,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,99,"I still wish we could avoid landing these with microversions called out, but.. not that big of a deal I guess.",EVOLVE
1337,9fdfeff1_9f477f1e,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_linux_net.py,1176,ditto,DISCUSS
1338,3f79a3b5_c76cc59f,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,208,"We should probably have a neutron docs change that mentions this as well and depends on the nova change, but I'm not sure what the best doc would be for that information, but here are some possible places:

https://docs.openstack.org/neutron/rocky/admin/config-ml2.html?highlight=metadata#metadata-agent

https://docs.openstack.org/neutron/rocky/admin/intro-os-networking.html?highlight=metadata#metadata

https://docs.openstack.org/neutron/rocky/configuration/metadata-agent.html?highlight=metadata#DEFAULT.nova_metadata_host

Maybe ask slaweq, hongbin or mlavalle which would be best.",EVOLVE
1339,ffb9cba7_f5223401,74cefe4266a613d4c2afbb0c791e16eb7789aef4,a991980863f056323c1ee9fd6a46dbc4cb899eca,nova/api/openstack/compute/availability_zone.py,95,/me turns blind eye,FALSE
1340,9fdfeff1_dbe8727d,3ef55e43d56ce66e003c934f4a5c83e787aca7b3,f58cdcd58dc555b5b8635907987510f4970eae58,nova/objects/request_spec.py,549,"This isn't right, what you want to do is add it to L527 using an ""in"" statement. IOW, don't modify ignore_hosts during the lifetime of this RequestSpec object in memory, but don't persist it either.",FUNCTION
1341,9fdfeff1_e3916348,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,360,nit: Is this necessary?,FUNCTION
1342,5fc1f717_53ab61d5,baba88b1d73dfee45f1ca1ca8e261664237c2da6,18dc4d3dc526a3313fb6e1eee1c8913b22dffb93,nova/compute/manager.py,89,"the pep8 issue is from this import and we need to fix it
we should rename it to something like pci_req_mod",EVOLVE
1343,bfdaf3ff_1d1ca610,397f7ea9f686eaf8d0ca8f267f26e29ded710bb3,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,734,Add a white space.,EVOLVE
1344,9fdfeff1_8d9b1915,fc4010176a5e445a1e5d333bbbd3e273e2448e79,859a0ac11842101c902a98165277175d984c3352,nova/objects/instance_pci_requests.py,39,"another name for this might be ""requested_by"", which has the advantage that it's harder to mistake with ""request_id"" :)

This would follow a similar naming practice to fields like the instance's locked_by field:

https://github.com/openstack/nova/blob/a8c065dea946599a1b07d003cd21409c4cd58df0/nova/objects/instance.py#L166",EVOLVE
1345,9fdfeff1_54681e86,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/tests/unit/virt/ironic/test_driver.py,1129,Note to self: this verifies that we've fetched fresh data from ironic.,FALSE
1346,bfdaf3ff_a3b9e9e9,661dd591c94a9203c1a63e17789b83539a364527,84d94171d93a89af9fc71f6a326a988842c64d5e,nova/compute/manager.py,6648,nit: Still got the unrelated change here,EVOLVE
1347,9fdfeff1_26c85e20,2db2839be9864f054a430b2013fdc3ba09a4eb69,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,nova/conductor/manager.py,1262,"Gross, we don't already have the allocations in the Selection object?

 jsonutils.loads(host.allocation_request)

Or is that not guaranteed to be there?",DISCUSS
1348,5fc1f717_fc5f50e2,3f18b702afe20cc7e3c3a1ccbdb2dbcc286bdbbb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1266,OK I guess you're not calling _disconnect_volume since that will try to detach the encryptor which could fail as no encryptor was attached.,FALSE
1349,5fc1f717_6289296d,b8e24f86668107342386fbb04de0daa05e11cf6d,a845b3bf7b15c3966452e99493edf02972ad438f,nova/scheduler/utils.py,272,OK so even if a host/node isn't specified this will default to None so we don't have to worry about an AttributeError here.,DISCUSS
1350,ffd0ebdf_280af425,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,207,same,EVOLVE
1351,3fce034c_44efbdaf,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/virt/driver.py,160,Wondering if this should be a ComputeDriver capability,DISCUSS
1352,9fdfeff1_5aa777be,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/compute/manager.py,6770,I have no idea,EVOLVE
1353,5fc1f717_73a318b3,74ef3a67096ca8203cd344e4ee32c71ab340ab1b,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,695,"I was going to say why don't we just do something like:

with excutils.save_and_reraise_error():
   self._cleanup_when_reschedule_fails(...)

But there isn't really a point in re-raising unless there was a decorator on this method that did more cleanup, but there isn't, and we return above as well after cleaning up, so this is fine.",FUNCTION
1354,3f79a3b5_922e89f7,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/scheduler/client/report.py,1591,ah os this is why you added remove_tree,DISCUSS
1355,5fc1f717_7ab96577,88c20a168ee89293751bd22ad621d1d8eb305693,75d4ba6752b0bebe6643d0efcdfcebdca2828a7c,nova/tests/functional/test_json_filter.py,74,"note-for-self: this is the name of the server and the request looks like 

 {'os:scheduler_hints': {'query': '[""="", ""$hypervisor_hostname"", ""host2""]'}, 'server': {'name': 'test_filter_on_hypervisor_hostname', 'flavorRef': u'http://fake.server/2', 'imageRef': u'cedef40a-ed67-4d10-800e-17455edce175'}}",FALSE
1356,9fdfeff1_7ebd8166,026b135d879fb0f67bb1de191fa57681205b0ac7,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/storage/rbd_utils.py,343,"Okay, you're now explicitly specifying the target disk format.  And are thus avoiding the mine field of ""insecure image format probing"".

Matt, can you double-check if I'm not complete bonkers here, please...",DISCUSS
1357,1f769fc5_660d7336,63d77bf63fd474d10fd7cac5f725784737bafa1a,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/workarounds.py,221,"This one too?

https://review.openstack.org/#/c/618478/17/nova/conf/workarounds.py@221",DISCUSS
1358,9fdfeff1_6ddf2c66,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1715,unnecessary with get(),EVOLVE
1359,9fdfeff1_4af1ae6a,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,105,Would have been nice to re-use the assertion methods from ProviderUsageBaseTestCase here but that's a minor detail.,EVOLVE
1360,3f79a3b5_13c6839c,9b3aa4d2d04c9d17effb51ee4a9ed33889bbdb1f,33aa1ec50a6733c30faeabd2f1b345b447498a7e,nova/conductor/tasks/live_migrate.py,262,"so i think you have missed that fact that before this change
migrate_data.vifs is only ever set here
but you are now also setting it at 
https://review.openstack.org/#/c/620115/1/nova/compute/manager.py@6002

we need to think about the orderign here as we should not activate any of the new sriov code until after we have confirmed that both sides support multiple port binding
and neutron does and we have created a new port binding on the destination node.",EVOLVE
1361,5fc1f717_247d31b1,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,249,"And they're probably going to be set by the new api code if we're running this anyway.

Why did you not just filter these out of the query? That would make us process less stuff in python, use less memory, and do more useful work each batch.

...later...

Okay, in your test you've got one that doesn't have a cell yet, so that is included in found but not done. That's probably worth it so we're not just always returning N,N in cases where things really don't get migrated.",FUNCTION
1362,3f79a3b5_b7f55ecc,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/tests/unit/pci/test_manager.py,317,"nit: I think the primary issue in the various bugs is that the PCI device is reported by the hypervisor, but the operator changed the whitelist, maybe accidentally, which wiped out what the PCI manager was tracking and cleared its ""inventory"".",EVOLVE
1363,9fdfeff1_c9228ba3,da972e3432ef0f7a242510a52484bc5660d9806c,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7612,"I was thinking, I wonder if we could put this part into a helper method, to avoid making all the room for the statements even smaller with yet another indentation.",EVOLVE
1364,9fdfeff1_728b161e,a152f0922e97a5f6e6dde36fc0b5d18bdfb04e1f,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,226,"This could just be a list - doesn't really matter I guess, but we shouldn't have duplicate instance UUIDs ever.",FUNCTION
1365,9fdfeff1_2d00ed01,a59ec1c06ef51c2e0038354b585940643dc9d125,0b372ae75e589550569713f9b1cc88b4a7902325,nova/objects/instance_mapping.py,225,This will return deleted instances by default. Do you care about those?,FUNCTION
1366,3f79a3b5_63afac7f,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,1197,"According to the spec:

https://specs.openstack.org/openstack/nova-specs/specs/stein/approved/handling-down-cell_new.html#proposed-change

If the tenant has instances in a down cell we should fail the server create unless policy passes, correct? I don't see the failure / error logic in this change.

I also wonder if we are only going to enforce that with the microversion. It seems wrong to make people opt into not cheating their quota limits. Probably something we need to discuss, but I'd think once we have the policy rule and support for handling down cells during the quota check, we should change the behavior, regardless of microversion, to fail server create/resize if the tenant has instances in a down cell and they don't pass the policy check. Yes it would be an upgrade impacting behavior change, but it's also a safety measure for multi-cell deployments.

Also, I think I now realize what you were trying to ask me in IRC about the policy / microversion question; sorry I didn't fully grasp what you were asking. I think we can probably ignore the microversion for the down-cell quota check since quota checks can fail at any time and this is really fixing a bug / adding a safety measure for multi-cell operations. I will ask the question during the cells v2 session at the summit:

https://etherpad.openstack.org/p/BER-cells-v2-updates

But I think we can ignore microversion for this, which will also make this change a lot simpler since you won't have to pass that flag down the stack.",DISCUSS
1367,9fdfeff1_56e40f0d,5c14429cb34bc6af77b0611c959f9c641e4f616a,208c382db4d995bd647c635394c73c86c6612b29,nova/api/openstack/compute/attach_interfaces.py,53,Note to self: this DB query is for interface show.,FALSE
1368,ffb9cba7_5bf032ca,13278be9f265e237fc68ee60acfacaa1df68522e,b7a018f1265d9e0354e26822d32cbdc789819c35,nova/virt/ironic/client_wrapper.py,131,So what happens if we pass endpoint=ironic_url to ironicclient? Will it blow up? Or do it's own version discovery? I'm mostly worried about a change in behavior here and then backporting this change.,DISCUSS
1369,5fc1f717_3d5ca917,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,110,"This case is tested with test_create_check_flavor_id_length, fine.",EVOLVE
1370,9fdfeff1_16ea07d7,5c14429cb34bc6af77b0611c959f9c641e4f616a,208c382db4d995bd647c635394c73c86c6612b29,nova/api/openstack/compute/attach_interfaces.py,89,... and this is for interface list.,FALSE
1371,5fc1f717_d50c7495,3b53e1a1f177d1eedf329dd525a613b1f1ae22d1,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,42,"My first reaction here was to object to moving this from a method to module scope. It kind of obscures the actual change here, especially since the bug is about nova-compute, but we don't change the import ordering visibly for cmd/* things.

The actual thing that is important is that this code runs super early, which could still happen if we just moved the monkey_patch utility here, decoupling it from utils.py which imports a bunch of other stuff before we get a chance to run the helper.

We could replicate that here, but we'd either (a) just define and then call it, or (b) make all the users of this have two #noqa lines, as they import something out of order, and then run a statement before the rest of their imports.

So, what is here is probably better as it's more obvious that this definitely has to run at import time and it's harder to make it not do that.",EVOLVE
1372,5fc1f717_bc5b5652,18ff2ab25b282e757e807174afcd9c122cc06aeb,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/conf/libvirt.py,687,"well, you said in the commit msg it's no longer an issue thanks to the guest OSes, right?
I mean, if we leave this comment and we say it's the default, maybe some operators would be afraid, nope ?",DISCUSS
1373,9fdfeff1_2099fdc2,3fbf336a38556db1fce2e9744a3c9712bf463614,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,37,Why is this added back in?,DISCUSS
1374,9fdfeff1_6ef793d6,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,671,Code comments here would be nice.,EVOLVE
1375,9fdfeff1_3fbf73fc,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/functional/api_sample_tests/api_sample_base.py,131,It should be modified in the parent patch https://review.openstack.org/#/c/624591/ .,DISCUSS
1376,9fdfeff1_e35e31e8,05df13e16e175fc54d06036f071901d533c90cdd,179c10fd36a42dda3b54fb9266d6747cbbaf6ec9,nova/compute/manager.py,4894,"This seems identical to [1] with the exception of `action`, which could be a parameter. Can we DRY?

[1] https://review.openstack.org/#/c/634831/2/nova/compute/manager.py",DISCUSS
1377,1f769fc5_9a5a2428,131c4649f7057dc3c47d354659319b6527d05167,35505c09dee5a3490411a37f9790d96e3a3acbbf,nova/objects/virtual_interface.py,168,"here and throughout, use port['id'] if the field in the dict is expected to exist. The way that get() is used here and throughout will essentially hide data corruption errors.",FUNCTION
1378,9fdfeff1_dcd97e56,08f71026cb90740ae166ce131fba20cb0349f1d4,2f21b1ba50e92311bc38426363ff09c495c81a05,nova/tests/unit/virt/libvirt/fakelibvirt.py,1563,oops :),FALSE
1379,dfd5e7cf_e1a4c9bb,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,8317,"nit:

  if pci_reqs:

is fine",FUNCTION
1380,5fc1f717_58d5beb6,7931f85fe66d4e024d7dd5396dcf38378af85470,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,135,nit: empty constructor not really required.,EVOLVE
1381,9fdfeff1_9c5cad7d,24d3c138b5b682c5f966bd5003b823d8eec6bc18,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/views/servers.py,176,Wah wah.,EVOLVE
1382,bfdaf3ff_2cce082e,7df93f1e87c4c821e274dbdbfee6cccf9447963b,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/api_version_request.py,167,not correct,EVOLVE
1383,bfdaf3ff_3f5f7e42,b19c2b7ccacfe3c464d1512049b0d2bc64b81350,5f9c8b45ffc5c2b9da5e3da6f2b4214b391d9900,nova/compute/api.py,630,I think this config option might only be used on the compute node currently.  If we want to start using it on a controller node we might need to update the release notes.,EVOLVE
1384,3f79a3b5_1a911946,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,564,"This is the wrong type of object, the DB API won't return a versioned object, it will return a dict-like structure, which is why I was wondering how your code was working with attribute access on the object. I think that would blow up in real code.",FUNCTION
1385,5fc1f717_7dd248d3,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/test_servers.py,4026,why is this not done at the top in the imports section?,DISCUSS
1386,9fdfeff1_72602402,c4c6e0a8942af963a681f95176f41b8078e41b36,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,461,nit: alignment,EVOLVE
1387,5fc1f717_b997ed90,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,284,I would add a recommendation to run nova-manage db archive_deleted_rows here so the person reading this doesn't have to guess what they need to do to clean these up.,EVOLVE
1388,9fdfeff1_ebfc5f73,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/tests/unit/objects/test_request_spec.py,1000,"But wait, if this was the only request group, how did the VCPU resource get allocated?",DISCUSS
1389,5fc1f717_899d165b,d24275951d3ad0e0ae00621971278aeedf2bfd09,2a12e420c2934e49da5cb3e586407d3f6e1d6300,nova/tests/unit/compute/test_compute_api.py,5802,This would be more clear if it was by the new assert below.,EVOLVE
1390,3f79a3b5_f60e2a31,bd245c2aab9b14951c4aeb7fbdcbb2e86e341dc1,a0eacbf7fff60282007ddca705ef7331e8a4a6f8,nova/tests/unit/virt/libvirt/test_migration.py,750,pep8 is going to complain this this needs to be on a dropped new line below,EVOLVE
1391,9fdfeff1_0a059c14,c0fd216780cfa9c17da385af63fa743d40434fa0,fe88d9e2c33af94139dbae896b95dcc45c412798,nova/virt/libvirt/driver.py,4961,"As an aside, and assuming you'd doing further untangling of this nest, bringing this down a level (in a future patch) would make this easier to read:

  if virt_type == 'parallels':
      pass
  elif virt_type not in (""qemu"", ""kvm""):
      self._create_consoles_non_qemu_kvm(...)
  else:
      if self._is_s390x_guest(image_meta):
          self._create_consoles_s390x(guest_cfg, instance,
                                      flavor, image_meta)
      else:
          self._create_consoles_qemu_kvm(guest_cfg, instance,
                                         flavor, image_meta)

But maybe that's just me",FUNCTION
1392,9fdfeff1_c102920c,451d41a9deaf4bdba20509afc15a73df02e400f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/exception.py,2318,"probably would be good to include a mention of Ironic and the nova-compute service in this exception message. I can imagine a reader of the Nova codebase looking in here and seeing a generic InvalidPeerList exception and thinking it might be raised by the nova-conductor or other distributed components when in fact it's specific to the Ironic nova-compute service hash ring.

Better yet would be to call the exception InvalidIronicComputeServicePeerList or similar, even though it's not exactly pithy.",EVOLVE
1393,5fc1f717_09432515,2685d554125133ee95aa4bdbe0e35a56ce4ae7a5,754847ed277e2b00f2002e227cf1d026149d1d43,nova/db/sqlalchemy/api.py,1500,One blank line should be deleted.,EVOLVE
1394,3f79a3b5_9347f31b,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,1172,"nit: rather than create a run-on sentence, just make the down-cell policy thing a new sentence, i.e. ""As a part of the handling-down-cell blueprint, ..."".",EVOLVE
1395,9fdfeff1_49015204,35cbe9290cef244142522f6bcc253888460d09ea,ecea762eb9f6a15f1006ad574c5ab6c8a9cb24c5,nova/api/openstack/api_version_request.py,178,"This is too generic, make it clear it's only for server create and move operations for servers with these types of ports are not yet supported.",EVOLVE
1396,5fc1f717_b46cd436,99732383422d5d262a6df13f22f651fd9f0078ad,3b4d1303d03e6df57ec28d4d72756bebd62d7115,nova/objects/instance_mapping.py,287,""".

so close",EVOLVE
1397,9fdfeff1_12c79d14,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,3233,"Do we want a similar TODO about handling the port binding profile allocation here if the host changes during a move operation (cold migrate/resize, unshelve or evacuate)?",EVOLVE
1398,3f79a3b5_c322fd0e,36c992f72d988ff20e3e286c1065aa76db5aec03,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,212,"This is the old value, not what is returned from compute_node_update above, so it wouldn't make a difference.",FUNCTION
1399,9fdfeff1_328d582a,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,772,Ã¢Å“â€,DISCUSS
1400,9fdfeff1_6d4e876f,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1385,"Given the size of this method overall, it would be good to have a comment here about what this is doing any why it's doing it here.",EVOLVE
1401,5fc1f717_9aba3edc,ced9c58503ed539787deee4d540b201445d03419,99ad674c26fdacfff72d84624ee060cf0e33304b,nova/network/linux_net.py,1200,What in the..,FALSE
1402,bfdaf3ff_da408b38,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/tests/unit/network/test_neutronv2.py,4294,remove space,EVOLVE
1403,5fc1f717_511a14c6,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,8567,How about just _claim_pci_devices_for_instance()?,EVOLVE
1404,dfd5e7cf_61e21904,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,6020,"I'm guessing this isn't passing tests, unless the function is wrong (instnace vs. instance).

Later: yup, typo in the function name :)",FUNCTION
1405,3f79a3b5_06859c53,4eb512aa15f9f80322b2889dfdafaab1b08da7c0,aceef76e03374501811e58d6c2f108c4a5ffddf1,nova/tests/functional/regressions/test_bug_1550919.py,73,Do we really need the bfv with the ephemeral and swap disk scenarios? The flavors themselves will generate ephemeral/swap bdms right for an image-backed instance. I'm not sure it really matters though.,DISCUSS
1406,9fdfeff1_78fcf13d,b86ade88a17f3e10fa12adbbc4242485f77a295f,e162bcb22ceb7c87924b992ad71a567f1f4c314b,nova/scheduler/client/report.py,181,"But we would ideally *like* to take the max, because that would be a fix for the cited bug. So I don't think we should remove this wording entirely without mentioning that (including the bug number in the comment).",FALSE
1407,ffb9cba7_8c66fcc0,674c004231a3f7696962d7a7bfa69b4b31af4de8,ce5ef763b58cad09440e0da67733ce578068752a,nova/conf/ironic.py,102,among,EVOLVE
1408,9fdfeff1_eafd8fb1,38e5e33aaf9f8d241b04763b5d186cbbff2a540a,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/conf/libvirt.py,730,"Any of above option will affect the existing instance, right?

We should note this in the help message.",EVOLVE
1409,9fdfeff1_0aa88689,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6248,"You're re-using this same reason throughout here, which is hard to debug - would be nice if you actually used a unique error message per exceptional case. But that could be a follow up.",EVOLVE
1410,dfd5e7cf_1aa5b304,51d1e00e359d3307231f547d3600dd8f09feeb63,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/virt/hyperv/imagecache.py,174,"This change makes here same as the libvirt one like https://github.com/openstack/nova/blob/master/nova/virt/libvirt/imagecache.py#L379

so LGTM",FALSE
1411,9fdfeff1_1897493d,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,735,"I find this to be more confusing than useful, so I think we should probably just remove it.",EVOLVE
1412,9fdfeff1_0f32d85e,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,467,Is this a status or a server id?,DISCUSS
1413,bfdaf3ff_62d9ed81,b19c2b7ccacfe3c464d1512049b0d2bc64b81350,5f9c8b45ffc5c2b9da5e3da6f2b4214b391d9900,nova/compute/api.py,3318,"I'm not a huge fan of validating numa topology separate from everything else.

I wonder if it'd be nicer if we added a ""validate_numa"" argument to _checks_for_create_and_rebuild() which would default to ""True"".  Then in _create_instance() we could call _checks_for_create_and_rebuild(validate_numa=False) since it's already been done.",FUNCTION
1414,9fdfeff1_ab85b2ae,31f048c689c6c750b0199a412922c87149e17bbf,8c1c0e2b2bd028d894ed60b24f1a7a2ba54d0215,nova/tests/fixtures.py,2051,straight,EVOLVE
1415,9fdfeff1_36dff90d,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,397,intended,EVOLVE
1416,9fdfeff1_f89da557,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,740,another,EVOLVE
1417,9fdfeff1_c58e032d,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/objects/instance_pci_requests.py,94,nit: this is redundant,EVOLVE
1418,9fdfeff1_4e35b9a7,55f455262144ab319a9ff480850aeece88b1dedb,20a46ece5701c9798a5e0df12c944237cb1ece3e,nova/scheduler/client/report.py,1777,"i think this might still raise a key error of the post on line 1786 below
may fail. should we add another if on line 1767 and bail out early if neitehr the source or target consumer have allocations
e.g.
if not ((source_alloc and source_alloc['allocations']) or ( target_alloc and target_alloc['allocations'])):
    return False",FALSE
1419,9fdfeff1_40970592,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/scheduler/client/report.py,832,"Note for the future me: Until now this refresh did not depend on the _associations_stale() check at L1072 (base version), and now it does not depend on it either as _ensure_resource_provider() calls _refresh_associations() with force=True",FALSE
1420,5fc1f717_4bbdcab5,ddc0aba5a54377178a5b2748afe2718aabbc267e,3b4d1303d03e6df57ec28d4d72756bebd62d7115,nova/objects/instance_mapping.py,274,"gah, this slipped past me. doink, thanks Dan.",FALSE
1421,bfdaf3ff_5dd1cefa,397f7ea9f686eaf8d0ca8f267f26e29ded710bb3,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/virt/libvirt/driver.py,4892,ditto,FUNCTION
1422,9fdfeff1_81744f69,701d653b5ac9a85fe691c77d6d0611f690d00d3a,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,168,nit: hypervisor_type,EVOLVE
1423,5fc1f717_c73259a7,2b15904afdc4bc7b17c34bc774386dec4eb3aa32,f130b295bb0e72ab9613018399ce423effeda37e,nova/virt/libvirt/volume/quobyte.py,71,not needed (you only need to use the 'global' keyword if you want to set the variable),FUNCTION
1424,5fc1f717_024e256e,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,520,nit: it would be good to document this case in the docstring for this method.,EVOLVE
1425,9fdfeff1_942a0b2a,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/conductor/tasks/live_migrate.py,226,this is not needed if you move the call later. see comments below,EVOLVE
1426,9fdfeff1_f206f01c,d02427f51823019974f2a5316e0cdd567be12711,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/driver.py,165,"The default to True looks a bit weird in the drivers that don't use this variable, i.e. it's called ""use_cache"" but most drivers aren't using it. So maybe in this description it would be good to say, ""This only applies to drivers which cache instance state information. For drivers that do not use a cache, this parameter can be ignored.""",EVOLVE
1427,9fdfeff1_cfa4d0a8,34deb5a903ed1ad924b9cd7aecb6bb0a79bf07a3,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/objects/request_spec.py,784,one,EVOLVE
1428,bfdaf3ff_d8242f10,6e49978b91e53d40dca766134340233163da374a,40a9d195de13e47eab37a07ccb9eb9518970875e,nova/tests/unit/scheduler/client/test_report.py,2862,"nice cleanup, thank you.",DISCUSS
1429,5fc1f717_afd61ac2,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,670,I think we can use ComputeNodeList.get_by_hypervisor here.,FUNCTION
1430,9fdfeff1_ee2ce34b,97ca6f8106f91af65980f47f1bcff7a6f8d7d01a,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/driver.py,701,and here,EVOLVE
1431,3fce034c_41b5b930,8f1773a7af273e2739843a804fb4fe718c0a242d,9fd4082d7c076146ec314b86e0e4772d0a021712,nova/tests/unit/objects/test_request_spec.py,581,"Seems like these shouldn't be here, they're unused.",DISCUSS
1432,9fdfeff1_8d405037,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,6052,"Shouldn't we only call this if port_allocation is True(ish)? Looks like the deep down the method will handle that case:

https://review.openstack.org/#/c/622421/27/nova/scheduler/client/report.py@1705

But that seems like a brittle interface to me.",FUNCTION
1433,9fdfeff1_72a48d07,448139b5a7876ffc86b625f5897fccafe3353786,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7529,OK so this is where a non-ironic driver before this change would get it's vm_power_state and pass that through...,FALSE
1434,9fdfeff1_524525b3,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/api/openstack/compute/views/servers.py,174,"Why wouldn't user_id be set? I guess because we could have pulled an old RequestSpec which doesn't have user_id set? Let's add a comment for that. And why wouldn't we return ""UNKNOWN"" in that case rather than the empty string? Should also have a test wrinkle for that case.",DISCUSS
1435,ffd0ebdf_cd1b3a71,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1043,This now enforces a certain naming convention which we might be lucky and have that consistently for the in-tree filters but there could be out of tree weighers that don't match this. It might be more flexible to just have the weigher pass in the multiplier name rather than us try to guess.,FUNCTION
1436,9fdfeff1_4a54f254,d883a1b3d174b9f8af373d254fe880c322df2ad2,883da6cb8129b96138339c24890b8871eb122111,nova/compute/manager.py,4420,No extra conditionals here. Looks good.,DISCUSS
1437,9fdfeff1_66c2b836,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/compute/api.py,2200,And this should always be set because it will be null in the database for old instances and _from_db_object will set it.,FUNCTION
1438,ffb9cba7_fee1d4ff,186b37f8237010b5abd4ab4ad208a9ea400f8819,570b07e53c72b1fbb80315bd5f4cf42e4e69f64b,nova/api/openstack/compute/availability_zone.py,66,"I guess regarding a unit test would could simply assert that we're passing enabled_services to get_availability_zones.

If we had a more robust test, we could further assert that service_get_all is only called once.",FUNCTION
1439,9fdfeff1_c96302dd,35cbe9290cef244142522f6bcc253888460d09ea,ecea762eb9f6a15f1006ad574c5ab6c8a9cb24c5,nova/tests/functional/test_servers.py,5978,71?,EVOLVE
1440,9fdfeff1_fa6ad417,9524eeff0cf84e2e9f068e6bf0c054a665977ac6,735c2181dc450195454cf4dc62a814ff1679abda,nova/network/neutronv2/api.py,480,"Don't put a specific log message in a generic method - move this to before calling the generic method.

Also, shouldn't the substitution variables be passed to the LOG.info method?

LOG.info(msg, port_id)",EVOLVE
1441,9fdfeff1_8fc61f49,0db948f8bca4579d9e187d83250e6c5ddfbacfe7,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/compute/manager.py,5450,A comment here would be good otherwise it's hard to know that this code is tightly coupled to the bdm.attach code that cleans up the attachment on failure (but only in some cases).,EVOLVE
1442,9fdfeff1_8590e9ee,da972e3432ef0f7a242510a52484bc5660d9806c,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/ironic/driver.py,886,Need to add use_cache param to docstring.,EVOLVE
1443,bfdaf3ff_b3d11efe,890e2d320e8e8e7b501af8e21cc6b751fb204d04,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/tests/unit/console/test_websocketproxy.py,651,"This test fails if this line is removed, but the failure is an exception, not an explicit assertion failure where some expectation has not been met. Not sure if that really matters, but I mention it because it was non-obvious from just reading this test that the thing being changed was actually being tested, so I brought down the code and messed with the test.

If there's an easy way to assert things, or to add a negative test, that might make things more clear.

However that would be really pushing the boat out, so I don't think it is truly necessary.",FALSE
1444,dfd5e7cf_01356846,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/virt/hardware.py,1025,technically if they requested explcit small pages or 4k pages we should also be checking total memory on the cell not just free. so you need to also change this above.,FUNCTION
1445,3f79a3b5_8a228d01,5c21a00e89539bbb271ccfa05e4a2ba1cddae58e,90b96170d3f269165f649e8b61739cf31ffb78b8,nova/tests/unit/image/test_glance.py,1451,Seems unnecessary? Ditto for above and below,FALSE
1446,3f79a3b5_24a433a4,39689ebbb83449fa853635314923f8de5d33de6c,5adfb64c6c6a212db93988da11469f77ed3ac87c,nova/tests/functional/fixtures.py,0,"I think nova.tests.functional.fixtures conflicts with the standard fixture package. I guess it is yet another absolute import issue.

Failed to import test module: nova.tests.functional.test_middleware
Traceback (most recent call last):
  File ""/mnt/ssd/ebalgib/nova/functional/.tox/functional/local/lib/python2.7/site-packages/unittest2/loader.py"", line 456, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/mnt/ssd/ebalgib/nova/functional/.tox/functional/local/lib/python2.7/site-packages/unittest2/loader.py"", line 395, in _get_module_from_name
    __import__(name)
  File ""nova/tests/functional/test_middleware.py"", line 18, in <module>
    from nova.tests.functional.api_sample_tests import api_sample_base
  File ""nova/tests/functional/api_sample_tests/api_sample_base.py"", line 22, in <module>
    from nova.tests.functional import api_paste_fixture
  File ""nova/tests/functional/api_paste_fixture.py"", line 26, in <module>
    class ApiPasteV21Fixture(fixtures.Fixture):
AttributeError: 'module' object has no attribute 'Fixture'",FUNCTION
1447,9fdfeff1_e5178745,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/network/neutronv2/api.py,1698,"nit: this is probably copied from elsewhere, but here I'd say something like ""Unable to determine port %s resource allocation information as the port no longer exists.""",EVOLVE
1448,9fdfeff1_172bdc82,3534471c578eda6236e79f43153788c4725a5634,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,178,should we care about cell0?,DISCUSS
1449,3fce034c_f0e0dfce,4713b49c8646501957a49b8a7f2e13521a2e0544,a40c7f3e8d06f0bc8918a25b60f73ec2c18add05,nova/compute/api.py,3640,"I think the bug reported by Wendy applies to resizing to any smaller flavor, not just a zero-disk flavor.",EVOLVE
1450,3f79a3b5_0b475f54,5cdb825394f3015ef4b1224eb7d9f55633d217e9,801ef1adca667ecdf243464b083282418d5987e4,nova/scheduler/client/report.py,1040,"ok nice makes sense, so no more double inventory queries from performance pov.",DISCUSS
1451,5fc1f717_f427d2b5,554f2c850707b85b178425c68166d49f34df5561,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/db/sqlalchemy/api_migrations/migrate_repo/versions/062_instance_mapping_add_user_id.py,27,"Hmm, if we're going to use this for mass lookups and counting, don't we want an  index on this new column?",DISCUSS
1452,9fdfeff1_138fac2a,79a2583efa835372fa375506e88aac92370ab98a,3548cf59217f62966a21ea65a8cb744606431bd6,nova/virt/libvirt/storage/rbd_utils.py,329,"This does implicit format detection on the imported disk, which is a well-known security hole. In this specific case a malicious user could create a 'raw' image which actually contained a malicious qcow2 header specifying a backing file of the the compute host's root disk. This would result in copying the compute host's root disk to the specified rbd volume and exposing it to the user.",FUNCTION
1453,bfdaf3ff_58683ff4,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/compute/resource_tracker.py,977,Ã¢Å“â€œ nice changes.,DISCUSS
1454,3fce034c_447c9db4,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/tests/unit/compute/test_compute_mgr.py,4960,"So, the change is in self._require_nw_info_update()
need to unit test it instead of _heal_instance_info_cache()",FUNCTION
1455,9fdfeff1_cb092d31,cfc1cb218c2f4824819ecd36c391a251995f3a16,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/tests/unit/objects/test_instance_mapping.py,111,"You're getting lucky here that self.context.user_id is 'fake-user' from _BaseTestCase and you used 'fake-user' in get_db_mapping(). I'm not asking you to change it, just pointing it out.",FUNCTION
1456,3f79a3b5_4caf4e9b,47ec5327c97c5916d9bc2b319bef8a7196fda60f,27b7bad88b531e0869f8e9af9ab951b921c37634,nova/compute/manager.py,512,"this change seems unnecessary to me (both the attribute renaming and the addition of the @property). Any reason we can't just do:

 self.reportclient = report.SchedulerReportClient()",DISCUSS
1457,3f79a3b5_c9d9da55,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,1122,"I'd think we'd have the same down cell issues here, but we're not using the scatter/gather utility so we're not dealing with those failures. Probably worth a TODO to handle down cells here as well.",DISCUSS
1458,bfdaf3ff_0db7dbd7,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/virt/hardware.py,1066,"just FYI, this is the kind of thing that placement's min_unit and max_unit address transparently for resources that are handled sanely.",FALSE
1459,3f79a3b5_dca5b39d,a2d72f673603f1f6487e09c78f36c27ebcb197a4,5d748001c2ffb1197ff991ca69a95865087f1010,nova/virt/libvirt/driver.py,1075,"Considering that we currently wipe out the instance directory if migrate_data.is_shared_block_storage with no regard for whether or not instance directory is shared, I'm not sure we 100% have to have this workaround config option, but it's probably better to be explicit, plus have it as an indication that the proper fix is future work.",FALSE
1460,9fdfeff1_0ac6ea69,7d9e3882e1a54ce421c36380817a1f619ccf250d,1948ce59c06aacc3fb9a71cbf8b099db8467da01,nova/pci/manager.py,317,recommend free_allocated_devices(),EVOLVE
1461,dfd5e7cf_3b8f7ecd,444441ec30e089761b7f4db68787b7b4e4dcf606,8d50d2ca84a654df23919b92c62bca4db88ad8e3,nova/tests/functional/test_conf_max_attach_disk_devices.py,44,"This can be a bit simplified:

        for i in range(0, 100):
            server = self.api.get_server(server_id)
            attached_vols = [vol['id'] for vol in
                             server['os-extended-volumes:volumes_attached']]
            if volume_id in attached_vols:
                return

            time.sleep(.1)

        self.fail('Timed out waiting for volume %s to be attached to '
                  'server %s. Currently attached volumes: %s' %
                  (volume_id, server_id, attached_vols))",FUNCTION
1462,5fc1f717_5b12a564,ff53c454276824112c45516153d0a6629b2ab658,9b121e3c37442cd12d3465928c36b93b09e916da,nova/scheduler/utils.py,607,"So why not do this after L545, and get rid of L553.",EVOLVE
1463,5fc1f717_88ee4f89,b096d9303acfea81ca56394cab681d2b2eed2d91,fd3b86d1c35efdd8356233863b8ad5b628df8d29,nova/conductor/manager.py,720,"This is another location where things can blow up and the server is left in BUILD status, in a case I just hit it was due to bug 1781286.",FUNCTION
1464,9fdfeff1_b3e9a41a,29f9febba714e1e331ecbdbc077606603dfc3ca5,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1640,oops,EVOLVE
1465,9fdfeff1_0d6b7685,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/compute/manager.py,6827,nit: NOTE (I don't know if that matters),EVOLVE
1466,5fc1f717_e13fd3b2,94524124a62817ffbeafddf8f18d9d66eb5f1198,b33fa1c054ba4b7d4e789aa51250ad5c8325da2d,nova/conductor/manager.py,1538,"Surely there is a test for this method and we could stub out instance mapping save() and assert that _create_block_device_mapping and _create_tags are called *before* InstanceMapping.save() to enforce the order, yeah?",DISCUSS
1467,9fdfeff1_1f65cfb5,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,983,ditto,DISCUSS
1468,3f79a3b5_b36f8f91,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/policies/servers.py,163,"Are there also microversion implications for this, i.e. it only works with a given minimum microversion? If so, the doc could be updated in the microversion patch on top of this to note the specific microversion.",DISCUSS
1469,3f79a3b5_d34f75bc,27b7bad88b531e0869f8e9af9ab951b921c37634,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,nova/compute/utils.py,1216,this should now be incorrect. I believe Ironic should return total=reserved when the node is unavailable...,EVOLVE
1470,9fdfeff1_67bdf1d6,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,1724,maximum,EVOLVE
1471,dfd5e7cf_c6143ba3,90c350fce0a30e59de753fddd6648513cc326ef7,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/pci/manager.py,300,nit: indent,EVOLVE
1472,9fdfeff1_5f5117d8,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,942,ditto,DISCUSS
1473,5fc1f717_3cb47dd1,59d95fabf796a3b33c2e086c4c27eeb2811eda20,edc130bc226e0e073b9fa102e8e77d6ba0834440,nova/tests/unit/scheduler/test_utils.py,107,++,DISCUSS
1474,9fdfeff1_73d55d42,52411867c391e04cbb227eb3bb6ef1af00e9358f,ffd81eb107dd04d05f828e9e049320412c576e1b,nova/virt/libvirt/config.py,311,"Is this a thing? I don't see it anywhere in https://libvirt.org/formatcaps.html

If it is, maybe make into a LibvirtConfigCapsGuestDomain object, because the nesting is getting pretty intense.",EVOLVE
1475,5fc1f717_e03f08d4,5e5b60ad0b468843bd4f11599a4e3f5ee6709598,00046e47db5d51ac4eb7f9d6e5d1e618663e806c,nova/compute/api.py,2447,Should have a simple test wrinkle for this in test_save_user_id_in_instance_mapping.,FUNCTION
1476,9fdfeff1_ab617707,3730bd079104ad14f6992ad55cf8643911c916ab,bbfb3bcf792b0d712ec59259479c8701b1e31722,nova/tests/unit/api/openstack/compute/test_migrate_server.py,109,Not sure we need this or the unit test below when we have the functional tests.,EVOLVE
1477,9fdfeff1_1f3f4a25,4da058723332a58323640fabce3d95902946a07d,b01da49dfc38057a751cb59f4a7a99dd7f20b6ff,nova/conductor/tasks/live_migrate.py,169,"I would lower this too to be safe, but I guess it's not going to change.",FUNCTION
1478,9fdfeff1_99ba446c,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/compute/manager.py,87,pcir_obj?,EVOLVE
1479,9fdfeff1_c7ea9dd6,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,1021,maximum,EVOLVE
1480,3fce034c_4e5b8c53,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7316,"we might still want to do this updated of the info cache if the ironic compute node has been rehased to be managed by a new compute agent.

im not sure when ironic nodes are allocated to compute agents.
if its just when nodes are requrned to a pool then ignore this but if the compute agent to irionic node mappign can chagne for example when a compute service goes offline then

its possibel that this is the frist time this agent has managed this ironic node and we do want to prime the cache with the instace netwrok info.",DISCUSS
1481,9fdfeff1_53298b34,344e0fcb74f0e4057af0a72ae4924b4f2e2baed9,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,3173,"Is this case obsolete after the change, are file-based sources still created?",DISCUSS
1482,dfd5e7cf_878f23cb,9cd315ef07bacc3c70fc6db4efdbbd3048747f19,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,205,nit: Add white space,EVOLVE
1483,9fdfeff1_06481985,48d6753d37c0ef1ae5aa1ec9b5b369869ff8905b,ffd81eb107dd04d05f828e9e049320412c576e1b,nova/virt/libvirt/config.py,313,consider calling this variable default_emulator to make it crystal clear that's what this is.,EVOLVE
1484,9fdfeff1_662ecafb,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/tests/unit/objects/test_request_spec.py,1404,A clearer simulation of the problem would have been if this (the compute) RP contained NET_BW_*.,FUNCTION
1485,dfd5e7cf_d0a3be4e,9b7d0fa5b0c60c878914a6fdecfec538fb4a1748,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/tests/unit/virt/libvirt/test_guest.py,569,"this will also cause pep8 line lenght issues.

http://logs.openstack.org/40/627540/4/check/openstack-tox-pep8/b3eb386/job-output.txt.gz#_2019-01-07_17_12_01_911386

spaces will be ingored in how we parse the xml if we reflow the text.",FUNCTION
1486,9fdfeff1_0dd2205d,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1716,same,EVOLVE
1487,9fdfeff1_87c25558,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,1743,maximum,EVOLVE
1488,9fdfeff1_8ff37fe7,0db948f8bca4579d9e187d83250e6c5ddfbacfe7,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/tests/unit/compute/test_compute.py,521,nit: use mock_destroy.assert_called_once_with() for a cleaner assertion message if this fails,EVOLVE
1489,5fc1f717_6ff59250,2f06b12623d446da0c398e681b3ee1fb68791d31,c3e3eede0916fa21015c4403f38a5ff0ae107f0b,nova/scheduler/host_manager.py,702,same,EVOLVE
1490,5fc1f717_92963a93,35cc0f5e943642dd8d9dacbf0dac6e260f708d7d,a6963fa6858289d048e4d27ce8e61637cd023f4c,nova/tests/functional/test_images.py,106,"It will be great check the image with tenant user context in the end, just ensure the tenant user can access the image.",FUNCTION
1491,9fdfeff1_8963ed41,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,538,Why did we need to split this out? If there were a docstring I wouldn't have to ask. I'm assuming something about the resize case and maybe volume-backed servers? But that change in compute.utils points out that even for volume-backed servers the image status is faked to 'active'.,DISCUSS
1492,3f79a3b5_cef26ee4,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,ec044885ff2c44202cc62cf85149b7993d4d0221,nova/scheduler/client/report.py,672,fourth option: do nothing and don't care.,FALSE
1493,9fdfeff1_6ca8571f,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/tests/functional/db/test_instance_mapping.py,306,"Well, I think we're going to drop that code as being over-eager for a tight window, but the next run of the data migration should hit it.",EVOLVE
1494,3f79a3b5_258e0a26,801ef1adca667ecdf243464b083282418d5987e4,2b97e508381e7f1efe48799ee3d9b068b4fd5902,nova/scheduler/client/report.py,680,"okay so this is the main optimization factor here: basically before this change we were always doing this call (i.e GET/resource_providers?in_tree=rp_uuid) and now we check 

1) if the provider tree cache of the resource provider with uuid exists already and if its fresh enough to not need refresh, then we go into the cache of the rest of the descendant nodes under this tree and directly add those node uuids whose cache is stale and needs refreshing (which would never be stake if association_refresh config is disabled). so that way we do not need to query placement to get the ""in_tree?"" nodes, since we pick it up from the cache of the provided uuid.

2) only if either the tree doesn't exist (which would only be during startup and/or sighup) or if its cache is stale which wouldn't happen if the association_refresh config is disabled, would it do the ""in_tree?"" query to placement.",DISCUSS
1495,bfdaf3ff_8f639fdc,58ead788aac71adf85ea38533ae10a33a8a48b0b,cf9e6db595191cefaba469c00efa66b5e51f3b65,nova/exception.py,2356,"If you made this extend InvalidBDM, then you could drop https://review.openstack.org/#/c/624832/5/nova/compute/manager.py since this will handle it:

https://review.openstack.org/#/c/624832/5/nova/compute/manager.py@2320",EVOLVE
1496,9fdfeff1_9e590f8f,900fe1c2e8e90be914f283563c0664439db54b5a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,4952,"Surely this entire column should go now since virtlogd is always present (or at least we don't have a conditional to check for it)

Later: tbh, I'd just remove this entire thing now. It should mostly be rewritten otherwise",EVOLVE
1497,3fce034c_1f35a546,02b26457f3c5773973f374f39e069d2a854e99f6,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/tests/unit/objects/test_request_spec.py,981,"The specified version is 1.0, why not 1_0 here?",EVOLVE
1498,5fc1f717_57df1668,40cbea18e6afba46cdc72712b89a122a1377592b,9b2a7f9e7c9c24ad5b698f78681a1de1593b4a53,nova/db/sqlalchemy/api.py,2775,ditto,DISCUSS
1499,9fdfeff1_94d20bd1,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2110,nit: unrelated,EVOLVE
1500,3f79a3b5_fcad0f83,fae92384a3d2d3299f7e25419b16ec7534f9233a,8d089111c8554e94e117ada3a7f51a42df59e84f,nova/conf/compute.py,660,"To Tetsuro's point in the release note, I'm not sure how much operators would read this and understand the implications.  For example, the compute service doesn't use aggregates information yet, so they shouldn't care about that. As for traits, that might matter if they are externally setting traits on compute node resource providers in placement for scheduling decisions. IOW, we should probably try to describe the use cases this is related to rather than ""this refreshes some stuff in the compute but you don't really know how that stuff is used, or if you should care"".",EVOLVE
1501,9fdfeff1_002246a5,9d5e805009a7f773eac9b696ea8162a04ff73b0e,7381ec7d7c318bddd42e1d90a171d20b2ec6f49d,nova/compute/manager.py,5369,"A comment here would also be nice, e.g. ""Some drivers may return an int on console_info.port but the port variable in this method is a string, so cast to be sure we are comparing the correct types.""",EVOLVE
1502,5fc1f717_771dd7bb,a036359b7d718b0e762cd6a91807af6a6390a07d,4f9bc724010f0c935bf83a6d19bdd805e86b7086,nova/conductor/manager.py,1287,same,EVOLVE
1503,dfd5e7cf_fa180682,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/weights/disk.py,20,ditto,DISCUSS
1504,5fc1f717_2ef5e383,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4563,ditto,FUNCTION
1505,9fdfeff1_29ae8181,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,544,Documenting this in a docstring would be nice.,EVOLVE
1506,3f79a3b5_5d2de4aa,619b81e81f99dad4601c4e0d567d7f138562856c,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/virt/libvirt/volume/net.py,73,This should probably be updated to mention username.,EVOLVE
1507,9fdfeff1_ee7d361c,b2e26271f40f9ee46822ad0a573116f0e02c2ca5,e90f01e81fe9696afcbd96128345a018573cfc05,nova/virt/libvirt/driver.py,6347,"Refer to [1]. TL;DR: the proposal is to have the virt driver's update_provider_tree method save a mapping that spawn can subsequently read. The simplest thing is for upt to save the ProviderTree object as an instance variable on the driver object.

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-02-12.log.html#t2019-02-12T14:42:21",EVOLVE
1508,3f79a3b5_7757c6cd,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,176,"exist?

Although ""be tracked"" might be better - the device could exist but it might not be part of the whitelist.",EVOLVE
1509,bfdaf3ff_da940b47,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3014,once found you should break,FUNCTION
1510,5fc1f717_b7233f05,a036359b7d718b0e762cd6a91807af6a6390a07d,4f9bc724010f0c935bf83a6d19bdd805e86b7086,nova/conductor/manager.py,1285,"nit: future proof this by just saying ""operation""",EVOLVE
1511,5fc1f717_8777bea0,8fcf36eb218faa5ea59f53c08b5226001f655b8c,e608568518ed91a0cbf08f779c5adb851762d80a,nova/conf/libvirt.py,854,"should reformat this as well, but meh.",EVOLVE
1512,9fdfeff1_6e9e7db9,5158327bc8a2fbc4c3cabcf3fd964e5f61285fa1,89c2d1056b3f37bad243c7468d974ded71336a0f,nova/virt/libvirt/driver.py,4894,"Prefer to use a function to do the checks and return `use_unique_serial`, there is a function `nova.virt.hardware._get_flavor_image_meta`. And better to check the boolean value using `oslo_utils.strutils.bool_from_string` I guess?",EVOLVE
1513,1f769fc5_0bcfe87f,5f2ec710cf38be6c23e04ce40e8a298d50e3b79d,5d748001c2ffb1197ff991ca69a95865087f1010,nova/conf/libvirt.py,807,"ditto, though the other options are wrong here (and we don't want unrelated changed, especially not if this is being backported) so maybe leave this one",FALSE
1514,9fdfeff1_880d47e9,b38ebb55c936b19e811e72e149d19d06fdff5f3f,5a4863aa152f58f6de426b3908a75c2cc1b2efca,nova/virt/libvirt/driver.py,1309,"If you're thinking about a refactor, this whole method is obviously a race and needs a redesign, but this specifically can be done much more efficiently in a single query.

Pseudoquery:

  select count(*) from instances where instance.uuid in attachments and instance.host = this host

The current implementation becomes more expensive the more instances per compute host.",FUNCTION
1515,9fdfeff1_add99483,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1694,"This could raise a 404 if the port is already gone. In fact, I remember fixing a related race bug for this in tempest recently:

https://review.openstack.org/#/c/605488/

So we could hit a case where the server is being deleted at the same time this (asynchronous) call is made. So should we handle that and continue below to at least try and delete the VirtualInterface information? Note that _unbind_ports and _delete_ports both handle the port being gone already gracefully.",FUNCTION
1516,5fc1f717_8974369b,2a12e420c2934e49da5cb3e586407d3f6e1d6300,554f2c850707b85b178425c68166d49f34df5561,nova/objects/instance_mapping.py,65,nit: is not,EVOLVE
1517,9fdfeff1_2babbd75,76cfd5925192d2bf717d67dd667fc8541398e6af,c5bb7b5dd4175d5017449de680895120942a36dc,nova/compute/manager.py,6646,"why not just self.rt.pci_tracker? (also I think that was causing the failure in the unit tests)
it seem that in the resource tacker it always check that 
if pci_tracker: . I think we should keep this and you can remove the TODO comment",DISCUSS
1518,3f79a3b5_e1ae949f,985307f562ec2143b21c210cfa65c7ab0f422e7e,9d15f3aa07a8fed2d42ee9ba92336d25b762f71c,nova/objects/compute_node.py,200,"you can combine these lines, you just assigned a series of variables here.",EVOLVE
1519,9fdfeff1_2a28ea30,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6243,"So as of this change the rp_uuid will always be the ComputeNode resource provider and if it's not in the local ProviderTree cache that was initialized on startup we don't know about it - not really something that should happen, but I guess we're being paranoid.",FUNCTION
1520,9fdfeff1_ce3ba4ce,869eb884b476b04642957ead2fda4c8a3ec44feb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1264,Should this be `LOG.exception`?,DISCUSS
1521,3f79a3b5_be06b972,82884c897cac0fc0cb21de8838e02ee806e223d6,7217e38bafb75e8a613763835b64e48e6b2c8ece,nova/objects/block_device.py,387,"Hmm, these can be passed in during boot from volume with the block_device_mapping_v2 parameter but not during volume attach. They might not be valid for a new root bdm anyway, but it's not something I thought about resetting.

Looking at other fields, volume_type is probably also something to reset. What about device_name and guest_format? I guess guest_format wouldn't be set for a root bdm since guest_format is only for swap and ephemeral BDMs. But device_name could be changed on a subsequent attach request (even though we ignore it).

The image_id and snapshot_id fields would also likely be irrelevant if you changed the root volume, so I don't know if we should reset those to None or not also.",DISCUSS
1522,3fce034c_21f971c7,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7274,"Note:

the control flow of this is honestly terrible.

the first time through this fuction 
instance_uuids will be []
so we enter this branch and recored the first instance on the hosts as instance
then add the rest that are not building or deleteing to 
self._instance_uuids_to_heal",FUNCTION
1523,9fdfeff1_54a670c3,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,679,Jay pointed this out later but we could just 'allocation' to the generator on L674.,FUNCTION
1524,9fdfeff1_093b0f9c,780ccfcbdea919b196c18372d1c66bc88b4fa48c,444d65221cc7a20a73fa38aa1ca41d7957b0198e,nova/objects/numa.py,140,"Stupid o.vo question time, changing this signature doesn't break us if we pass around NUMACell objects between  stable/rocky services with and without this change right?

I'm not even sure that we pass NUMACell objects around but just wanted to check that if we did this wouldn't break us.",DISCUSS
1525,9fdfeff1_8aed118d,965fec7e320640c610444305a0809c33dddd8fc1,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/tests/fixtures.py,1393,Good catch. We could use fields to filter out fields from the returned port dict but that is a future enhancement of this fixture.,DISCUSS
1526,9fdfeff1_5c264acd,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/tests/unit/scheduler/client/test_report.py,3651,"excellent unit tests, thank you Gibi.",DISCUSS
1527,9fdfeff1_544a0727,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,769,needed,EVOLVE
1528,9fdfeff1_0e0a9e25,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_compute.py,95,"This one is a bit tricky since it's actually inversely proportional to the value set, so min could be thought to be -1000, so in that case would we want to pass based_on=max to validate_num_values?",DISCUSS
1529,3fce034c_bc45a219,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/tests/unit/objects/test_instance.py,547,ditto,FALSE
1530,3f79a3b5_64c08f7e,4ebd2504bb27afac7184d254aa6556fe61493a5d,fae92384a3d2d3299f7e25419b16ec7534f9233a,nova/tests/unit/scheduler/test_client.py,40,"You could probably kill this test entirely, as all it seems to be doing is confirming that python works, unless we really care to confirm that keyword args actually happen?

I suppose this and the other modified test are basically confirming ""yes, my proxy methods do in fact proxy"".

I suppose that's valid but suggests a future refactoring where get rid of the proxy/facade entirely.",FUNCTION
1531,5fc1f717_e6af2092,bc718dd37c1505aa3784c8379b6544d1bae169b5,b4320d0bfe7908797af7f57cdca8c19cfa379ffe,nova/pci/request.py,209,nit: unnecessary (None is the default return),EVOLVE
1532,bfdaf3ff_0e8b201f,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/virt/libvirt/blockinfo.py,194,"Is there a chance that we could have an upgrade impact where a user reboot a server with volumes already attached and then the device names change? Or should the device name calculation be consistent with what we had before, with the addition of allowing more devices (the patch below this one in the series)?

The reason I ask about the device name changing for existing attached BDMs is because virtual device tags for volumes are linked via the device name, so I'm wondering if we could have a case where a user creates a server, attaches some volumes with tags, we upgrade, and then the user can't correlate the device tags to the bdms in the metadata API anymore.

https://github.com/openstack/nova/blob/e5b55245976293e0cb53089cc1efad6cc1edfa17/nova/virt/libvirt/driver.py#L8791

https://github.com/openstack/nova/blob/e5b55245976293e0cb53089cc1efad6cc1edfa17/nova/api/metadata/base.py#L441

Why we used device name as the correlation key there I can't remember, Artom might. Seems like using bdm uuid would have been better but maybe that didn't exist when that code was written.",DISCUSS
1533,bfdaf3ff_736d2497,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/tests/functional/test_report_client.py,301,any reason to remove this?,DISCUSS
1534,5fc1f717_4e6dca97,71e5c9ea4da49e6ef86cc176ac24216186db1092,3aa702686ba0e01e8931585636da8d9535098923,nova/tests/fixtures.py,59,nit: Should probably have been in the previous patch,FUNCTION
1535,9fdfeff1_05190287,3f0cc8c27856461eb6b4366254260033c9910875,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/api_sample_tests/test_migrate_server.py,210,instance.uuid?,FUNCTION
1536,3f79a3b5_92bb1010,b88074fcc5d840de962845f09d5c206406838c8e,6f970f0b1996ad59eeac849b975737b13feb6c1a,nova/network/linux_net.py,40,It should be removed.,FUNCTION
1537,bfdaf3ff_8474cf69,127104732e6c25b97f9547f3368e8e66cd04e27a,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/objects/virtual_interface.py,189,"This is never decremented, which means you're going to process $max_limit instances from each cell, which could be more than the actual limit the user specified.",FUNCTION
1538,5fc1f717_f105407b,c49813ccfb1e50d4973dd79038fb32ee3c8c1b5e,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6745,Claim,EVOLVE
1539,9fdfeff1_a8b36be8,b38ebb55c936b19e811e72e149d19d06fdff5f3f,5a4863aa152f58f6de426b3908a75c2cc1b2efca,nova/virt/libvirt/driver.py,1316,"A more obvious way to write this would be:

  # Assume that if we're being called, it's only for an instance we expect to still have attachments here, regardless of its current host.
  if instance.host != CONF.host:
    connection_count += 1

I also think this better states the assumption here. I'm trying to think of situations where this assumption may be incorrect.",FUNCTION
1540,3f79a3b5_6cf80a17,d86125602775505d88f832831ec3c68a97d71fdd,6d0386058b9628bbfcf64abdd707ad87ee19353c,nova/conductor/manager.py,1227,"Aren't the tags part of the notification above in the InstancePayload? I guess not:

https://docs.openstack.org/nova/latest/reference/notifications.html#versioned-notification-samples

I thought we had tags in the payload somewhere? Maybe gibi remembers why we don't have the tags in the versioned notification payloads.

Anyway, I think we should create the tags in cell0 before sending the notification in case we change the notification payload at some point.",DISCUSS
1541,3f79a3b5_440eb330,085fe6de688923540e13440f9189310e4cc15194,288c537fcd3dd605dc3ad393ba1234199a782e05,nova/conf/workarounds.py,201,"Also kernel and ramdisk, but I don't think anybody cares.",EVOLVE
1542,9fdfeff1_cf6db032,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/unit/api/openstack/compute/test_serversV21.py,3780,not used,FUNCTION
1543,5fc1f717_7271970c,8cf401735ec885c07647a75731e694a1e798e3fe,2384c41b781a84de98d0932f44d4b3c544c3fe3d,nova/virt/libvirt/driver.py,6056,nit: would it be cleaner to just put this in the try block?,EVOLVE
1544,dfd5e7cf_bdab58d4,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,928,ditto,FUNCTION
1545,3f79a3b5_8c0246b8,47ec5327c97c5916d9bc2b319bef8a7196fda60f,27b7bad88b531e0869f8e9af9ab951b921c37634,nova/compute/manager.py,563,why was this needed?,DISCUSS
1546,9fdfeff1_74cb7e52,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/network/base_api.py,208,'the' or 'such a',EVOLVE
1547,9fdfeff1_21e65a18,a77fc3458274b6778ba3a7a61cfb1cbaca229eae,d928de52fe2fe43d9eae796bf60273551a61e2f3,nova/network/linux_net.py,936,"We lose the fakeyfake behavior of _execute; but I guess since tests don't blow up, that must be okay.",FALSE
1548,9fdfeff1_6d29a787,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1268,"We removed the CachingScheduler:

I1832da2190be5ef2b04953938860a56a43e8cddf

But technically there could be out-of-tree scheduler drivers that don't use placement which means the scheduler driver doesn't actually create allocations, so it might be prudent to have a condition on allocs actually having something in it before we get this far.",FUNCTION
1549,3f79a3b5_23141199,36c992f72d988ff20e3e286c1065aa76db5aec03,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,616,This passes because the thing you passed in is the same thing you're checking against. mock_update should actually return a value with a different updated_at time and assert that the 2nd updated_at time is the one that's on the object after _from_db_object returns.,FALSE
1550,3fce034c_6ef3e80b,49a9ce67ae3798bbcf8e0701d33f791c57ca7e93,9aa071f12c7461a9108d96c5e71769d055d2c95d,nova/cmd/manage.py,1190,"I'm not sure about that, it was added in https://review.openstack.org/#/c/270565/ but I'm not sure if it was for the v1 transition, but maybe since it talks about passing nova-cells.conf.",EVOLVE
1551,3f79a3b5_5752cada,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,180,"reasonable,",EVOLVE
1552,3f79a3b5_531bde1b,2b97e508381e7f1efe48799ee3d9b068b4fd5902,32082ebcfc17fdaf83e8f154ce0045e7a1fed16a,nova/scheduler/client/report.py,279,"note to self: 

1) we clear this refresh_time cache for all nodes as well so that after the SIGHUP, the `refresh_time` would be zero (https://github.com/openstack/nova/blob/7217e38bafb75e8a613763835b64e48e6b2c8ece/nova/scheduler/client/report.py#L858) and we would hence load the RPT cache like on startup, on the first periodic update.

2) we could also just do a force refresh here: https://github.com/openstack/nova/blob/7217e38bafb75e8a613763835b64e48e6b2c8ece/nova/scheduler/client/report.py#L768 maybe but that code path doesn't do an explicit inventory refresh which is why it isn't very useful here and also because we clear the whole tree, probably makes sense to load the tree freshly and refresh everything.

3) need to check how the SIGHUP of ironic compute would look like for all the underlying rp's at the same time (since in rocky starting up doesn't bring the service up so probably same effect).",FALSE
1553,9fdfeff1_a7c67967,6489f2d2b44827d133dad9a3bb52436ee304a934,56811efa3583dfa3c03f9e43a9802bbe21e45bbd,nova/virt/driver.py,1023,why would detach_volume() ever return TooManyDiskDevices?,FALSE
1554,5fc1f717_7cb93c13,43ce926dccae9e60611b1224ab06dcad8f650fce,b7bd97bc8896346e92d271a443d5ada9ab0074be,nova/compute/manager.py,1394,maybe just use self.host?,FUNCTION
1555,9fdfeff1_813dc6de,dda0b9d95019ada2ea975fd1d5c434661dad09a7,3b79f635de4d3495f01ed98d1a8bcfaefe154b0b,nova/network/linux_net.py,1545,Oh - we lost run_as_root=True,FUNCTION
1556,9fdfeff1_b08a9118,c7490fcdb46fe883aefc2c85293973e9df226b3e,2bf79236a39aa4417fea39ab1f900bf150b05764,nova/tests/unit/test_utils.py,1434,"oo, should this util (and these tests) be moved to os-resource-classes?",EVOLVE
1557,9fdfeff1_43fdb806,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/objects/request_spec.py,530,This will always be False because what we're doing in this method is setting fields on spec (which is a RequestSpec object) based on the results from the db_spec. It looks like you should be looking at spec_obj here instead.,FALSE
1558,3f79a3b5_55f6822e,9001ef47086427806c3ac7461edbc0d1bb176d07,f572527d2b7f93b0c2108118c2f240f2dd1cf968,nova/conf/api.py,218,"I'd personally drop this entirely since this is already inserted by the Sphinx extension and the oslo-config-generator output, plus things like this tend to get out of sync with the code.",EVOLVE
1559,3fce034c_330f75e2,acd64d1d805ad36004bc4c23d74ed7490bd43857,02b26457f3c5773973f374f39e069d2a854e99f6,nova/db/sqlalchemy/api.py,661,"As far as know, host is not the same as hyervisor_hostname. MHO, should we need an another new exception like ComputeNodeNotFound(nodename=hypervisor_hostname)?",DISCUSS
1560,3fce034c_216df131,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7230,"this gets called once every 15 mins by default.

so if i have 16 instance on a host it will update each every 4 hours  it is documented i guess but i for one 
had always tought this updated all instance in the cache on every invocation. im not sure if this is a proablem or not.

it certenly makes the interval untill an instnace i healed much longer tehn i expected but changin the behavior coudl significaily increase the neutron api queries so maybe this is what we want...",DISCUSS
1561,9fdfeff1_a7463e7a,6b844af57eebda6317b1ed3bf5a2f85dcba0bc13,a6963fa6858289d048e4d27ce8e61637cd023f4c,nova/tests/fixtures.py,792,The only thing I worry about with this is messing with private attributes in a library. We could guard against that by checking if the attribute exists before resetting it.,DISCUSS
1562,9fdfeff1_4325cf09,8cf12f5843ddbc3954ef8c3bc774ecd6eb05a7b7,d46cb73fb001d35ae76ed30303b1cf8f63d5860c,nova/tests/unit/compute/test_compute_mgr.py,8498,nit: identation is all whacky. This block should be dedented by a tab,EVOLVE
1563,3fce034c_4099096c,02b26457f3c5773973f374f39e069d2a854e99f6,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/tests/unit/objects/test_request_spec.py,997,"this is not really needed right since the object would anyways have the ""in_tree"" field set to None by default? So I guess this test and the one above are same except the downgrading to versions 1.0 and 1.1 respectively (which is probably why the naming of the test seems confusing). Both these tests could have just been combined into one like here : https://github.com/openstack/nova/blob/013aa1915c79cfcb90c4333ce1e16b3c40f16be8/nova/tests/unit/objects/test_instance_mapping.py#L168",FUNCTION
1564,9fdfeff1_1738ea3a,9ba910bb539b0172bab899852692a49d30645a14,a5d6833d77c961ea75488f0992b91d3166424381,nova/tests/unit/network/test_neutronv2.py,5219,"nit: rename to mock_request_group or mock_from_port_request

When I was first looking at this variable below I wondered what a request spec had to do with this test.",EVOLVE
1565,9fdfeff1_b803f40f,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1409,x,EVOLVE
1566,3f79a3b5_9b3e88b4,d6172354e1e02d37bfcf37c0748a0dba0f7bd685,3e756ff674e5da58b854b6b65ae225e3f7f97556,nova/policies/servers.py,156,"we recently added consistent naming thing in oslo policy [1] which are also proposed in nova polciy change spec[2]. 

Can we make this new policy with considering to consistent naming so that we do not end up changing this policy. 

current name become like- os_compute_api:servers:create:cell_down

as per consisten naming suggestion, How about: 
compute:server:create:cell_down

[1] https://docs.openstack.org/oslo.policy/latest/user/usage.html#naming-policies

[2] https://review.openstack.org/#/c/547850/",EVOLVE
1567,bfdaf3ff_4294e944,b19c2b7ccacfe3c464d1512049b0d2bc64b81350,5f9c8b45ffc5c2b9da5e3da6f2b4214b391d9900,nova/compute/api.py,3590,"I think this is wrong.  In the case of a resize the image isn't changing.  Also, I think it's possible the image properties (of the image) may have been updated since the instance was created, so I think we should use instance.image_meta here rather than the current properties for the image.  (In order to match what will be used later on in the virt driver.)",FUNCTION
1568,3f79a3b5_9ca97bdf,073c330f52dfa535e6f787f5bb2fc8ec52f1be9a,514eaaef12dad2460fd4c2fffdc05a3db0490711,nova/compute/resource_tracker.py,808,"And that happens somewhere else down in _update_to_placement I'm assuming when we call reportclient.update_from_provider_tree? Since this is a bit tightly coupled to what happens down there, you should probably add that detail to the comment, otherwise pass the is_new_compute_node through that call path. It's not immediately obvious to me how clearing the cache here means we create (or ensure) the resource provider for the newly created compute node later.",EVOLVE
1569,5fc1f717_dd29e589,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,90,"test_create_with_name_too_long is testing long length of flavor name. But the length 0 case is not tested now.
Could you add the following unit test to test_flavor_manage.py?

     def test_create_with_short_name(self):
         self.request_body['flavor']['name'] = ''
         self._create_flavor_bad_request_case(self.request_body)",DISCUSS
1570,5fc1f717_ae09d395,e96f5ae68b8d297c31cc4fbd04e46d9f60db9427,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/unit/compute/test_compute_api.py,4551,"The following fields are not lazy-loadable. So they should be set (None).

volume_type
snapshot_id
volume_id
volume_size",FUNCTION
1571,9fdfeff1_ebf2da04,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6264,"this is fragile, FYI. anyone can change the name of a resource provider in the placement service. As soon as that name changes, boom, this is broken...",FUNCTION
1572,5fc1f717_dabc46bd,ced9c58503ed539787deee4d540b201445d03419,99ad674c26fdacfff72d84624ee060cf0e33304b,nova/tests/unit/network/test_linux_net.py,956,"I'm missing where assertions like these are made in the new code. New line 924 is the check, but .. is anything actually passing that command list?",DISCUSS
1573,9fdfeff1_77cced60,d0d51a653a25a651e204b940957d0eb3c85798e5,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,635,"nit: if we've got multiple ports on the same network, we don't need to do this lookup every time since we could just keep track of the networks we've already got, keyed by network_id.",FUNCTION
1574,3f79a3b5_0757af5b,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/driver.py,7392,"I was wondering why we just don't call trigger_postcopy_switch here like L7408 below, but I guess we do it in a roundabout way by calling live_migration_force_complete because that will make us hit this code:

https://review.openstack.org/#/c/619143/12/nova/virt/libvirt/migration.py@579

Am I following this correctly? If so, wouldn't it just be easier to call trigger_postcopy_switch and avoid that in-between logic?",DISCUSS
1575,5fc1f717_7e100b5a,391ea45fa36aac2aaad6af21f5c2af2086f393c0,556cf103b22ab6bebecc9d824d6f918cda38fe3e,nova/virt/fake.py,616,"A bit unrelated to the change, but looking at PS3, I understand why you modified it.

We could have had a specific change for the above but I'm fine with squashing it.",DISCUSS
1576,9fdfeff1_9ee6efaf,a76eefed62db96fe51ef40e3209c187af3eb9834,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/unit/virt/libvirt/fakelibvirt.py,1550,nit: redundant,EVOLVE
1577,9fdfeff1_ea8d14d4,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/compute/manager.py,5965,"We don't need the if/else condition here because you can do this:

with excutils.save_and_reraise_exception(reraise=raise_on_failure):",FUNCTION
1578,3f79a3b5_ec62dad9,d86125602775505d88f832831ec3c68a97d71fdd,6d0386058b9628bbfcf64abdd707ad87ee19353c,nova/tests/functional/regressions/test_bug_1806515.py,63,nit: drop the blank line here,EVOLVE
1579,3f79a3b5_bd1d1879,619b81e81f99dad4601c4e0d567d7f138562856c,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/tests/unit/virt/libvirt/volume/test_net.py,153,and username.,EVOLVE
1580,9fdfeff1_e599c779,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/objects/instance_pci_requests.py,44,I guess we don't need to set default=None on requester_id since it'll just get set to None here if it's not loaded.,DISCUSS
1581,9fdfeff1_181ff270,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,f6996903d2ef0fdb40135b506c83ed6517b28e19,nova/tests/functional/db/test_instance_mapping.py,370,"And because of the way this is handled:

https://github.com/openstack/nova/blob/a6963fa6858289d048e4d27ce8e61637cd023f4c/nova/objects/instance_mapping.py#L105

The create() method should insert the record with None rather than False so we do get the OR condition in the query covered.",FALSE
1582,3f79a3b5_4c8ad566,df6ebfeb0f3675a9dc64c9da5e1edd57b0490f19,4fdc5f33c0a62d1369187f165e0b1d5b2a58f547,nova/network/linux_net.py,1431,what about these?,DISCUSS
1583,5fc1f717_97f1fe03,40cbea18e6afba46cdc72712b89a122a1377592b,9b2a7f9e7c9c24ad5b698f78681a1de1593b4a53,nova/db/sqlalchemy/api.py,1791,Ã¢Å“â€ https://github.com/openstack/nova/blob/master/nova/exception.py#L616,DISCUSS
1584,9fdfeff1_ed51bb37,b35c6b3bfdab2f0277cc692393532d1b6ee7d113,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,5629,guh,EVOLVE
1585,9fdfeff1_ad5b7d83,7680760c82cc3793d856ff502f16b834d624eb1c,9bca646324913916e352601ece1afe4e060fadd8,nova/compute/manager.py,7549,nit: We can move this line into the previous line.,EVOLVE
1586,9fdfeff1_1bf36ce9,12c38291b85a373905bd754bd210c7d1cac53662,d9bd5b1377acf4468c89422fa471de6c8325d775,nova/api/openstack/compute/servers.py,213,"On the command line it's --all-tenants (for nova CLI) and --all-projects for openstack CLI. In the API it's just ""all_tenants"" so let's be consistent with the wording of this filter parameter and talk about it from the API parameter name, not the CLI.",EVOLVE
1587,9fdfeff1_8afa3640,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,119,Why is this 20 when _create_flavor defaults disk to 10?,DISCUSS
1588,5fc1f717_615fbee5,67d5970445818f2f245cf1b6d9d46c36fb220f04,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/regressions/test_bug_1815153.py,174,same,FUNCTION
1589,5fc1f717_5cb8e40f,3f18b702afe20cc7e3c3a1ccbdb2dbcc286bdbbb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/virt/libvirt/driver.py,1264,This doesn't need to be marked for translation.,FALSE
1590,3f79a3b5_eed279d0,ef0a50df52abef022d67fa20a1bbba9bb23ad6c2,ad31f5d66d6df25555c2f1c5653ac754790f06df,nova/virt/xenapi/vmops.py,1160,'ws' is better at the end of a line.,EVOLVE
1591,9fdfeff1_facc148a,55f455262144ab319a9ff480850aeece88b1dedb,20a46ece5701c9798a5e0df12c944237cb1ece3e,nova/scheduler/client/report.py,1766,"I'm curious whether we ever hit this part now. Under what circumstances would target allocations exist, where it would be okay to overwrite them? I.e. I'm wondering if we should make this an exception now (possibly in a separate patch).",DISCUSS
1592,9fdfeff1_a698a0bf,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1659,conflicts,EVOLVE
1593,5fc1f717_3c69588b,3f18b702afe20cc7e3c3a1ccbdb2dbcc286bdbbb,7491de2e80506320a3e8e73c37d5c6c8174e43e8,nova/tests/unit/virt/libvirt/test_driver.py,7512,I'm surprised we don't already have a test for this but I don't see anything obvious.,FALSE
1594,ffb9cba7_7bff36aa,13278be9f265e237fc68ee60acfacaa1df68522e,b7a018f1265d9e0354e26822d32cbdc789819c35,nova/virt/ironic/client_wrapper.py,99,OK and this is a microversion.,DISCUSS
1595,9fdfeff1_dc1823d4,be61237a7bc7cf2fa8423f7a798e944e8ee6b3da,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,189,"Since this code is just being duplicated from L354-L360, maybe we could just do this before calling _show_from_down_cell() and pass the list alone since anyways show_server_groups will always be true as 2.71 > 2.69. That way this function doesn't have to end up having everything duplicated from show() unless necessary. Sorry if I confused you in my previous comment about passing the ""show_server_groups"" flag. I thought it would be 'moduled' into a separate function like the show_extra_specs/get_flavor(). If you prefer you could also just module this as _get_instance_server_groups() and call it from both these functions, upto you.",EVOLVE
1596,dfd5e7cf_b91cac6a,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,6975,...and you don't have the equivalent 'if pci_tracker' check here,FUNCTION
1597,3f79a3b5_99044613,4224afc5850e7969ff3df3e1218aebfffc8887f3,ed4fe3ead62c09ec7de7b6a11072295a99997b4f,nova/compute/api.py,3628,This 'if' can be removed.,FUNCTION
1598,9fdfeff1_603d69ba,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/scheduler/client/report.py,808,and now inventories as well.,EVOLVE
1599,9fdfeff1_ad00b435,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/scheduler/client/report.py,1709,"nit: I'd personally avoid a generic error reason for each of the specific errors below to help with debugging since that leaves the person looking at the logs to have to figure out just what about the resources_to_remove and current_allocs is causing the failure. Plus then in your tests you can explicitly check that you're asserting AllocationUpdateFailed for the correct reason, e.g.:

ex = self.assertRaises(exception.AllocationUpdateFailed, ...)
self.assertIn('something i expect for this test', six.text_type(ex))",EVOLVE
1600,3fce034c_98c01253,a4543eaf2e55bfb3abd981aa9d743f39cd2559ce,0d1310224818c204c52f67deee18efafd1269681,nova/objects/compute_node.py,275,nit: it'd be nice to have a docstring on this to mention that it raises ComputeHostNotFound because I always have to dig into the DB API code to figure that out when writing code against object DB query methods like this and if we just documented the object query methods I wouldn't have to do that.,EVOLVE
1601,9fdfeff1_f7e446e2,9ba910bb539b0172bab899852692a49d30645a14,a5d6833d77c961ea75488f0992b91d3166424381,nova/network/neutronv2/api.py,1942,"nit: this could live closer to the context=None for context

or

re-word as ""explicitly orphan the RequestGroup by setting context=None as we never intended to save it to the DB""",EVOLVE
1602,3fce034c_90ab9b87,4713b49c8646501957a49b8a7f2e13521a2e0544,a40c7f3e8d06f0bc8918a25b60f73ec2c18add05,nova/compute/api.py,682,"this part of comment is not accurate, image activity is checked in _validate_flavor_image.",EVOLVE
1603,9fdfeff1_aa137a00,2d00da78d5799c9d47fff8ab5fbd68f43ed35b35,33f367ec2f32ce36b00257c11c5084400416774c,nova/virt/libvirt/driver.py,6269,alignment,EVOLVE
1604,9fdfeff1_34a89676,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/network/base_api.py,206,requesting,EVOLVE
1605,9fdfeff1_5c6f2a5f,d78c1dde589b30d8439bb1074720b0033ae74c1a,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1640,nix :),EVOLVE
1606,5fc1f717_bc44edb8,e2352a1c70b5bc491dbcfe87977b0f2c0b907a97,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,nova/tests/unit/compute/test_compute.py,13323,nit: use a named kwarg so people don't need to lookup the signature to see what this is.,EVOLVE
1607,5fc1f717_3fea3873,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4552,compute,EVOLVE
1608,3f79a3b5_d9fdcf70,52d515ba7dbb22433d8fceeafd3bc045aa2781ac,ed4fe3ead62c09ec7de7b6a11072295a99997b4f,nova/tests/unit/compute/test_compute.py,8982,"Something I learned from melwitt: if you add a 'new=mock.Mock'  argument here, you don't need to pass an argument to the function. Maybe useful if you need to rework this.",FUNCTION
1609,3f79a3b5_a0d765bd,5cdb825394f3015ef4b1224eb7d9f55633d217e9,801ef1adca667ecdf243464b083282418d5987e4,nova/conf/compute.py,663,Adding the inventories is a huge improvement.,FALSE
1610,3fce034c_2bd0721f,469d58ed79aca342a2916d0f4f8ffd06df467fe4,a4743f982ac5348d0aa036f3afac530ac7c56ff8,nova/api/validation/parameter_types.py,311,Looks like this is no longer used either. Could remove in a follow up.,FUNCTION
1611,ffb9cba7_552ea043,7906633820107489546a054bf1a6fab78d2737ca,78e742662edd164c46382c31e106884762fed029,nova/compute/rpcapi.py,381,"So, this all looks cool. However, if we fix the SIGHUP thing in oslo.service, this will no longer reset the upgrade_versions pin and/or recalculate the service version.

Even thought we know that's broken, shouldn't we plumb that reset into here, given that what is currently in reset is effectively a no-op, but *looks* like it should do the right thing?

If not (and I'm not sure why that would be), we should remove the _apparent_ re-loading of the compute rpcapi from compute manager's reset.",FUNCTION
1612,9fdfeff1_0d45e9b3,859a0ac11842101c902a98165277175d984c3352,b4a52f8968e657aae83f512d8e165aba9fd7388f,nova/tests/functional/test_servers.py,6271,"tiny suggestion... it might be worth adding these assertions before attempting to access allocations[self.compute1_rp_uuid] and allocations[self.ovs_bridge_rp_per_host[self.compute1_rp_uuid]]:

 self.assertIn(self.compute1_rp_uuid, allocations)
 self.assertIn(self.ovs_bridge_rp_per_host[self.compute1_rp_uuid], allocations)

otherwise KeyError might be hard to reason about in a potential test failure.",FUNCTION
1613,3fce034c_d43d822b,54cde449516bc4823c6be301fd9ad553c63ac388,0b48d9148bbde88bb6b50329f76b6a25db9ac986,nova/objects/instance_info_cache.py,72,"Good call, avoid the version bump.",DISCUSS
1614,bfdaf3ff_78ac238c,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/tests/functional/libvirt/test_report_cpu_traits.py,51,"hmm, this seems out of place in this patch. perhaps this is leftover from a different patch?",FALSE
1615,9fdfeff1_278a4ebb,86fb5fd4fe484838b2d70bcdd914fe04c020a7d6,29e5b0ad7bde210f95885656768f0480d06882c0,nova/tests/functional/api_sample_tests/test_servers.py,433,I still think we can avoid this and most of _test_servers_post by passing extra_subs to _post_server in the base class so we can pass in the sg_uuid for the server create template. I'll pull this down and tinker with it.,FUNCTION
1616,5fc1f717_ef13c263,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,514,"This seems pretty heavy to construct for every request like this but it looks like we don't have much of an option since you need to use the HostManager because that has the enabled_cells cache, right?

Couldn't we just pass a handle to the HostManager into this method from the SchedulerManager (self.driver.host_manager)?

Granted this would only be for each move operation that involves a specified target host and/or node, but still it seems we can easily avoid this.",FUNCTION
1617,9fdfeff1_c4baf7df,99a3823f98c593fd7f0a9e3fe3aab4126f9bb383,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/tests/unit/virt/libvirt/test_utils.py,522,"Should probably also test non-support.

...or have unit test coverage for convert_image and abstract this.",FUNCTION
1618,9fdfeff1_cb6b9b1b,bbfb3bcf792b0d712ec59259479c8701b1e31722,735c2181dc450195454cf4dc62a814ff1679abda,nova/tests/unit/api/openstack/compute/test_server_actions.py,820,"Rather than have to slap this on all of the tests, I would suggest doing the mock in the test class setUp to just always return False. If a test case wanted to override that, it could reset the return_value.",FUNCTION
1619,3f79a3b5_8c3cb4bd,adffd410d665f84d279d686e716bb699e9386594,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,449,"How about documenting the other parameters. For confirm resize, the source node and old_flavor are passed in, but for revert the dest node is passed in and the new_flavor is the default. You don't need to document those here since those are caller-specific, but it does make a difference on what this method does.",EVOLVE
1620,5fc1f717_f4ffbc64,df6a648748802205a60848df3401dcf9a9d15b68,3b4d1303d03e6df57ec28d4d72756bebd62d7115,nova/objects/instance_mapping.py,287,"nit: Throw this in quotes:

'after running ""nova-manage db archive_deleted_rows --purge"".'

Do you also want to mention if there were down cells here? I guess not since we already warn for that above on a per-cell basis.",EVOLVE
1621,9fdfeff1_77aaf271,5a8b0956f6a5e9ca2be4388129de7ca9728cc27b,3548cf59217f62966a21ea65a8cb744606431bd6,nova/objects/request_spec.py,729,s/are appeared in/appear in/,EVOLVE
1622,9fdfeff1_989d22bd,e160cb69d99792049aba8511f3515cae8c8025f7,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/ironic/client_wrapper.py,42,"nit: Should be 38 now since we use it for Rescue. Both versions come from Queens, so it should not matter much.

And then we can remove all explicit mentions of version 1.38..",FUNCTION
1623,dfd5e7cf_2f838ace,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/tests/unit/compute/test_compute_mgr.py,8508,I'd move/duplicate this line above the two asserts at the end of this function to explain what you're trying to achieve,EVOLVE
1624,5fc1f717_e7473e1e,2a8d417913fe32777393e796684d4712e827e2ac,28944d05f3fc415bc294e11202db7810bc354b5a,nova/tests/fixtures.py,2242,"This is really invasive, IMHO. Aside from making people mock out sleep any time they tickle code that runs through a sleep (which I know is the point), it also has the potential to cause us some strange behaviors for code that depends on the sleep yielding to another greenthread.

If we're going to do this globally, what if we replace this with a warning, and an implementation that always really calls sleep()? Maybe call sleep(0) the first time and sleep(0.1) every time after that. We get the same yield behavior, but massively reduce the amount of time we actually sleep for.",DISCUSS
1625,9fdfeff1_c27982c5,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1261,"Also, there is a TODO on get_allocations_for_consumer to use get_allocs_for_consumer instead - why aren't you?",DISCUSS
1626,dfd5e7cf_190e1832,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/compute/manager.py,6749,"Can this ever be False? Far as I can tell, this will always be configured by 'nova.compute.resource_tracker.ResourceTracker._setup_pci_tracker', which is called in every code path in '_init_compute_node' of that same class",DISCUSS
1627,bfdaf3ff_c40e578c,545523a7d25bac319ff6d222ce70632be4d2f33d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_compute.py,115,"the number of failed builds are [0, 1, 10, 100] the formula is: -1 * utils.get_weight_multiplier() * failed_builds. Above the weights is set to 1000 in the aggregate, so I think the result should be [0, -1000, -10000, -100000]. What I'm I missing?",FALSE
1628,9fdfeff1_17e28604,e3b0fab90cd4f236aec663dbda0f2585c1775b53,60a772b4a11512f3d7d591367fc7a1735e4b2515,nova/compute/manager.py,6624,I think it init only when you define the pci whitelist,EVOLVE
1629,bfdaf3ff_63c78147,661dd591c94a9203c1a63e17789b83539a364527,84d94171d93a89af9fc71f6a326a988842c64d5e,nova/compute/manager.py,6751,"As noted at [1], maybe add a TODO to perhaps remove these logic checks in the future? I'll tinker with them myself at some point

[1] https://review.openstack.org/#/c/620115/9/nova/compute/manager.py@6749",EVOLVE
1630,5fc1f717_9951d1db,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,267,This should be more than a debug right? At least warning or error.,DISCUSS
1631,3f79a3b5_512d2fab,d2db53521bd6246629ee46a1c15ccf84732e7717,bc46a5477338274a2db0ef83faa531e7ea0ee13d,nova/scheduler/client/report.py,1877,"I hate deep nesting like this, and would prefer to check for this specific case before the general case of any other consumer generation conflict so they are on the same level. But, this works.",FUNCTION
1632,3f79a3b5_b3cbd945,84825b16f20adfaf9264e5c87d7feaf6480f076e,47ec5327c97c5916d9bc2b319bef8a7196fda60f,nova/conductor/manager.py,750,"ah,  yes, here it is...",FALSE
1633,9fdfeff1_babd8869,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/test_servers.py,2444,Around here is where I'd add the negative test.,EVOLVE
1634,3f79a3b5_24f57052,ee34f58b1ce62dd1e2fc0f750801347ce96776c0,32082ebcfc17fdaf83e8f154ce0045e7a1fed16a,nova/conf/compute.py,656,"Okay, it is reasonable to have just TODO here for now.",DISCUSS
1635,dfd5e7cf_ca4aecaa,9160fe50987131feda9429c4e95d573e176916b6,a8e992b1057a3c0c56478baaf6f090aad87438d4,nova/conf/libvirt.py,465,"nit: could you add a subject/summary line above this. Something like:

  Use native TLS encryption when live migrating.",EVOLVE
1636,3f79a3b5_29b64e28,67fed7cc2d42e611e278b4a09fb0887ae8314aa4,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/objects/compute_node.py,197,Should probably add a comment about the logic here.,EVOLVE
1637,dfd5e7cf_41afd5e2,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/pci/request.py,215,Do we want to fail in any way here?,DISCUSS
1638,dfd5e7cf_e7cb8fa2,5b2021575a618d603685b97b694934c857e6f9c6,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/privsep/qemu.py,25,It is not necessary.,EVOLVE
1639,9fdfeff1_c3da0878,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,125,the requested target_host.,EVOLVE
1640,9fdfeff1_09213dfd,64d1984c85c040fcb62f803986f929ce80564aeb,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/api/openstack/compute/servers.py,857,"Hmm, where would we hit this from resize? It looks like this is raised from get_pci_requests_from_flavor but I only see that called in the API from _validate_and_build_base_options which is only called from server create. Should we be calling that from the resize flow to validate pci requests in the new flavor?

Also, it looks like get_pci_requests_from_flavor can raise PciInvalidAlias but we don't handle that in the API anywhere, unless we handle the base class (Invalid)? Also, does that mean the pci alias configuration in the API service has to be the same across all of the compute services? Because that seems wrong.",DISCUSS
1641,5fc1f717_9f7d6cb3,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4576,"Comment this out in this patch, and uncomment it in the patch where the bug is fixed.",FUNCTION
1642,bfdaf3ff_8399456f,661dd591c94a9203c1a63e17789b83539a364527,84d94171d93a89af9fc71f6a326a988842c64d5e,nova/compute/manager.py,8361,"nit: maybe

  ':'.join([pci_dev.vendor_id, pci_dev.product_id])",FUNCTION
1643,dfd5e7cf_8c8adf18,4e1f6b1c1a15fd6aa31d8100626d771563a06b3d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,38,this apreantly does not exist which is why all the gate jobs failed,FUNCTION
1644,9fdfeff1_d3f632d9,bea316d479750452a42295d9980d9dac5a89934e,f5d236f868a598f8f241df759c516ec49e3779b0,nova/compute/manager.py,2096,This is another huge method. It would be nice to throw your logic that builds the dict into a private helper method and call that from within here.,EVOLVE
1645,ffb9cba7_3415249d,fd8fdc934530fb49497bc6deaa72adfa51c8783a,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/conductor/tasks/live_migrate.py,343,U release,EVOLVE
1646,5fc1f717_9d6f8ac4,febf6db11d2e6c5fc023c3b9ce713696411e78fc,c7db20d140eb0d3ccf0fd107eda7e80275bdd7d4,nova/virt/ironic/client_wrapper.py,107,Nit: prefer parens over backslash,EVOLVE
1647,9fdfeff1_5a68d71b,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/objects/migrate_data.py,158,?,EVOLVE
1648,5fc1f717_d9abd9d3,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,280,This is another potentially large amount of UUIDs if let's say 500 instances have been deleted but the db archive/purge hasn't happened yet. I would probably just drop this logging since the orphan warning below is the more useful one.,EVOLVE
1649,3f79a3b5_3c8f0723,fae92384a3d2d3299f7e25419b16ec7534f9233a,8d089111c8554e94e117ada3a7f51a42df59e84f,nova/conf/compute.py,652,"Can we just make the default 0 for new installs? To Jay's point, we might not really need the aggressive caching at all, and in a 'normal' environment the inventory on the host shouldn't be changing that often - they can restart the service (or SIGHUP it) if it does I guess. The default should match the normal case, in other words. That would require an upgrade reno, but that seems OK.",DISCUSS
1650,5fc1f717_f804ef16,a3d33f2d34e0c793fb0c1e07181322d98da1707d,2529ddfbe7940e90548175d6e2032383c38cda8f,nova/cmd/manage.py,1877,"I get why you wanted to add explicit `else`s and indents, but why did you need to invert the order of everything? IMO changing `if X and Y` to `if not X or not Y` is a backwards step clarity-wise; and it also makes for a bigger and harder-to-grok delta.",EVOLVE
1651,9fdfeff1_9b02ea3d,3ef55e43d56ce66e003c934f4a5c83e787aca7b3,f58cdcd58dc555b5b8635907987510f4970eae58,nova/objects/request_spec.py,602,You can just add ignore_hosts to this tuple/generator/thing.,FUNCTION
1652,9fdfeff1_2344341b,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,161,the,EVOLVE
1653,ffb9cba7_e2658ae2,74cefe4266a613d4c2afbb0c791e16eb7789aef4,a991980863f056323c1ee9fd6a46dbc4cb899eca,nova/availability_zones.py,127,"sure, it's just a unrelated tech debt fix",DISCUSS
1654,5fc1f717_04a57fb5,d2f89951039e99c7ab4aa11bea5464004265c76b,f58f73978e3c533304b06a4d1eb6abe3f229bc10,nova/virt/libvirt/utils.py,549,"fine, we will then use the default one.",FALSE
1655,3f79a3b5_33ce1fb7,ffc7d694de1aca84e46de3b4dfbc19d056aacf90,48beae986f0ec7845ac5b0138d8d2c085d87e9ae,nova/quota.py,980,Document this in the docstring.,EVOLVE
1656,9fdfeff1_9b851c5c,4178fb0d2e4a1033156826fda16ed01f9af8acf4,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/api/openstack/compute/views/servers.py,350,"in the spec, we don't have uuid field http://specs.openstack.org/openstack/nova-specs/specs/stein/approved/show-server-group.html#rest-api-impact?",FUNCTION
1657,3f79a3b5_8e947643,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,ec044885ff2c44202cc62cf85149b7993d4d0221,nova/scheduler/client/report.py,1597,"again, I think this MAY be a bridge too far for Ironic nova-computes...",FUNCTION
1658,9fdfeff1_52d685f4,624235fb015166856895e48869008bc6190fa430,b0f795e512416e3934a7e2663f22998f62248cba,nova/network/neutronv2/api.py,1045,"Missed this:

https://review.openstack.org/#/c/616240/32/nova/network/neutronv2/api.py@1039",EVOLVE
1659,9fdfeff1_6aab08d6,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,834,partition,EVOLVE
1660,9fdfeff1_73284f85,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/network/neutronv2/api.py,1415,as above,EVOLVE
1661,9fdfeff1_2a9f8a02,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,116,You could loop over server1 and server2 for this right? The allocations should be identical.,DISCUSS
1662,9fdfeff1_93750a35,2fa9f42ca71e03eaa2c5b9be31624e367d862c77,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/virt/libvirt/driver.py,6321,weird spacing,EVOLVE
1663,9fdfeff1_4247d278,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/conductor/manager.py,1264,We should make this a public method now yeah?,DISCUSS
1664,9fdfeff1_7c37254f,27617ee1931b3240dbd0ad4c7d8ffd64cc202bc9,bcc4d233efceb98d3799f3ee339a5fe9a55aa266,nova/rc_fields.py,15,This is the only non-rebase-y difference from the previous PS.,FALSE
1665,9fdfeff1_c3ea0dab,1cc6525996cc2e2b98d449c790320f131f097c96,f6996903d2ef0fdb40135b506c83ed6517b28e19,nova/objects/instance_mapping.py,265,newer?,EVOLVE
1666,9fdfeff1_daa4c2a8,135889d8b5991ec249a31767f5a11fd89908e38f,f2983a49f8be40b5f6f5572988fdb22f2d423c8b,nova/objects/request_spec.py,821,ListOfUUIDField?,FUNCTION
1667,9fdfeff1_607b857a,3fbf336a38556db1fce2e9744a3c9712bf463614,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,36,"This misses the 'nt' condition from nova.utils.monkey_patch which is needed for hyper-v on nova-compute.

i.e. you've regressed I8b456676a04b9066cb2b570060c0d95cd4fe69f8 here and below.",FUNCTION
1668,9fdfeff1_d8cb9d6f,fc962b62d4202d76f2c04166c97ace9d31c21e18,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/functional/db/test_virtual_interface.py,57,OK this creates the first compute service in cell1 which is why you have compute2 in cell0 below (which isn't really something that would happen [computes in cell0] but is convenient for your test).,FALSE
1669,9fdfeff1_5aac9c34,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/test_servers.py,3048,Does this test need to use force? It's not clear from the docstring.,DISCUSS
1670,5fc1f717_cf3db9bb,2233d69fdb89f3b146553c059de57cd425bc29f8,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/scheduler/utils.py,246,This line must be 79 characters or less.,FUNCTION
1671,5fc1f717_840c2a3c,229274154a6eca929981d2f43539bc491b13327e,926e584136e7dce59f32065292aa4eb8120f628c,nova/monkey_patch.py,55,"if we create a module level global flag so that this execute only once i think it might solve your issue.

my teroy is we try to monkey patch twich in the docs job due
to one of the shpinx extention loading both the test and non test code paths.",EVOLVE
1672,5fc1f717_9e031bbf,ff53c454276824112c45516153d0a6629b2ab658,9b121e3c37442cd12d3465928c36b93b09e916da,nova/scheduler/utils.py,551,"Why do we need `else: pass`?? I went and looked at the patch where this was done [1] and there's no indication. If we just need a vehicle for the ""source allocations were provided"" context of the comment, it seems like there are better ways.

[1] https://review.openstack.org/#/c/583667/",EVOLVE
1673,5fc1f717_178437d2,73aaead294b9df412305abb1cb01aac95477bcc1,ca7cb9eeb7192f4320c95e2e323886627963f10d,nova/tests/functional/test_availability_zones.py,173,"To prove the bug, this should have asserted the value in the db is wrong.",FUNCTION
1674,5fc1f717_791bc51a,1b36de08ada2b482d803c16f6436322513d46e2b,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/tests/functional/db/api/test_migrations.py,730,"You can also add something like this for the two new indexes:

self.assertIndexExists(engine, 'resource_providers',
            'resource_providers_root_provider_id_idx')
        self.assertIndexExists(engine, 'resource_providers',
            'resource_providers_parent_provider_id_idx')",FUNCTION
1675,9fdfeff1_0d79c0fa,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/tests/unit/scheduler/client/test_report.py,3608,"This can just be return_value since the response doesn't change, right?",EVOLVE
1676,ffd0ebdf_b22df5a9,04acda84be2866c38943132f4e1b394df91ae897,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/scheduler/utils.py,1049,Seems we could just re-use nova.scheduler.filters.utils.aggregate_values_from_key for this processing logic.,FUNCTION
1677,9fdfeff1_c93542dd,48d6753d37c0ef1ae5aa1ec9b5b369869ff8905b,ffd81eb107dd04d05f828e9e049320412c576e1b,nova/virt/libvirt/config.py,315,"it's actually per domain *type*, no?",DISCUSS
1678,3f79a3b5_67155895,bbc2fcb8fb20dde1b81597c319392afb5b2c53fe,8c318d0fb20fdfe0ae8e203245e4d4d6668c8a44,nova/scheduler/client/report.py,701,And here we'll do our refresh dance.,FALSE
1679,5fc1f717_06d93981,bd6c5b0416ce2d95849b65217748933a176a31a7,b63c42a0d4836fd0364cb306145d3474619f1e19,nova/tests/functional/test_servers.py,6736,"the `_fill_provider_mapping` doesn't raise this exception any more, since this patch https://review.openstack.org/#/c/638711/10.

And I just merged the previous patch...",FUNCTION
1680,9fdfeff1_6a0a728a,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/unit/virt/libvirt/fakelibvirt.py,1522,You don't need this else or the indent since the condition above returns.,FUNCTION
1681,3f79a3b5_e5e1f2cf,801ef1adca667ecdf243464b083282418d5987e4,2b97e508381e7f1efe48799ee3d9b068b4fd5902,nova/scheduler/client/report.py,681,"and of course if either of this doesn't happen, then means rp is not existing so we create it,",FALSE
1682,9fdfeff1_ff048bc8,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,2944,ditto,DISCUSS
1683,3f79a3b5_e894b099,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/migration.py,400,should update this,EVOLVE
1684,3f79a3b5_a7735b50,8cdd57d91088ffc1d6f8ca60b5fa0dc3ec822bd3,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,440,nit: I would reverse the option usage here - you have to hit live_migration_completion_timeout before live_migration_timeout_action is used.,EVOLVE
1685,9fdfeff1_8085e0b0,0b56cdeb8a438246d45cbf5117f3cbbf4ba9355d,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/objects/instance_mapping.py,89,"Hmm, why try this last? The cell is going to be the fastest option right? Especially if you add a Instance.get_user_id(instance_uuid) call, you'll query out just that one thing and avoid the expensive JSON loads of the above. If the cell is down/disabled, then falling back to the JSON-based structures above is maybe worth it.

From skimming the patches above, I'm guessing you're just going to end up doing this for every instance sequentially which is going to be a really ugly performance hit. You'd gain a lot by being able to batch a bunch of these, but I guess it's just a hit until the migrations are run.",DISCUSS
1686,9fdfeff1_510acc89,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/conductor/manager.py,498,"Again, we should know the user_id long before scheduling.",EVOLVE
1687,9fdfeff1_7ff89bc3,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/virt/xenapi/test_xenapi.py,1143,ditto,DISCUSS
1688,9fdfeff1_18d8d71b,34a27619a02cf07b96ec3c39d1b6f2b99ebd3a3d,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/network/neutronv2/api.py,3012,Use items() instead of iteritems() because iteritems is not supported in python 3.,FUNCTION
1689,5fc1f717_a70491c7,a7888d13fb01f8b493ac4174bf6011c3e991b124,59f1f187e5dceb5841a711f265280346d70a972b,nova/monkey_patch.py,93,Why is this giant if block not in a function we call if the variable is set?,EVOLVE
1690,9fdfeff1_c9e71e12,684e4ffc522c6e0f6079308274b1899046e45120,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/api/openstack/compute/servers.py,399,nit: I was a little confused because this doesn't contain the chage  related to v2.69. It would be nice to contain NOTE/TODO for next patch.,EVOLVE
1691,9fdfeff1_9914d6ea,cd2fe293354b617e17909001c0ce8bee3b27532d,bcfd2439bab7cfad942d7e6a187df6edb1d1bf09,nova/virt/libvirt/driver.py,6288,This is pretty bizarre. But I guess it's as good as any other way of picking an arbitrary item out of a dict.,FUNCTION
1692,dfd5e7cf_41dd956e,0582b9f9e41075fceb09e89290909b8fe01869d1,18b4859568243f193a7ed36b197436ea158c921a,nova/tests/unit/pci/test_request.py,88,nit: Guess we could do and store this in the setUp too? Much of a muchness,EVOLVE
1693,5fc1f717_157c3cea,3b53e1a1f177d1eedf329dd525a613b1f1ae22d1,9fab7e73e31bac3cab26c5aaeb773054ee917161,nova/monkey_patch.py,50,"I don't think this is required if we're getting everything patched before any oslo_context loads. The reload was specifically working around the issue of having imported this module before the patching could take place because of the existing layout.

I think it's safe to remove this and we probably should for clarity, although I don't think it's technically hurting anything other than performance.",EVOLVE
1694,9fdfeff1_cd55f8c3,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/scheduler/client/report.py,1712,"Is this really what we want? If we're trying to remove resources from the allocations for the consumer, and the consumer already has no allocations, then why complain about it? Clearly we just lost a race but the end result is what we wanted anyway.",DISCUSS
1695,9fdfeff1_c5660352,1aca2efd1f6fe2a65383deec68c964c90068f426,ba39214197efc45cd634ab0476393b7ce1548e26,nova/tests/unit/pci/test_request.py,276,This should be flavorid.,EVOLVE
1696,9fdfeff1_f26094a7,c4c6e0a8942af963a681f95176f41b8078e41b36,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,185,"this needs to go inside the if condition on L155 (like after L176). Since we are only exposing this via server show and not via server list, there is going to be this extra unnecessary check for the whole list of partial servers during listing from details() which will anyways be False always. So its a redundant check while listing servers.",EVOLVE
1697,9fdfeff1_92ec7af5,19cb8280232fd3b0ba0000a475d061ea9fb10e1a,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7559,Ã¢Å“â€,DISCUSS
1698,5fc1f717_caaa3918,fbbe7694a0d4c80db5da5f90d46bd3e13a8c5276,6304bcf781441ff9845bc78740f3b9919b5a4264,nova/scheduler/utils.py,319,be satisfied,EVOLVE
1699,9fdfeff1_cf229052,3f46eb1d971fddd98cbde2ce9ff3f11687c00e7b,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,154,"Move this to where it's used (within the ""if show_server_groups"" conditional below).",EVOLVE
1700,9fdfeff1_a3472da3,84feb23cfd88ad15b8a2313aba6e2f569b3400bc,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,nova/tests/functional/libvirt/test_reshape.py,108,"You get them out of the database:

ctxt = nova_context.get_admin_context()
instance = objects.Instance.get_by_uuid(ctxt, server['id'])",FALSE
1701,9fdfeff1_b7693a27,a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2178,++,DISCUSS
1702,ffd0ebdf_e8038c0e,bb857a4b386b4ee29654b12ce849c727ba5ee680,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,207,and here,EVOLVE
1703,9fdfeff1_388bc91f,fc962b62d4202d76f2c04166c97ace9d31c21e18,8ef3d253a086e4f8575f5221d4515cda421abea2,nova/tests/functional/db/test_virtual_interface.py,82,"I believe this is safe because of the ""ORDER BY ID ASC"" in CellMappingList.get_all and cell0 is created first in the test setup.",DISCUSS
1704,5fc1f717_4973aee8,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,251,"Repeating this from PS17 since it looks like you didn't see it:

Hitting this in flight should be relatively rare I would think so it might be worth logging this instance mapping as not having a cell yet during the migration. I'm thinking about stuff like where mnaser has seen some weird things where an instance mapping doesn't have a cell but the build request is gone. So if I were running this over and over and over and continued to see 'found' results but nothing 'done' I'd want some logging, because if that's a persistent issue we'd have to consider trying to lookup the RequestSpec to fill in the user_id here.",EVOLVE
1705,9fdfeff1_0f16064b,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/tests/unit/compute/test_compute_mgr.py,6661,actual vendor/product IDs might not be a bad idea,EVOLVE
1706,3fce034c_e48a6919,7fb4515666333118c2a8ffb9ecda72b3c5543494,d569ade1703bd5811eea8dd987ecd84bd0337fac,nova/compute/manager.py,7185,"i dont think the intention is that the virt driver is not allowed but the other way around, in case the virt driver(aka compute driver) manages port bindings, the compute manager should not intervene.",EVOLVE
1707,9fdfeff1_93cb40a2,29f9febba714e1e331ecbdbc077606603dfc3ca5,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1679,"OK so I guess we are now marking these for translation. That's fine, I just don't think it's necessary if these aren't user-facing. Nova doesn't really get translated anymore.",FUNCTION
1708,bfdaf3ff_9eb51ad0,7cb53a855a0490a836f90ad4cb945e5bcd83c753,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/api.py,539,I don't see any other place handle this like this.,DISCUSS
1709,3f79a3b5_2d139ab3,1a38ae6bc3e4a2d0369731ed7f906cc2426b7dce,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/virt/libvirt/migration.py,397,again,EVOLVE
1710,5fc1f717_3d2ee98b,107c95fc5bae36e8e9f5e98a65ae0e4043ddb26e,3548cf59217f62966a21ea65a8cb744606431bd6,nova/compute/flavors.py,97,"This case is tested with test_create_invalid_name, fine.",EVOLVE
1711,3f79a3b5_273fb2b3,6fea14020bf7246bfcb2c7b2dcb71b680e9a0aa0,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/tests/unit/virt/libvirt/volume/test_net.py,153,and username,EVOLVE
1712,5fc1f717_cb73fae6,30295f1a141bb10f69f39c7ba453c7162db926b2,a7fae371a7fc48a778b2d632b1b90bf5659eda7d,nova/pci/request.py,208,"Ã¢Å“â€ thanks for adding this

technically, there's no unit test corresponding to this conditional, but I'm OK with that..",DISCUSS
1713,5fc1f717_3d543254,1f1644bf117b466844251e8580453bc9eb70e8de,a2d7ffba32585cce3da2212edc026be66d4ede66,nova/compute/manager.py,6214,"or just:

 objects.LiveMigrateData",FALSE
1714,bfdaf3ff_59acbe8b,ed5362d09f655e8f04d0f9ccae22f9c4480a852c,c9ac27f1bcf81d0cf8a06414edcafc3a9068ae1f,nova/compute/manager.py,7678,"Remove this comment, which refers to a time when we had a ResourceTracker instance per baremetal Ironic node.",EVOLVE
1715,9fdfeff1_f3d8231f,a59198ae4940f27551166cbaeddc8ceedb20ff24,430baa37bf961e5a5bc1fa1956e13c52000150fa,nova/compute/api.py,2189,Why are we changing this portion of code to update user_id also when an instance gets deleted ? Wouldn't the migration take care of all the existing mappings? And you are updating the user_id on L950 before saving the mapping for those scheduling case. Not sure why we need to handle the delete scenarios,DISCUSS
1716,3fce034c_e162a516,80f552267ef8e69d9f4ce7ebed1788b24351d500,fc9c0e8703004ae206071d820c07e3cd701baf0e,nova/tests/unit/compute/test_compute_api.py,6857,I am quite offended that you changed the order of these tests.,EVOLVE
1717,9fdfeff1_16b44c35,df723adab02d84229b17cd57ae3b24704b1a69f2,ee57c92e8b675adf3f35de29f7cea9c9d042d44b,nova/compute/api.py,3575,We probably need unittest ensure resize calling this check.,FUNCTION
1718,3f79a3b5_6c5a781f,adffd410d665f84d279d686e716bb699e9386594,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,453,"I think for a resize revert, where the claim was made on the dest to start with:

https://github.com/openstack/nova/blob/c1de096098344c733565c244163fc3ebf8c35e68/nova/compute/manager.py#L4182

Then this would be true and we'll decrement usage using the new_flavor from the dest RT. That all makes sense to me.",FUNCTION
1719,5fc1f717_8e042519,cbfa45f257381b50104d78083bccc9e410e2d3db,afbe4abba881c75fef2d4ef864334d5d91181d8c,nova/objects/instance_mapping.py,253,This could be like 1000+ UUIDs right? That would explode the console output. Seems like this is something you'd want to actually check when populating inst_uuids_by_cell_id above so you can log which instance mappings don't have a matching cell_id.,EVOLVE
1720,3f79a3b5_855c6258,256e35fe49da9d3dac430c3b92d6ed2e5c500a12,ae3064b7a820ea02f7fc8a1aa4a41f35a06534f1,nova/conf/libvirt.py,441,"Not even if ' live-migration memory copy iteration does not make percentage increase of at least 10% over the last iteration,' ?",DISCUSS
1721,5fc1f717_dc3d392d,e2352a1c70b5bc491dbcfe87977b0f2c0b907a97,5e7b840e48eb480ba1955e6ba52fbcaf9884c3fa,nova/tests/unit/compute/test_compute.py,13308,Do we really need a new test class for this? Just throw a new test into nova.tests.unit.compute.test_compute_mgr.ComputeManagerUnitTestCase.,EVOLVE
1722,9fdfeff1_33369e53,2fa9f42ca71e03eaa2c5b9be31624e367d862c77,8e9fa1ad1e55a2b40e4c74f4c64a042a829b36a5,nova/tests/unit/virt/libvirt/test_driver.py,20628,Does it have to be totally bogus? Would we be testing the same code path if the other provider had a validly-formatted name but represented a different PF? I would have thought that was the interesting case here.,DISCUSS
1723,9fdfeff1_a72850ee,0b1548a988cdded059700bb27963a8149e65480a,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/virt/libvirt/driver.py,5018,"Asked this on IRC but I don't think I got a proper answer (or I didn't grasp it). We're removing this (or rather the 'sclplm' console above) because it doesn't actually work, right? If so, should this removal be done in a separate patch before this one since this is likely also broken on master under certain circumstances, no?",DISCUSS
1724,9fdfeff1_72006903,c5fc1126d9ff8b016d83c2026de7ada10df64cbd,b0f795e512416e3934a7e2663f22998f62248cba,nova/compute/manager.py,5975,"Alternatively you could refactor this cleanup code to a helper method that deals with the allocation deletion, then the caller doesn't need to handle that explicitly. It looks like the only difference between it being used here and in detach_interface is if deallocate_port_for_instance raises something we may re-raise it, and we could control that with a kwarg to the helper method.

That could be a follow up though.",EVOLVE
1725,dfd5e7cf_99ec482a,e27c9c6eb25ced5403c2f9f203c9d5b84b865ddd,0582b9f9e41075fceb09e89290909b8fe01869d1,nova/objects/migrate_data.py,160,nit: unnecessary (no need for a Hungarian notation variant here),EVOLVE
1726,3f79a3b5_d75d7ae5,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,181,"rather than link the bug, which should be in the git history via the commit message, just summarize the issue - the instance to which the pci device is allocated may lose it during a reboot, and/or the scheduler may try to allocate the device to another instance which will fail.",EVOLVE
1727,3f79a3b5_3a941535,7e1378773495b90b94bea91ad4bd5cf7d7a08c6c,08f3ae960623c94bdd997cacb3e81f04b4bbba69,nova/tests/unit/objects/test_compute_node.py,589,same,FUNCTION
1728,3f79a3b5_975ce2ef,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,177,:,EVOLVE
1729,9fdfeff1_03e1f5d0,1cc6525996cc2e2b98d449c790320f131f097c96,f6996903d2ef0fdb40135b506c83ed6517b28e19,nova/objects/instance_mapping.py,264,Shouldn't this be NULL for older instances?,DISCUSS
1730,3f79a3b5_19f9161a,4224afc5850e7969ff3df3e1218aebfffc8887f3,ed4fe3ead62c09ec7de7b6a11072295a99997b4f,nova/compute/api.py,4492,This 'if' can be removed.,FUNCTION
1731,3f79a3b5_1320aaad,3e32e76d83a15bc7bb43aa41c1fefc2ea15d7176,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,451,"nit: it's not really the host (as in the nova-compute service host), it's the compute node, which could be different (if this were ironic migrations - which aren't supported today - you'd have 1:M host:node so it makes a difference).",EVOLVE
1732,3f79a3b5_fc2eb68b,5187ea57e9f3b45972813a63fa81323b928b3498,5a101e1417f492a549b0403f6fa61f5e55582f43,nova/compute/provider_tree.py,350,"i would almost rename this to remove_subtree but that is probably a separate patch.

i get that this is actually removing a node in a tree and the fact that the children of that not is removed is just a  required side effect but with the more explicit naming of remove_tree the symertry would be nice.

that said that would be noise an obsure what you are actully changing but maybe add a todo?",EVOLVE
1733,5fc1f717_c74c6f78,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,271,"Heh, or just ""if done >= max_count; break"" but ... sure :)",EVOLVE
1734,3fce034c_3f38a13b,02b26457f3c5773973f374f39e069d2a854e99f6,03322bb517925a9f5a04ebdb41c3fd31e7962440,nova/tests/unit/objects/test_request_spec.py,993,ditto: 1_1,EVOLVE
1735,5fc1f717_996a317e,1b36de08ada2b482d803c16f6436322513d46e2b,14c4c8040ce7b3180c2ff2ef1513a30c94805e41,nova/db/sqlalchemy/api_migrations/migrate_repo/versions/062_instance_mapping_add_user_id.py,30,"there is no need for an index on just user_id if you have an index on (user_id, project_id) below because of the single-column index will prefix-match everything in the multi-column index.

The idea was to have a (project_id, user_id) index that would solve queries that used both project_id and user_id and a single user_id index for queries that only used user_id. There is already an index on (project_id) alone (https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api_models.py#L134) therefore a (project_id, user_id) index would make the single (project_id) index redundant.

So, it's enough here to just add one multi-column (user_id, project_id) index.

That said, that index would not be able to satisfy queries such as ""get me the number of distinct users that have instances in each project"" because of the order of the columns in the index. Not sure that is actually something we will want to query for in the future, though, so for now, just one index on (user_id, project_id) is fine.",DISCUSS
1736,3f79a3b5_a79982ce,47b7c4f3cc582bf463fd0c796df84736a0074f48,905e25a63d3ba25cfbdf492891ac8864fed609ab,nova/virt/libvirt/volume/net.py,90,"We should update this queens mention as well, but I'll do that in a follow up.",EVOLVE
1737,9fdfeff1_5ba6d411,4178fb0d2e4a1033156826fda16ed01f9af8acf4,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/api/openstack/compute/views/servers.py,343,just right 'show_server_group' instead of 'show_server_group is True',EVOLVE
1738,9fdfeff1_5f6a7780,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,2870,ditto,DISCUSS
1739,9fdfeff1_04cae34c,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/conf/compute.py,843,"I was wondering if we should actually put the server into ERROR status on rebuild since there are some cases where we can fail in rebuild without actually touching the guest, but this isn't one of those cases and ERROR is correct because with the default rebuild implementation, we'll detach volumes and then destroy the guest before calling _prep_block_device which is the thing that would raise TooManyDiskDevices - so in that case the guest was destroyed and the instance should be in ERROR status.",DISCUSS
1740,9fdfeff1_ce5ebf75,bf24d9e3a92aaa23757eed66fd27d572a61f38bb,1bfe04684c271e83636bcdaae363daefadd0cb9f,nova/tests/functional/api_sample_tests/test_volumes.py,336,"I have to admit that this lost me.

At first I thought ""Ah, he'll override _get_vol_attachment_subs() in his class and add tags that way"" but you aren't.

Also, how did this ever work before? VolumeAttachmentsSampleV249 does override _get_vol_attachment_subs, but before you changed this that method was never called, it was just hardcoded to {}.",DISCUSS
1741,9fdfeff1_7174b036,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/scheduler/client/report.py,1674,"ick, as above.",FUNCTION
1742,9fdfeff1_05b16b44,ba39214197efc45cd634ab0476393b7ce1548e26,6c239c2390799fef03ba4f7d00762a4a96f62819,nova/virt/fake.py,199,nit: this could be combined into so we only loop over vifs once. And maybe add a comment that we track interfaces here so detach_interface() can be used on interfaces provided when creating the server.,FUNCTION
1743,9fdfeff1_f416f258,7d9e3882e1a54ce421c36380817a1f619ccf250d,1948ce59c06aacc3fb9a71cbf8b099db8467da01,nova/pci/manager.py,353,the above makes no functional change to the code at all...,FALSE
1744,9fdfeff1_64640f23,3885bb228a7eea6e14dbea21d3c14d45068364e2,6489f2d2b44827d133dad9a3bb52436ee304a934,nova/compute/manager.py,1600,Putting the docstring on the driver interface would also be good.,EVOLVE
1745,9fdfeff1_6c4cd7c7,1c948c7a247221a7c9f2e6bfb89ae1144d8bf3bc,657439ec6d86324d1aef73de0cb76aa8cc4467bc,nova/objects/instance_mapping.py,235,"Can't you use scalar() here to clean this up a bit? I've used that in nova-status upgrade checks:

https://github.com/openstack/nova/blob/eb93d0cffd11fcfca97b3d4679a0043142a5d998/nova/cmd/status.py#L85",FUNCTION
1746,3f79a3b5_930d9a40,3e32e76d83a15bc7bb43aa41c1fefc2ea15d7176,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,460,"The description here is a bit specific to resize, but it doesn't necessarily have to be (cold migration would use this as well but the flavor doesn't change). Anyway, it's a nit - this is fine.",EVOLVE
1747,3f79a3b5_c290bef5,5c21a00e89539bbb271ccfa05e4a2ba1cddae58e,90b96170d3f269165f649e8b61739cf31ffb78b8,nova/image/glance.py,485,"Seems that this erroneously drops the third argument, breaking the rbd backend, see https://bugs.launchpad.net/nova/+bug/1803717",FUNCTION
1748,3f79a3b5_042bdbe9,073c330f52dfa535e6f787f5bb2fc8ec52f1be9a,514eaaef12dad2460fd4c2fffdc05a3db0490711,nova/compute/resource_tracker.py,809,"(thinking out loud again) this will be true only when there wasn't a compute node record in the database, so when the nova-compute process runs, then stops, then runs again clear... won't be called",FALSE
1749,5fc1f717_4d199986,38f2ce549ce4b21d5085824df701f9d2392b5604,047f8c71c2bc45e4a2c00394f23cd953236f6050,nova/cmd/status.py,217,"yeah. Fortunately we don't have a large size of magnitude for the number of cells.
That said, I guess we could *later* (eg. if needed more than once) provide an argument to the get_all() object method so it wouldn't need to loop again :-)",DISCUSS
1750,5fc1f717_7388f870,56541244fd4931c88cc17771c18e2e72ae9356eb,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/virt/libvirt/driver.py,8451,"As best I can tell, this was running with an implied cache mode of ""unsafe"" and will now be running with ""writethrough"" if directio is not supported on the filesystem. I think that's probably a win for correctness (as well as the obvious win for consistency), but just noting here that it does mean that this is not just a no-op for the non-directio case.",FALSE
1751,9fdfeff1_978391cc,d0d51a653a25a651e204b940957d0eb3c85798e5,db5c52b9d8a87ea56907f072bf2b853eecdc36b4,nova/network/neutronv2/api.py,1533,We could have avoided this semi-redundant check by storing a variable from the check on L647 and simply not call this method based on that value.,EVOLVE
1752,5fc1f717_7f3520f6,7593ddcdab4022299476d2ed6d39774fca49b579,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/unit/scheduler/test_utils.py,127,This also fails the test until the bug is fixed. Either you do a similar thing that I suggested for the functional test. Or simply move this unit test to the bugfix patch as on reproduction functional test is enough for this patch.,FUNCTION
1753,5fc1f717_fc77d53a,edc130bc226e0e073b9fa102e8e77d6ba0834440,64f6cbc9120e3c288f312eddc59452dee4998f93,nova/tests/functional/test_servers.py,4569,same thing here: we need both positive and negative assertions.,FUNCTION
1754,bfdaf3ff_4212a95a,b19c2b7ccacfe3c464d1512049b0d2bc64b81350,5f9c8b45ffc5c2b9da5e3da6f2b4214b391d9900,nova/compute/api.py,635,"maybe add a comment here indicating that we don't actually care about the results if no exception is raised, we're just checking that the image/flavor are reasonable and compatible.",EVOLVE
1755,9fdfeff1_001c9d68,2f77e7ad90300458f4cdaefabb8e62aadec6c5fd,deef31729bd54f3747b7adba4132f148559c2242,nova/tests/unit/scheduler/client/test_report.py,2894,reset_getter_mocks,EVOLVE
1756,9fdfeff1_fa0aeb76,3c9073f39dd5f7af3c3701ebcbaa3a652844d3fb,39f7e163c027a7f561a07651484b4bef07035174,nova/network/neutronv2/api.py,3223,We should probably define this as a constant somewhere. I see LIVE_MIGRATION in nova/compute/instance_actions.py but that's something different,FUNCTION
1757,9fdfeff1_3bc6874b,603c4cccc12dfad345d5552dc6ad5a206240a640,7f92674a80c8d76749067e86363370814b7f0429,nova/tests/unit/network/test_linux_net.py,1158,ditto,EVOLVE
1758,dfd5e7cf_a11edcb7,fe9f22745940a389331e640db637a4fd10e36544,1351f031b86418b49ea9fae82856e6b3e84cd1ce,nova/virt/hardware.py,643,"for small pages and or a pagesize value of ""4"" or ""4k""

you should also be passing false to host_cell.can_fit_pagesize or over subsription is still broken when you use explcit small pages.",FUNCTION
1759,3f79a3b5_4d6b481b,10ca429a62431078cfd476255ddfe07fc3179b7d,f13debf2f0e5377b9d0b0bbd9422c6a79d2cc611,nova/quota.py,885,"nit: I guess

        for resource in resources:
            self.register_resource(resource)

could be easier to understand the code, but that is not matter.",FUNCTION
1760,9fdfeff1_3157d5cc,c2331d692445796d604d27d2388309f2eb545d31,e3c24da89aa3e6462f1b07e00659c87f252ba4ba,nova/tests/functional/api_sample_tests/test_servers.py,443,"suggest rename to test_servers_get_include_server_group, overwise it is a little bit confusing, but no big deal on this I guess",EVOLVE
1761,9fdfeff1_2ab8ea72,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,123,Would be nice to define a constant for this in fakelibvirt so people looking at this test know where it's used.,FUNCTION
1762,3f79a3b5_2e93585c,b5f5da43032f1d7c4e57c2aa6ab3da526d03bf51,3b2e42f37152a539472782ad1d71c1f951c0343b,nova/api/openstack/compute/flavors_extraspecs.py,121,"Each of these things can be set in both the flavor and the image, so it doesn't make sense to validate the flavor by itself.  (You could have a flavor that doesn't make sense by itself, but when combined with a particular image it does make sense.)  So we need to test these things somewhere we have access to both the flavor and image, like in _validate_flavor_image().

If there are things that can only be set in the flavor then it would make sense to validate them here.",FUNCTION
1763,3f79a3b5_46e26238,d2db53521bd6246629ee46a1c15ccf84732e7717,bc46a5477338274a2db0ef83faa531e7ea0ee13d,nova/scheduler/client/report.py,1871,"I'm not sure why it wouldn't be okay just to retry *any* time we get the 409. If we don't think it's acceptable to retry on some random update to the allocations, why is some random deletion of the allocations acceptable? The theory being that there may be random deletions of allocations that aren't because of this specific race condition.",DISCUSS
1764,9fdfeff1_7a45e06f,678bccc2f69e8e8972c933e4ddf566fcb28385c3,c1fb445b8d94e69d7878fad60c4653650052313a,nova/tests/functional/test_servers.py,5142,"nit: here and above, rather than pin this for the entire test, we could do:

with utils.temporary_mutation(self.api, microversion='2.67):
    self.api.post_server_action(server['id'], post)

And that could be done in a private helper method:

def _force_evacuate(self, server_id, request_body):
    with utils.temporary_mutation(self.api, microversion='2.67):
        return self.api.post_server_action(server_id, request_body)

Then we have less copy/paste, it's isolated nicely, and 2.67 is only used for those force calls.",EVOLVE
1765,bfdaf3ff_bf0f95df,fb4dcaccb041a6ae38a4e46c7ed83fc855c707db,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/image/glance.py,0,Where is the test coverage for this delta? (See comments in the func test.),DISCUSS
1766,9fdfeff1_25df660d,a1502ee01468630f53bfc16cba06a323c803489e,2b3ba2286a6d2733c33aecdbbacc576085b142fc,nova/tests/unit/compute/test_compute_api.py,1943,We should assert this is *not* called for cold migrate.,FUNCTION
1767,5fc1f717_f0bb680b,b927748c257e705903c2aa0ffa47b19914e31ede,59d94633518e6f6272e9f0654bb908e332f97a96,nova/tests/unit/virt/libvirt/fakelibvirt.py,188,"Well, except this one of course... it's Nvidia after all.",DISCUSS
1768,5fc1f717_44af7ee2,f8b8a6af553db5f658ab2fdcceaafb5cf356f84a,358776a303b0c5dba3c279f242c82b7a12ff5ce8,nova/tests/unit/conductor/test_conductor.py,2189,"blarg, what happened here",FALSE
1769,5fc1f717_fd3a4e96,0a91f3ce521c2ff165967fc99555cda118d23ed0,926e584136e7dce59f32065292aa4eb8120f628c,doc/source/conf.py,101,you might want to make it explicit here that rm -rf nova/api/openstack/placement is coming in a few short weeks and at that time we can make adjustments?,EVOLVE
1770,9fdfeff1_c395288a,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/tests/functional/regressions/test_bug_1815153.py,123,You can remove this part - there is no 'force' flag on the migrate API (for good reason).,EVOLVE
1771,9fdfeff1_b1a3f89d,44230773a53a10867d1485d2e8937b7a3510fae8,6efa3861a5a829ba5883ff191e2552b063028bb0,nova/tests/unit/scheduler/client/test_report.py,3246,why not @mock.patch decorators?,FUNCTION
1772,bfdaf3ff_cb91b19b,40a9d195de13e47eab37a07ccb9eb9518970875e,da98f4ba4554139b3901103aa0d26876b11e1d9a,nova/compute/resource_tracker.py,789,"Based on this, the resource provider shouldn't be in the cache if the resource provider doesn't exist, and it shouldn't exist until get_provider_tree_and_ensure_root is called, right?",DISCUSS
1773,3f79a3b5_e78b0167,3deac1c38aff763f4bc5d892f2167603040924ac,a1c01f97ae0397e8f4ccff5eb2a8b8f5ef7f7221,nova/conf/api.py,202,Indicates,EVOLVE
1774,9fdfeff1_51188cd1,657439ec6d86324d1aef73de0cb76aa8cc4467bc,cfc1cb218c2f4824819ecd36c391a251995f3a16,nova/conductor/manager.py,1449,same,FUNCTION
1775,9fdfeff1_eb377ffd,f2ba72e88cab86b2ab72aace9fd96c77fcb1d012,95287619c9f59ea91537ac5789dda25aab41f5f6,nova/tests/unit/objects/test_request_spec.py,1137,"oh, look what you did :)

Note to self: This works, despite uuidsentinel being nondeterministic, because OrderedDict orders *chronologically*, not numerically/lexicographically/otherwise by key.",FALSE
1776,5fc1f717_4232edf3,a845b3bf7b15c3966452e99493edf02972ad438f,2f06b12623d446da0c398e681b3ee1fb68791d31,nova/scheduler/utils.py,516,nit: use the cell=target_cell named kwarg here.,EVOLVE
1777,9fdfeff1_31b97ecb,b18e905de6a0ab24f90e6dee207214d126347e10,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/conf/ironic.py,87,"nit: if you put the '-' at the end of the character class (right before the closing bracket), you don't need to escape it.",FUNCTION
1778,9fdfeff1_b78495d4,4f29c45b827160b9cee8604ac3dd4f87af373e78,34e595f2a7ac1cd16ea13d0e3a14899b89f94998,nova/tests/functional/api_sample_tests/test_servers.py,441,"I think we needn't this case, we can just call self._post_server() for other testcases.",EVOLVE
1779,5fc1f717_e6bcb26d,c5fd884d1b9405f9584b7be2f3c16c8ad8465ab2,d8ec9487429d87bd7b8bee23d0718ef0b0632f20,nova/scheduler/utils.py,484,"This will not cover the server create case where force_hosts and/or force_nodes is set in the RequestSpec because that unfortunately doesn't use the requested_destination field (requested_destination was introduced for scenarios where the user requests a target and it goes through the scheduler filters, whereas force_hosts/nodes completely bypasses the scheduler filters, hence the 'force').",FUNCTION
1780,3f79a3b5_c046a47e,f604b60d7e1251c6cbafbac75010ea720687f4b0,47bcc39cd633cdbdca97bf8b3d94bccd127b940f,nova/objects/cell_mapping.py,288,"This is almost certainly fine. It is quite likely there is a more direct SQL (non-ORM) query you could make and call via context.session.execute(...) which would do the right thing in a nicely efficient way that makes both postgresql and mysql happy, but I'm not sure it is really worth it, unless someone like Jay came along and produced it in whole cloth from the top of his head.",FUNCTION
1781,9fdfeff1_537f4b65,c7413d9bf533397ee7f02e94baf3820dc4724644,55f455262144ab319a9ff480850aeece88b1dedb,nova/tests/fixtures.py,1424,This looks like something that ought to be mentioned explicitly in the commit message.,EVOLVE
1782,9fdfeff1_4b048b15,a76bed1000da15a6f45766484680e0b6ae352102,29e5b0ad7bde210f95885656768f0480d06882c0,nova/api/openstack/compute/views/servers.py,203,"Hmm, the server group information is in the API database, so we should be able to show server group membership even for instances in a down cell, correct?",DISCUSS
1783,9fdfeff1_2a6d4a02,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,162,same - I don't get it,FALSE
1784,9fdfeff1_cafa7e73,34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,1,nit: you can remove this,EVOLVE
1785,9fdfeff1_5e2887e0,a76eefed62db96fe51ef40e3209c187af3eb9834,054eb3a652f340d819f1b04567d0ed5e207ed733,nova/tests/functional/libvirt/test_reshape.py,96,temporarily,EVOLVE
1786,9fdfeff1_b2b44cf3,ba3fe17b0390ef7027a37d2577b6a3ea14548ce9,4d32b45c152c4dedcb9d01380f557338c3acb81e,nova/network/os_vif_util.py,344,nit: We have vif_name above to use.,FUNCTION
1787,bfdaf3ff_b76355dc,75f96dad42ca60435a66c7710e5a2513ac700eb6,36f310f469b91c7de72a8366c7d493e1e7a4fd0f,nova/conf/compute.py,806,"I think you'd want to mention in here that operators should be careful about changing this on a compute service that is hosting instances because that could cause rebuilds to fail (rebuild on the compute calls _prep_block_device which will do the max check, so if I've got an existing server with 26 volumes attached, the operator thinks 20 is a good max number for some reason, and then I rebuild my server, it's going to fail - similarly but probably less annoying to the user would be if evacuation fails because moving from one host to another fails because the target host is configured with a lower number).

Now that I'm thinking about evacuate (move operations), I don't see anything in here that enforces this for migrate operations so I could create a server with let's say 25 volumes on host A, and then be migrated to host B which is configured with max=10, and it would work even though my server is violating that constraint. Granted, if you're going to set this ever, you're probably going to do it universally, or at least on hosts with similar hardware and grouped into aggregates or something similar, so it's less of a concern. I could just see someone reporting a bug about that in the future.",EVOLVE
1788,9fdfeff1_33153e4a,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,55,driver,EVOLVE
1789,9fdfeff1_3dc10d4f,65910122ef5d66d6804c3138f16f7e989be162ee,1a5ba01451f59220d38c701184183d31d6bc9126,nova/objects/instance_mapping.py,210,nit: needs to be removed since the logic was changed.,EVOLVE
1790,9fdfeff1_91030f0e,94605380e00d0f433d4e66880e98e313f9ec5fb3,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/weights/test_weights_cpu.py,189,Why not just 1.5? :) Here and in a couple of other tests.,DISCUSS
1791,9fdfeff1_33177e54,abe5a4b64dcf678903d3db555caa2fb7f1fa01ee,6e8a69daf14a15fe0b0633f21f4112f19487e9da,nova/api/openstack/api_version_request.py,167,so we should be consisistant about this name,EVOLVE
1792,3f79a3b5_2c480060,adffd410d665f84d279d686e716bb699e9386594,594c653dc1a312d0364ad24c703e1a9b228133e1,nova/compute/resource_tracker.py,450,"In the case of resize revert, it's the destination but that doesn't mean it's a failure, the user just reverted the resize:

https://github.com/openstack/nova/blob/c1de096098344c733565c244163fc3ebf8c35e68/nova/compute/manager.py#L3999

So maybe just say ""failed or was reverted"".",EVOLVE
1793,3fce034c_21e73115,2b5bcc6bb2a64ccc062909a94f68423895993d6b,78e742662edd164c46382c31e106884762fed029,nova/compute/manager.py,7301,"note:
then we update one instace.

on subsequet invocations of this function we enter the else block  and select the first insstance that is not migration or deleting then break and we update the network info cache for that instance.",FUNCTION
1794,5fc1f717_1d3f8425,092f71a38a9caa57c3f1c7356f469c6fb8de57c4,f853e04cd22acc36c906ffb29084160fa05d1ebd,nova/tests/functional/integrated_helpers.py,272,name kwargs,EVOLVE
1795,5fc1f717_e41e496f,226dc89ffa5b5d83ebe6b4d30c44e7e275b19d4c,d24275951d3ad0e0ae00621971278aeedf2bfd09,nova/objects/instance_mapping.py,246,You're iterating the mappings twice back to back. Why not just make this one loop and build both the ims_by_inst_uuid dict and the inst_uuids_by_cell_id dict at the same time?,FUNCTION
1796,5fc1f717_132174a0,56541244fd4931c88cc17771c18e2e72ae9356eb,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/virt/libvirt/driver.py,8449,"This is done as part of images.convert_image(), so we're not losing anything here.",FALSE
1797,3fce034c_fc09eadc,7cffd17c5983000632488038b8c4548317e9465e,bb39296c331948c29ad9aa6422cb103095ce851c,nova/tests/unit/objects/test_instance.py,461,Note to self: admin_state_reset is still used and seems to be in a reachable code path; but that code path doesn't get hit by these tests anymore so this removal is copacetic.,FALSE
1798,9fdfeff1_d146bc21,a4d348fd499328cd58fb786504b0dda37d677f57,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/compute/manager.py,7551,"whereupon you can also remove the vm_power_state arg to this method, yah?",EVOLVE
1799,3f79a3b5_ebac6388,801ef1adca667ecdf243464b083282418d5987e4,2b97e508381e7f1efe48799ee3d9b068b4fd5902,nova/tests/functional/libvirt/test_report_cpu_traits.py,48,shouldn't this go with https://review.openstack.org/#/c/615646/7 the patchset below? why is this not failing below ?,DISCUSS
1800,9fdfeff1_aa5b302c,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/network/linux_utils.py,74,"so, AFAICT, the fix for the above bug (and associated bug in libvirt) is in libvirt 3.2.0. Technically, our libvirt min version is still (crazily...) 1.3.1:

https://github.com/openstack/nova/blob/99ca7d60b41f63446f86ed9be86440a2b250f330/nova/virt/libvirt/driver.py#L223

Not sure if this is something to worry about, though, since in order to use most SR-IOV stuff, I think the end user would be using a much newer version of libvirt?",DISCUSS
1801,9fdfeff1_e521b5b5,da972e3432ef0f7a242510a52484bc5660d9806c,104d79d8dd05fc49c4160b759d43291b874c5d28,nova/virt/ironic/driver.py,909,"This is a change in behavior where, if _validate_instance_and_node doesn't raise, the result from self.ironicclient.call('node.get_by_instance_uuid', ...) will be returned instead of a hardware.InstanceInfo object. I didn't think that's intended, but let me know if it is.",FUNCTION
1802,3f79a3b5_070b447f,bbc2fcb8fb20dde1b81597c319392afb5b2c53fe,8c318d0fb20fdfe0ae8e203245e4d4d6668c8a44,nova/scheduler/client/report.py,1033,OK on the next periodic we call this.,FALSE
1803,9fdfeff1_7bf43df2,47061e699b9dbf6fdeea572a5abeaa72e499ec87,eb93d0cffd11fcfca97b3d4679a0043142a5d998,nova/tests/functional/db/test_instance_mapping.py,203,nice!,DISCUSS
1804,9fdfeff1_c3444d1e,3c997ebf1508f74176bad101db8390e63c5bbe3b,8c663dbd25a0dab1c2d903efc7cf7fc3d9d07b00,nova/pci/manager.py,174,"./nova/pci/manager.py:174:21: N330  LOG.warning, LOG.warn messages require translations `_LW()`!",FUNCTION
1805,9fdfeff1_4e2619bd,35737e27d7e05068fddb0cc4fda3b7d5aeadb307,73c4c87a0f726b1d65e29789638261d8a6d61231,nova/tests/functional/libvirt/test_reshape.py,85,"Could you use set_inventory_for_provider here? Otherwise the report client's provider tree is out of sync with placement after this. In particular, I'm concerned that the reshape will be triggered as if we started with no VGPUs.

[Later] Okay, clearly it's doing a real reshape, which is cool. I actually suspect it's doing... something once, bouncing 409, hitting the retry, refetching the world, and then doing the reshape on the second try. Is it worth confirming that?",DISCUSS
1806,bfdaf3ff_936a087e,d2e13e6af091603228d858cc770b9089a91bd24a,6e49978b91e53d40dca766134340233163da374a,nova/tests/functional/test_report_client.py,306,any reason to remove this test?,DISCUSS
1807,5fc1f717_f7ee4220,40cbea18e6afba46cdc72712b89a122a1377592b,9b2a7f9e7c9c24ad5b698f78681a1de1593b4a53,nova/cmd/common.py,50,Ã¢Å“â€ https://github.com/openstack/nova/blob/master/nova/exception.py#L1661,DISCUSS
1808,3f79a3b5_f3188ece,51d433812010c886b49762296d47cbba9a1be5fd,e27905f482ba26d2bbf3ae5d948dee37523042d5,nova/virt/libvirt/driver.py,8372,could we just switch this to use nova.privsep.qemu.convert_image() so we'd reduce duplicated code and pick up the cache behaviour for free?,EVOLVE
1809,9fdfeff1_40612e11,ae5f4cdcbc0896fb4ac67b3b76587da0b4e38190,d2a87a44468f91d5a468e1262e7e2fd8c7add35c,nova/objects/request_spec.py,528,persisted,EVOLVE
1810,9fdfeff1_14a5bb47,7143131c8b1ae0c68060d16df45c6a877422d167,727b942a88a812afb7368b4d7d3c314a4f8554ed,nova/compute/manager.py,2178,"OK, so we're still using tags",DISCUSS
1811,9fdfeff1_2da63f11,f5d236f868a598f8f241df759c516ec49e3779b0,2fc904acf6d13fed8f81a9dbb88a1bfce06287da,nova/tests/unit/conductor/test_conductor.py,2095,"This wouldn't actually get raised from that method:

https://github.com/openstack/nova/blob/ffc07a689c1584db9128b2f3a86114f1f0f3a523/nova/scheduler/client/report.py#L1477

I guess you're just looking to trigger an error for handling but then why not just mock _fill_provider_mapping and not deal with stuff inside that method? In other words, you're mocking too deep, can just mock _fill_provider_mapping and have it raise test.TestingException.",DISCUSS
1812,9fdfeff1_0381c24a,ecd0d0c3572f77b844e5dd9657204d23ada12318,b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba,nova/compute/api.py,2516,"Had to go find where this is set in this function, but.. here it is :)",FALSE
1813,9fdfeff1_7dcb1571,f32019b8d010895e39cb03aff2912432a6e0ca6e,ad842aa4e74a450e7ace5e394b1554486f814e42,nova/tests/unit/virt/libvirt/test_utils.py,524,Did you forget to plumb this in somewhere?,DISCUSS
1814,ffb9cba7_58405f08,d1f6dda85a8a69e6aed8b48125e15f2460453885,fc3890667e4971e3f0f35ac921c2a6c25f72adec,nova/virt/driver.py,1846,"nit: not sure that's a good name, maybe is_* or check_*",EVOLVE
1815,9fdfeff1_df5e67e5,4c0fb2cf237496f8de41cbbc24bff9278067c7c3,ad4e86dfe8b6c7460e1d1761e6035c39e93231d4,nova/tests/unit/network/test_manager.py,1710,ditto,DISCUSS
1816,9fdfeff1_74f38be8,8b21752c81ae5c3e8f02e1b4b0802c57ab176c29,5283b464b5c4976224a8d7ea3898dfe3e6bec786,nova/virt/libvirt/vif.py,777,no longer,EVOLVE
1817,3f79a3b5_374dce37,47daa751efd52767841635bed3062843b96907be,a1dba961f0018a4995d208a290f4a859ce295840,nova/pci/manager.py,178,from,EVOLVE
1818,dfd5e7cf_5db82c29,0637c5957a23eed1cedcf3d42b5bf6a7ca08d50d,208db51fa1c4bb40fac2a75cc5be72e6a832c119,nova/tests/unit/scheduler/test_utils.py,933,ditto,FUNCTION
1819,3f79a3b5_2fa2f2fa,ec044885ff2c44202cc62cf85149b7993d4d0221,8545ba2af7476e0884b5e7fb90965bef92d605bc,nova/compute/manager.py,551,"as discussed in another patch, you can consolidate this to just having a reportclient attribute set up once in the manager (in a fup patch of course).",FUNCTION
1820,5fc1f717_41eccb28,27128fc7cff1bbff20c813cb6c1a1e8af889e431,2384c41b781a84de98d0932f44d4b3c544c3fe3d,nova/virt/libvirt/driver.py,6051,Leave a comment about why we can ignore this.,EVOLVE
1821,5fc1f717_c15df715,94524124a62817ffbeafddf8f18d9d66eb5f1198,b33fa1c054ba4b7d4e789aa51250ad5c8325da2d,nova/conductor/manager.py,1240,"I thought about this as well, but we can't create the BDMs and tags before the instance in this case.",DISCUSS
1822,3f79a3b5_94660e27,5375ef6b6acbabddafe0c405fa0586a1f54c597a,5f648dda49a6d5fe5ecfd7dddcb5f7dc3d6b51a6,nova/compute/resource_tracker.py,822,the problem that jaypipes raised here for ironic in PS9 is not addressed for this portion right ? where the new computes/nodes get added for ironic ? or am I missing something?,DISCUSS
1823,9fdfeff1_32cd0131,87f4b2365837fc97175bcdefa2499ea23d92c948,0c8824b44d2f841d610296893f9a316f4f083d43,nova/tests/unit/api/openstack/compute/test_serversV21.py,7570,We should have a wrinkle where the AZ is going to be UNKNOWN.,DISCUSS
1824,9fdfeff1_ea7a9886,090e41a13c3c2cd76d8c56571044dcfa8c1aeb7b,99ca7d60b41f63446f86ed9be86440a2b250f330,nova/virt/libvirt/vif.py,828,Stein,EVOLVE
1825,9fdfeff1_b8a71da8,dec5dd9286e0d218d3f7658879369b5d4a529a65,16dda2774801cb829ca849506f077edb95e85253,nova/conf/libvirt.py,742,they are,EVOLVE
1826,9fdfeff1_bedfdc38,f3b7b972ddea69649cfa6c79cad5a4220a2588c7,9cb825b0147af3b191ea2989e5187e4afdadcb15,nova/utils.py,296,"we stop returning a ValueError and we rather now check whether it's either one of the tuple items by conditionals.

Should we raise ValueError then after all of the conditionals ?",DISCUSS
1827,3f79a3b5_ce0cae3b,7b6e01396c102bf37e0e2c08c99cd7319dbd02dc,fd7ca473daef93548bc11bf2bd8ae74a6bd7e817,nova/scheduler/client/report.py,775,might be worth just renaming this to _refresh_provider() since everything about the provider is now being pulled anew.,EVOLVE
